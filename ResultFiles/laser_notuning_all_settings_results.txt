DOING SINGLE LANG CLASSIFICATION EXPTS
FOr lang:  DE
1024
************for dimension:  OverallCEFRrating  ***************
Printing class statistics
Counter({'B1': 328, 'A2': 306, 'B2': 293, 'A1': 57, 'C1': 42})
RandomForestClassifier(bootstrap=True, class_weight='balanced',
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, min_impurity_decrease=0.0,
                       min_impurity_split=None, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=None, oob_score=False,
                       random_state=1234, verbose=0, warm_start=False)
Fold 0
[[ 2 10  0  0  0]
 [ 0 52 10  0  0]
 [ 0 17 39 10  0]
 [ 0  0  5 54  0]
 [ 0  0  0  9  0]]
              precision    recall  f1-score   support

          A1       1.00      0.17      0.29        12
          A2       0.66      0.84      0.74        62
          B1       0.72      0.59      0.65        66
          B2       0.74      0.92      0.82        59
          C1       0.00      0.00      0.00         9

    accuracy                           0.71       208
   macro avg       0.62      0.50      0.50       208
weighted avg       0.69      0.71      0.67       208


Fold 1
[[ 2 10  0  0  0]
 [ 0 48 12  1  0]
 [ 0 16 31 19  0]
 [ 0  0  8 51  0]
 [ 0  0  0  9  0]]
              precision    recall  f1-score   support

          A1       1.00      0.17      0.29        12
          A2       0.65      0.79      0.71        61
          B1       0.61      0.47      0.53        66
          B2       0.64      0.86      0.73        59
          C1       0.00      0.00      0.00         9

    accuracy                           0.64       207
   macro avg       0.58      0.46      0.45       207
weighted avg       0.62      0.64      0.60       207


Fold 2
[[ 1 10  0  0  0]
 [ 0 44 17  0  0]
 [ 0 14 41 11  0]
 [ 0  0 11 48  0]
 [ 0  0  1  7  0]]
              precision    recall  f1-score   support

          A1       1.00      0.09      0.17        11
          A2       0.65      0.72      0.68        61
          B1       0.59      0.62      0.60        66
          B2       0.73      0.81      0.77        59
          C1       0.00      0.00      0.00         8

    accuracy                           0.65       205
   macro avg       0.59      0.45      0.44       205
weighted avg       0.64      0.65      0.63       205


Fold 3
[[ 0 10  1  0  0]
 [ 0 51 10  0  0]
 [ 0 16 31 18  0]
 [ 0  2 10 46  0]
 [ 0  0  0  8  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        11
          A2       0.65      0.84      0.73        61
          B1       0.60      0.48      0.53        65
          B2       0.64      0.79      0.71        58
          C1       0.00      0.00      0.00         8

    accuracy                           0.63       203
   macro avg       0.38      0.42      0.39       203
weighted avg       0.57      0.63      0.59       203


Fold 4
[[ 0 10  1  0  0]
 [ 0 47 13  1  0]
 [ 0 13 38 14  0]
 [ 0  0  8 50  0]
 [ 0  0  0  8  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        11
          A2       0.67      0.77      0.72        61
          B1       0.63      0.58      0.61        65
          B2       0.68      0.86      0.76        58
          C1       0.00      0.00      0.00         8

    accuracy                           0.67       203
   macro avg       0.40      0.44      0.42       203
weighted avg       0.60      0.67      0.63       203


K-fold scores
[0.6746720920923047, 0.6042303005289138, 0.6270822150300845, 0.5908051991795834, 0.6284029631858008]
SKF f1 score mean 0.6250385540033375

LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
          verbose=0)
Fold 0
[[ 5  7  0  0  0]
 [ 5 49  7  1  0]
 [ 0 24 27 15  0]
 [ 0  0  1 57  1]
 [ 0  0  0  9  0]]
              precision    recall  f1-score   support

          A1       0.50      0.42      0.45        12
          A2       0.61      0.79      0.69        62
          B1       0.77      0.41      0.53        66
          B2       0.70      0.97      0.81        59
          C1       0.00      0.00      0.00         9

    accuracy                           0.66       208
   macro avg       0.52      0.52      0.50       208
weighted avg       0.65      0.66      0.63       208


Fold 1
[[ 5  7  0  0  0]
 [ 8 42  9  2  0]
 [ 0 20 23 23  0]
 [ 1  0  4 51  3]
 [ 0  0  0  8  1]]
              precision    recall  f1-score   support

          A1       0.36      0.42      0.38        12
          A2       0.61      0.69      0.65        61
          B1       0.64      0.35      0.45        66
          B2       0.61      0.86      0.71        59
          C1       0.25      0.11      0.15         9

    accuracy                           0.59       207
   macro avg       0.49      0.49      0.47       207
weighted avg       0.59      0.59      0.57       207


Fold 2
[[ 4  7  0  0  0]
 [ 7 45  8  1  0]
 [ 0 24 28 13  1]
 [ 0  0  5 51  3]
 [ 0  0  0  7  1]]
              precision    recall  f1-score   support

          A1       0.36      0.36      0.36        11
          A2       0.59      0.74      0.66        61
          B1       0.68      0.42      0.52        66
          B2       0.71      0.86      0.78        59
          C1       0.20      0.12      0.15         8

    accuracy                           0.63       205
   macro avg       0.51      0.50      0.50       205
weighted avg       0.63      0.63      0.61       205


Fold 3
[[ 2  7  2  0  0]
 [ 5 40 14  2  0]
 [ 0 18 26 21  0]
 [ 0  3  6 46  3]
 [ 0  0  0  8  0]]
              precision    recall  f1-score   support

          A1       0.29      0.18      0.22        11
          A2       0.59      0.66      0.62        61
          B1       0.54      0.40      0.46        65
          B2       0.60      0.79      0.68        58
          C1       0.00      0.00      0.00         8

    accuracy                           0.56       203
   macro avg       0.40      0.41      0.40       203
weighted avg       0.54      0.56      0.54       203


Fold 4
[[ 6  4  1  0  0]
 [ 3 45 12  1  0]
 [ 0 16 33 16  0]
 [ 0  0  7 50  1]
 [ 0  0  0  8  0]]
              precision    recall  f1-score   support

          A1       0.67      0.55      0.60        11
          A2       0.69      0.74      0.71        61
          B1       0.62      0.51      0.56        65
          B2       0.67      0.86      0.75        58
          C1       0.00      0.00      0.00         8

    accuracy                           0.66       203
   macro avg       0.53      0.53      0.53       203
weighted avg       0.63      0.66      0.64       203


K-fold scores
[0.6309256452949875, 0.5664927854186167, 0.6135841429462217, 0.5404499121157154, 0.6410659277399476]
SKF f1 score mean 0.5985036827030978

LogisticRegression(C=1.0, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='multinomial', n_jobs=None,
                   penalty='l2', random_state=1234, solver='lbfgs', tol=0.0001,
                   verbose=0, warm_start=False)
Fold 0
[[ 8  4  0  0  0]
 [25 28  9  0  0]
 [ 4 28 26  6  2]
 [ 0  4  7 21 27]
 [ 0  0  0  0  9]]
              precision    recall  f1-score   support

          A1       0.22      0.67      0.33        12
          A2       0.44      0.45      0.44        62
          B1       0.62      0.39      0.48        66
          B2       0.78      0.36      0.49        59
          C1       0.24      1.00      0.38         9

    accuracy                           0.44       208
   macro avg       0.46      0.57      0.42       208
weighted avg       0.57      0.44      0.46       208


Fold 1
[[ 9  3  0  0  0]
 [30 22  7  1  1]
 [ 5 18 27 11  5]
 [ 1  5  9 18 26]
 [ 0  1  1  1  6]]
              precision    recall  f1-score   support

          A1       0.20      0.75      0.32        12
          A2       0.45      0.36      0.40        61
          B1       0.61      0.41      0.49        66
          B2       0.58      0.31      0.40        59
          C1       0.16      0.67      0.26         9

    accuracy                           0.40       207
   macro avg       0.40      0.50      0.37       207
weighted avg       0.51      0.40      0.42       207


Fold 2
[[ 8  3  0  0  0]
 [22 23 15  1  0]
 [ 3 22 30  8  3]
 [ 0  3 13 22 21]
 [ 0  0  1  3  4]]
              precision    recall  f1-score   support

          A1       0.24      0.73      0.36        11
          A2       0.45      0.38      0.41        61
          B1       0.51      0.45      0.48        66
          B2       0.65      0.37      0.47        59
          C1       0.14      0.50      0.22         8

    accuracy                           0.42       205
   macro avg       0.40      0.49      0.39       205
weighted avg       0.50      0.42      0.44       205


Fold 3
[[ 8  3  0  0  0]
 [21 23 16  1  0]
 [ 9 15 28 10  3]
 [ 1  2 15 25 15]
 [ 0  0  0  0  8]]
              precision    recall  f1-score   support

          A1       0.21      0.73      0.32        11
          A2       0.53      0.38      0.44        61
          B1       0.47      0.43      0.45        65
          B2       0.69      0.43      0.53        58
          C1       0.31      1.00      0.47         8

    accuracy                           0.45       203
   macro avg       0.44      0.59      0.44       203
weighted avg       0.53      0.45      0.47       203


Fold 4
[[ 8  2  1  0  0]
 [23 29  8  1  0]
 [ 8 13 30 11  3]
 [ 0  1  9 24 24]
 [ 0  0  0  3  5]]
              precision    recall  f1-score   support

          A1       0.21      0.73      0.32        11
          A2       0.64      0.48      0.55        61
          B1       0.62      0.46      0.53        65
          B2       0.62      0.41      0.49        58
          C1       0.16      0.62      0.25         8

    accuracy                           0.47       203
   macro avg       0.45      0.54      0.43       203
weighted avg       0.59      0.47      0.50       203


K-fold scores
[0.45919453211193506, 0.4178132658194979, 0.4410991595169407, 0.46537624459402377, 0.5030131219442575]
SKF f1 score mean 0.45729926479733096

************for dimension:  Grammaticalaccuracy  ***************
Printing class statistics
Counter({'B1': 349, 'A2': 284, 'B2': 258, 'A1': 88, 'C1': 47})
RandomForestClassifier(bootstrap=True, class_weight='balanced',
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, min_impurity_decrease=0.0,
                       min_impurity_split=None, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=None, oob_score=False,
                       random_state=1234, verbose=0, warm_start=False)
Fold 0
[[ 4 12  2  0  0]
 [ 4 34 18  1  0]
 [ 0 18 37 15  0]
 [ 0  3 12 37  0]
 [ 0  0  0 10  0]]
              precision    recall  f1-score   support

          A1       0.50      0.22      0.31        18
          A2       0.51      0.60      0.55        57
          B1       0.54      0.53      0.53        70
          B2       0.59      0.71      0.64        52
          C1       0.00      0.00      0.00        10

    accuracy                           0.54       207
   macro avg       0.43      0.41      0.41       207
weighted avg       0.51      0.54      0.52       207


Fold 1
[[ 5 12  1  0  0]
 [ 1 36 20  0  0]
 [ 0 16 43 11  0]
 [ 0  2 13 37  0]
 [ 0  0  1  9  0]]
              precision    recall  f1-score   support

          A1       0.83      0.28      0.42        18
          A2       0.55      0.63      0.59        57
          B1       0.55      0.61      0.58        70
          B2       0.65      0.71      0.68        52
          C1       0.00      0.00      0.00        10

    accuracy                           0.58       207
   macro avg       0.52      0.45      0.45       207
weighted avg       0.57      0.58      0.56       207


Fold 2
[[ 5 13  0  0  0]
 [ 0 35 22  0  0]
 [ 0 16 32 22  0]
 [ 0  1  9 42  0]
 [ 0  0  0  9  0]]
              precision    recall  f1-score   support

          A1       1.00      0.28      0.43        18
          A2       0.54      0.61      0.57        57
          B1       0.51      0.46      0.48        70
          B2       0.58      0.81      0.67        52
          C1       0.00      0.00      0.00         9

    accuracy                           0.55       206
   macro avg       0.52      0.43      0.43       206
weighted avg       0.55      0.55      0.53       206


Fold 3
[[ 2 14  1  0  0]
 [ 2 40 15  0  0]
 [ 0 21 37 12  0]
 [ 0  0 16 35  0]
 [ 0  0  1  8  0]]
              precision    recall  f1-score   support

          A1       0.50      0.12      0.19        17
          A2       0.53      0.70      0.61        57
          B1       0.53      0.53      0.53        70
          B2       0.64      0.69      0.66        51
          C1       0.00      0.00      0.00         9

    accuracy                           0.56       204
   macro avg       0.44      0.41      0.40       204
weighted avg       0.53      0.56      0.53       204


Fold 4
[[ 3 11  3  0  0]
 [ 1 41 14  0  0]
 [ 0 26 31 12  0]
 [ 0  1 16 34  0]
 [ 0  0  0  9  0]]
              precision    recall  f1-score   support

          A1       0.75      0.18      0.29        17
          A2       0.52      0.73      0.61        56
          B1       0.48      0.45      0.47        69
          B2       0.62      0.67      0.64        51
          C1       0.00      0.00      0.00         9

    accuracy                           0.54       202
   macro avg       0.47      0.40      0.40       202
weighted avg       0.53      0.54      0.51       202


K-fold scores
[0.5194375974404235, 0.5644651286366679, 0.5298991044447787, 0.5316803679733757, 0.5136354076132066]
SKF f1 score mean 0.5318235212216905

LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
          verbose=0)
Fold 0
[[ 9  8  1  0  0]
 [ 7 34 15  1  0]
 [ 2 22 24 22  0]
 [ 0  2  5 42  3]
 [ 0  0  0 10  0]]
              precision    recall  f1-score   support

          A1       0.50      0.50      0.50        18
          A2       0.52      0.60      0.55        57
          B1       0.53      0.34      0.42        70
          B2       0.56      0.81      0.66        52
          C1       0.00      0.00      0.00        10

    accuracy                           0.53       207
   macro avg       0.42      0.45      0.43       207
weighted avg       0.51      0.53      0.50       207


Fold 1
[[11  7  0  0  0]
 [10 31 15  1  0]
 [ 0 28 23 18  1]
 [ 0  3  7 42  0]
 [ 0  0  0 10  0]]
              precision    recall  f1-score   support

          A1       0.52      0.61      0.56        18
          A2       0.45      0.54      0.49        57
          B1       0.51      0.33      0.40        70
          B2       0.59      0.81      0.68        52
          C1       0.00      0.00      0.00        10

    accuracy                           0.52       207
   macro avg       0.42      0.46      0.43       207
weighted avg       0.49      0.52      0.49       207


Fold 2
[[ 9  9  0  0  0]
 [12 28 16  1  0]
 [ 2 15 20 32  1]
 [ 0  2  3 46  1]
 [ 0  0  0  9  0]]
              precision    recall  f1-score   support

          A1       0.39      0.50      0.44        18
          A2       0.52      0.49      0.50        57
          B1       0.51      0.29      0.37        70
          B2       0.52      0.88      0.66        52
          C1       0.00      0.00      0.00         9

    accuracy                           0.50       206
   macro avg       0.39      0.43      0.39       206
weighted avg       0.48      0.50      0.47       206


Fold 3
[[ 8  9  0  0  0]
 [13 35  8  1  0]
 [ 2 24 22 22  0]
 [ 0  1  8 39  3]
 [ 0  0  0  8  1]]
              precision    recall  f1-score   support

          A1       0.35      0.47      0.40        17
          A2       0.51      0.61      0.56        57
          B1       0.58      0.31      0.41        70
          B2       0.56      0.76      0.64        51
          C1       0.25      0.11      0.15         9

    accuracy                           0.51       204
   macro avg       0.45      0.45      0.43       204
weighted avg       0.52      0.51      0.50       204


Fold 4
[[ 6 10  1  0  0]
 [ 8 36 11  1  0]
 [ 7 23 23 16  0]
 [ 1  3  1 45  1]
 [ 0  0  0  9  0]]
              precision    recall  f1-score   support

          A1       0.27      0.35      0.31        17
          A2       0.50      0.64      0.56        56
          B1       0.64      0.33      0.44        69
          B2       0.63      0.88      0.74        51
          C1       0.00      0.00      0.00         9

    accuracy                           0.54       202
   macro avg       0.41      0.44      0.41       202
weighted avg       0.54      0.54      0.52       202


K-fold scores
[0.5030110493415489, 0.4913703397266494, 0.4685373677042281, 0.49630310601790106, 0.5177341162327367]
SKF f1 score mean 0.4953911958046128

LogisticRegression(C=1.0, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='multinomial', n_jobs=None,
                   penalty='l2', random_state=1234, solver='lbfgs', tol=0.0001,
                   verbose=0, warm_start=False)
Fold 0
[[11  6  1  0  0]
 [20 28  8  1  0]
 [ 8 25 29  3  5]
 [ 1  4 14  7 26]
 [ 0  0  3  0  7]]
              precision    recall  f1-score   support

          A1       0.28      0.61      0.38        18
          A2       0.44      0.49      0.47        57
          B1       0.53      0.41      0.46        70
          B2       0.64      0.13      0.22        52
          C1       0.18      0.70      0.29        10

    accuracy                           0.40       207
   macro avg       0.41      0.47      0.36       207
weighted avg       0.49      0.40      0.39       207


Fold 1
[[13  3  2  0  0]
 [23 23 11  0  0]
 [ 5 27 29  5  4]
 [ 2  4 21  5 20]
 [ 0  0  3  3  4]]
              precision    recall  f1-score   support

          A1       0.30      0.72      0.43        18
          A2       0.40      0.40      0.40        57
          B1       0.44      0.41      0.43        70
          B2       0.38      0.10      0.15        52
          C1       0.14      0.40      0.21        10

    accuracy                           0.36       207
   macro avg       0.33      0.41      0.32       207
weighted avg       0.39      0.36      0.34       207


Fold 2
[[17  1  0  0  0]
 [24 23 10  0  0]
 [ 7 18 28 14  3]
 [ 0  3 18  9 22]
 [ 0  1  0  2  6]]
              precision    recall  f1-score   support

          A1       0.35      0.94      0.52        18
          A2       0.50      0.40      0.45        57
          B1       0.50      0.40      0.44        70
          B2       0.36      0.17      0.23        52
          C1       0.19      0.67      0.30         9

    accuracy                           0.40       206
   macro avg       0.38      0.52      0.39       206
weighted avg       0.44      0.40      0.39       206


Fold 3
[[12  4  1  0  0]
 [22 28  7  0  0]
 [11 21 27  9  2]
 [ 0  5 16 10 20]
 [ 0  0  1  2  6]]
              precision    recall  f1-score   support

          A1       0.27      0.71      0.39        17
          A2       0.48      0.49      0.49        57
          B1       0.52      0.39      0.44        70
          B2       0.48      0.20      0.28        51
          C1       0.21      0.67      0.32         9

    accuracy                           0.41       204
   macro avg       0.39      0.49      0.38       204
weighted avg       0.46      0.41      0.40       204


Fold 4
[[11  4  2  0  0]
 [22 23 11  0  0]
 [12 27 23  0  7]
 [ 2  2 17 11 19]
 [ 0  0  1  0  8]]
              precision    recall  f1-score   support

          A1       0.23      0.65      0.34        17
          A2       0.41      0.41      0.41        56
          B1       0.43      0.33      0.37        69
          B2       1.00      0.22      0.35        51
          C1       0.24      0.89      0.37         9

    accuracy                           0.38       202
   macro avg       0.46      0.50      0.37       202
weighted avg       0.54      0.38      0.38       202


K-fold scores
[0.38830825328076707, 0.3412093501541368, 0.3917281224237583, 0.40395274040874213, 0.3767041557011446]
SKF f1 score mean 0.3803805243937098

************for dimension:  Orthography  ***************
Printing class statistics
Counter({'B2': 338, 'B1': 321, 'C1': 161, 'A2': 150, 'C2': 38, 'A1': 18})
RandomForestClassifier(bootstrap=True, class_weight='balanced',
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, min_impurity_decrease=0.0,
                       min_impurity_split=None, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=None, oob_score=False,
                       random_state=1234, verbose=0, warm_start=False)
Fold 0
[[ 0  2  2  0  0  0]
 [ 0  8 22  0  0  0]
 [ 0  3 46 16  0  0]
 [ 0  1 21 43  3  0]
 [ 0  0  3 27  3  0]
 [ 0  0  0  8  0  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         4
          A2       0.57      0.27      0.36        30
          B1       0.49      0.71      0.58        65
          B2       0.46      0.63      0.53        68
          C1       0.50      0.09      0.15        33
          C2       0.00      0.00      0.00         8

    accuracy                           0.48       208
   macro avg       0.34      0.28      0.27       208
weighted avg       0.46      0.48      0.43       208


Fold 1
[[ 0  3  1  0  0  0]
 [ 0  5 23  2  0  0]
 [ 0  1 48 15  0  0]
 [ 0  0 23 41  4  0]
 [ 0  0  2 26  4  0]
 [ 0  0  0  8  0  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         4
          A2       0.56      0.17      0.26        30
          B1       0.49      0.75      0.60        64
          B2       0.45      0.60      0.51        68
          C1       0.50      0.12      0.20        32
          C2       0.00      0.00      0.00         8

    accuracy                           0.48       206
   macro avg       0.33      0.27      0.26       206
weighted avg       0.46      0.48      0.42       206


Fold 2
[[ 0  3  1  0  0  0]
 [ 0  5 25  0  0  0]
 [ 0  1 53 10  0  0]
 [ 0  0 26 41  1  0]
 [ 0  0  4 26  2  0]
 [ 0  0  0  6  2  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         4
          A2       0.56      0.17      0.26        30
          B1       0.49      0.83      0.61        64
          B2       0.49      0.60      0.54        68
          C1       0.40      0.06      0.11        32
          C2       0.00      0.00      0.00         8

    accuracy                           0.49       206
   macro avg       0.32      0.28      0.25       206
weighted avg       0.46      0.49      0.42       206


Fold 3
[[ 0  2  1  0  0  0]
 [ 0  8 22  0  0  0]
 [ 0  3 52  9  0  0]
 [ 0  0 17 42  8  0]
 [ 0  0  4 24  4  0]
 [ 0  0  1  4  2  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         3
          A2       0.62      0.27      0.37        30
          B1       0.54      0.81      0.65        64
          B2       0.53      0.63      0.58        67
          C1       0.29      0.12      0.17        32
          C2       0.00      0.00      0.00         7

    accuracy                           0.52       203
   macro avg       0.33      0.31      0.29       203
weighted avg       0.48      0.52      0.48       203


Fold 4
[[ 0  1  2  0  0  0]
 [ 0 11 18  1  0  0]
 [ 0  2 50 12  0  0]
 [ 0  2 16 48  1  0]
 [ 0  0  2 27  3  0]
 [ 0  0  0  7  0  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         3
          A2       0.69      0.37      0.48        30
          B1       0.57      0.78      0.66        64
          B2       0.51      0.72      0.59        67
          C1       0.75      0.09      0.17        32
          C2       0.00      0.00      0.00         7

    accuracy                           0.55       203
   macro avg       0.42      0.33      0.32       203
weighted avg       0.57      0.55      0.50       203


K-fold scores
[0.43122520341920434, 0.422833972696784, 0.4237514189418344, 0.47594861182901727, 0.49995136099452364]
SKF f1 score mean 0.4507421135762727

LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
          verbose=0)
Fold 0
[[ 1  3  0  0  0  0]
 [ 4 17  8  1  0  0]
 [ 0 14 36 10  2  3]
 [ 0  4 23 24 15  2]
 [ 0  1  2 15 12  3]
 [ 0  0  0  6  2  0]]
              precision    recall  f1-score   support

          A1       0.20      0.25      0.22         4
          A2       0.44      0.57      0.49        30
          B1       0.52      0.55      0.54        65
          B2       0.43      0.35      0.39        68
          C1       0.39      0.36      0.38        33
          C2       0.00      0.00      0.00         8

    accuracy                           0.43       208
   macro avg       0.33      0.35      0.34       208
weighted avg       0.43      0.43      0.43       208


Fold 1
[[ 3  1  0  0  0  0]
 [ 5 17  7  1  0  0]
 [ 3  8 42  9  2  0]
 [ 0  0 29 20 18  1]
 [ 0  0  4 13 12  3]
 [ 0  0  0  3  4  1]]
              precision    recall  f1-score   support

          A1       0.27      0.75      0.40         4
          A2       0.65      0.57      0.61        30
          B1       0.51      0.66      0.58        64
          B2       0.43      0.29      0.35        68
          C1       0.33      0.38      0.35        32
          C2       0.20      0.12      0.15         8

    accuracy                           0.46       206
   macro avg       0.40      0.46      0.41       206
weighted avg       0.46      0.46      0.45       206


Fold 2
[[ 2  2  0  0  0  0]
 [ 1 13 15  1  0  0]
 [ 1 14 41  6  2  0]
 [ 0  3 28 21 11  5]
 [ 0  0  7 11 14  0]
 [ 0  0  0  3  5  0]]
              precision    recall  f1-score   support

          A1       0.50      0.50      0.50         4
          A2       0.41      0.43      0.42        30
          B1       0.45      0.64      0.53        64
          B2       0.50      0.31      0.38        68
          C1       0.44      0.44      0.44        32
          C2       0.00      0.00      0.00         8

    accuracy                           0.44       206
   macro avg       0.38      0.39      0.38       206
weighted avg       0.44      0.44      0.43       206


Fold 3
[[ 3  0  0  0  0  0]
 [ 6 13 11  0  0  0]
 [ 1 15 41  5  2  0]
 [ 1  3 20 13 17 13]
 [ 0  1  5  7  6 13]
 [ 0  1  0  0  4  2]]
              precision    recall  f1-score   support

          A1       0.27      1.00      0.43         3
          A2       0.39      0.43      0.41        30
          B1       0.53      0.64      0.58        64
          B2       0.52      0.19      0.28        67
          C1       0.21      0.19      0.20        32
          C2       0.07      0.29      0.11         7

    accuracy                           0.38       203
   macro avg       0.33      0.46      0.34       203
weighted avg       0.44      0.38      0.38       203


Fold 4
[[ 2  1  0  0  0  0]
 [ 2 19  7  2  0  0]
 [ 1 18 35  9  0  1]
 [ 0  3 20 18 15 11]
 [ 0  0  3  8 15  6]
 [ 0  0  0  1  5  1]]
              precision    recall  f1-score   support

          A1       0.40      0.67      0.50         3
          A2       0.46      0.63      0.54        30
          B1       0.54      0.55      0.54        64
          B2       0.47      0.27      0.34        67
          C1       0.43      0.47      0.45        32
          C2       0.05      0.14      0.08         7

    accuracy                           0.44       203
   macro avg       0.39      0.45      0.41       203
weighted avg       0.47      0.44      0.44       203


K-fold scores
[0.4293002469424554, 0.4515569879764076, 0.42913760214104724, 0.3788984699438611, 0.44395698777121667]
SKF f1 score mean 0.42657005895499767

LogisticRegression(C=1.0, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='multinomial', n_jobs=None,
                   penalty='l2', random_state=1234, solver='lbfgs', tol=0.0001,
                   verbose=0, warm_start=False)
Fold 0
[[ 3  1  0  0  0  0]
 [ 8 16  4  2  0  0]
 [ 7 25 23  5  1  4]
 [ 6  5 19 20  5 13]
 [ 1  0  2 10  5 15]
 [ 1  0  0  3  4  0]]
              precision    recall  f1-score   support

          A1       0.12      0.75      0.20         4
          A2       0.34      0.53      0.42        30
          B1       0.48      0.35      0.41        65
          B2       0.50      0.29      0.37        68
          C1       0.33      0.15      0.21        33
          C2       0.00      0.00      0.00         8

    accuracy                           0.32       208
   macro avg       0.29      0.35      0.27       208
weighted avg       0.42      0.32      0.35       208


Fold 1
[[ 3  1  0  0  0  0]
 [11 12  5  0  2  0]
 [ 4 15 34  7  3  1]
 [ 4  1 29  9 14 11]
 [ 0  2  2 10  4 14]
 [ 0  1  0  2  2  3]]
              precision    recall  f1-score   support

          A1       0.14      0.75      0.23         4
          A2       0.38      0.40      0.39        30
          B1       0.49      0.53      0.51        64
          B2       0.32      0.13      0.19        68
          C1       0.16      0.12      0.14        32
          C2       0.10      0.38      0.16         8

    accuracy                           0.32       206
   macro avg       0.26      0.39      0.27       206
weighted avg       0.34      0.32      0.31       206


Fold 2
[[ 2  2  0  0  0  0]
 [ 4 18  7  1  0  0]
 [ 5 21 31  4  1  2]
 [ 3  7 22 10  4 22]
 [ 1  1  6  5  6 13]
 [ 0  0  0  2  4  2]]
              precision    recall  f1-score   support

          A1       0.13      0.50      0.21         4
          A2       0.37      0.60      0.46        30
          B1       0.47      0.48      0.48        64
          B2       0.45      0.15      0.22        68
          C1       0.40      0.19      0.26        32
          C2       0.05      0.25      0.09         8

    accuracy                           0.33       206
   macro avg       0.31      0.36      0.28       206
weighted avg       0.42      0.33      0.33       206


Fold 3
[[ 3  0  0  0  0  0]
 [11 10  9  0  0  0]
 [ 6 24 27  3  1  3]
 [ 3  4 17  4 10 29]
 [ 0  2  4  2  3 21]
 [ 0  1  0  0  4  2]]
              precision    recall  f1-score   support

          A1       0.13      1.00      0.23         3
          A2       0.24      0.33      0.28        30
          B1       0.47      0.42      0.45        64
          B2       0.44      0.06      0.11        67
          C1       0.17      0.09      0.12        32
          C2       0.04      0.29      0.06         7

    accuracy                           0.24       203
   macro avg       0.25      0.37      0.21       203
weighted avg       0.36      0.24      0.24       203


Fold 4
[[ 2  1  0  0  0  0]
 [ 8 14  6  2  0  0]
 [ 6 23 27  2  0  6]
 [ 4  5 19  3 12 24]
 [ 1  1  3  2 11 14]
 [ 0  0  0  0  4  3]]
              precision    recall  f1-score   support

          A1       0.10      0.67      0.17         3
          A2       0.32      0.47      0.38        30
          B1       0.49      0.42      0.45        64
          B2       0.33      0.04      0.08        67
          C1       0.41      0.34      0.37        32
          C2       0.06      0.43      0.11         7

    accuracy                           0.30       203
   macro avg       0.28      0.40      0.26       203
weighted avg       0.38      0.30      0.29       203


K-fold scores
[0.3451341088647505, 0.3085054245468671, 0.3349429281703036, 0.241621871285258, 0.29011242862016184]
SKF f1 score mean 0.30406335229746817

************for dimension:  Vocabularyrange  ***************
Printing class statistics
Counter({'B1': 349, 'B2': 271, 'A2': 213, 'C1': 138, 'A1': 50, 'C2': 5})
RandomForestClassifier(bootstrap=True, class_weight='balanced',
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, min_impurity_decrease=0.0,
                       min_impurity_split=None, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=None, oob_score=False,
                       random_state=1234, verbose=0, warm_start=False)
Fold 0
[[ 2  5  3  0  0  0]
 [ 0 26 17  0  0  0]
 [ 0  8 59  3  0  0]
 [ 0  0 10 38  7  0]
 [ 0  0  1 15 12  0]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       1.00      0.20      0.33        10
          A2       0.67      0.60      0.63        43
          B1       0.66      0.84      0.74        70
          B2       0.68      0.69      0.68        55
          C1       0.60      0.43      0.50        28
          C2       0.00      0.00      0.00         1

    accuracy                           0.66       207
   macro avg       0.60      0.46      0.48       207
weighted avg       0.67      0.66      0.65       207


Fold 1
[[ 0  4  6  0  0  0]
 [ 0 22 21  0  0  0]
 [ 0 15 49  5  1  0]
 [ 0  0  8 32 14  0]
 [ 0  0  0  8 20  0]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        10
          A2       0.54      0.51      0.52        43
          B1       0.58      0.70      0.64        70
          B2       0.71      0.59      0.65        54
          C1       0.56      0.71      0.63        28
          C2       0.00      0.00      0.00         1

    accuracy                           0.60       206
   macro avg       0.40      0.42      0.41       206
weighted avg       0.57      0.60      0.58       206


Fold 2
[[ 0  9  1  0  0  0]
 [ 0 21 22  0  0  0]
 [ 0  7 52 11  0  0]
 [ 0  1  9 33 11  0]
 [ 0  0  0  7 21  0]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        10
          A2       0.55      0.49      0.52        43
          B1       0.62      0.74      0.68        70
          B2       0.65      0.61      0.63        54
          C1       0.64      0.75      0.69        28
          C2       0.00      0.00      0.00         1

    accuracy                           0.62       206
   macro avg       0.41      0.43      0.42       206
weighted avg       0.58      0.62      0.60       206


Fold 3
[[ 0  8  2  0  0  0]
 [ 0 24 18  0  0  0]
 [ 0  2 64  4  0  0]
 [ 0  0  7 37 10  0]
 [ 0  0  0 10 17  0]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        10
          A2       0.71      0.57      0.63        42
          B1       0.70      0.91      0.80        70
          B2       0.73      0.69      0.70        54
          C1       0.61      0.63      0.62        27
          C2       0.00      0.00      0.00         1

    accuracy                           0.70       204
   macro avg       0.46      0.47      0.46       204
weighted avg       0.66      0.70      0.67       204


Fold 4
[[ 0  8  2  0  0  0]
 [ 0 16 26  0  0  0]
 [ 0  7 56  6  0  0]
 [ 0  0  9 33 12  0]
 [ 0  0  0 10 17  0]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        10
          A2       0.52      0.38      0.44        42
          B1       0.60      0.81      0.69        69
          B2       0.67      0.61      0.64        54
          C1       0.57      0.63      0.60        27
          C2       0.00      0.00      0.00         1

    accuracy                           0.60       203
   macro avg       0.39      0.41      0.39       203
weighted avg       0.57      0.60      0.58       203


K-fold scores
[0.6467839791010522, 0.5799920144580339, 0.5960707244488878, 0.6712085375027897, 0.5754771798683785]
SKF f1 score mean 0.6139064870758284

LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
          verbose=0)
Fold 0
[[ 4  5  1  0  0  0]
 [ 0 27 15  1  0  0]
 [ 1 16 51  2  0  0]
 [ 0  1  9 35 10  0]
 [ 0  1  0  4 23  0]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.80      0.40      0.53        10
          A2       0.54      0.63      0.58        43
          B1       0.67      0.73      0.70        70
          B2       0.83      0.64      0.72        55
          C1       0.68      0.82      0.74        28
          C2       0.00      0.00      0.00         1

    accuracy                           0.68       207
   macro avg       0.59      0.54      0.55       207
weighted avg       0.69      0.68      0.67       207


Fold 1
[[ 4  3  3  0  0  0]
 [10 16 14  3  0  0]
 [ 3 13 44  8  2  0]
 [ 0  0  6 32 16  0]
 [ 0  0  0  4 24  0]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.24      0.40      0.30        10
          A2       0.50      0.37      0.43        43
          B1       0.66      0.63      0.64        70
          B2       0.68      0.59      0.63        54
          C1       0.56      0.86      0.68        28
          C2       0.00      0.00      0.00         1

    accuracy                           0.58       206
   macro avg       0.44      0.48      0.45       206
weighted avg       0.59      0.58      0.58       206


Fold 2
[[ 4  5  1  0  0  0]
 [ 4 20 16  3  0  0]
 [ 0  9 47 13  1  0]
 [ 0  1  8 29 16  0]
 [ 0  0  0  3 25  0]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.50      0.40      0.44        10
          A2       0.57      0.47      0.51        43
          B1       0.65      0.67      0.66        70
          B2       0.60      0.54      0.57        54
          C1       0.58      0.89      0.70        28
          C2       0.00      0.00      0.00         1

    accuracy                           0.61       206
   macro avg       0.48      0.49      0.48       206
weighted avg       0.60      0.61      0.60       206


Fold 3
[[ 3  6  1  0  0  0]
 [ 3 23 13  3  0  0]
 [ 3  9 52  6  0  0]
 [ 0  0  6 33 15  0]
 [ 0  0  0  4 23  0]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.33      0.30      0.32        10
          A2       0.61      0.55      0.57        42
          B1       0.72      0.74      0.73        70
          B2       0.72      0.61      0.66        54
          C1       0.59      0.85      0.70        27
          C2       0.00      0.00      0.00         1

    accuracy                           0.66       204
   macro avg       0.49      0.51      0.50       204
weighted avg       0.66      0.66      0.65       204


Fold 4
[[ 3  5  2  0  0  0]
 [ 2 22 15  3  0  0]
 [ 1 12 47  9  0  0]
 [ 0  0  9 32 13  0]
 [ 0  0  0  8 19  0]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.50      0.30      0.37        10
          A2       0.56      0.52      0.54        42
          B1       0.64      0.68      0.66        69
          B2       0.62      0.59      0.60        54
          C1       0.58      0.70      0.63        27
          C2       0.00      0.00      0.00         1

    accuracy                           0.61       203
   macro avg       0.48      0.47      0.47       203
weighted avg       0.60      0.61      0.60       203


K-fold scores
[0.6747347828779223, 0.579711322942872, 0.5983395479458092, 0.6521258930824839, 0.6007125356539341]
SKF f1 score mean 0.6211248165006042

LogisticRegression(C=1.0, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='multinomial', n_jobs=None,
                   penalty='l2', random_state=1234, solver='lbfgs', tol=0.0001,
                   verbose=0, warm_start=False)
Fold 0
[[ 8  2  0  0  0  0]
 [10 24  8  1  0  0]
 [ 6 22 39  3  0  0]
 [ 0  2  7 37  8  1]
 [ 1  0  1  6 19  1]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.32      0.80      0.46        10
          A2       0.48      0.56      0.52        43
          B1       0.71      0.56      0.62        70
          B2       0.79      0.67      0.73        55
          C1       0.68      0.68      0.68        28
          C2       0.00      0.00      0.00         1

    accuracy                           0.61       207
   macro avg       0.50      0.54      0.50       207
weighted avg       0.66      0.61      0.62       207


Fold 1
[[ 4  4  2  0  0  0]
 [24  7  9  3  0  0]
 [10 15 37  6  2  0]
 [ 1  0  7 30 13  3]
 [ 0  0  1  5 15  7]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.10      0.40      0.16        10
          A2       0.27      0.16      0.20        43
          B1       0.66      0.53      0.59        70
          B2       0.68      0.56      0.61        54
          C1       0.48      0.54      0.51        28
          C2       0.00      0.00      0.00         1

    accuracy                           0.45       206
   macro avg       0.37      0.36      0.35       206
weighted avg       0.53      0.45      0.48       206


Fold 2
[[ 7  3  0  0  0  0]
 [13 16 11  3  0  0]
 [ 3 18 36 13  0  0]
 [ 2  2  6 29 13  2]
 [ 0  0  0  7 16  5]
 [ 0  0  0  0  0  1]]
              precision    recall  f1-score   support

          A1       0.28      0.70      0.40        10
          A2       0.41      0.37      0.39        43
          B1       0.68      0.51      0.59        70
          B2       0.56      0.54      0.55        54
          C1       0.55      0.57      0.56        28
          C2       0.12      1.00      0.22         1

    accuracy                           0.51       206
   macro avg       0.43      0.62      0.45       206
weighted avg       0.55      0.51      0.52       206


Fold 3
[[ 8  1  0  1  0  0]
 [17 15  8  2  0  0]
 [10 10 46  4  0  0]
 [ 1  0  5 34 12  2]
 [ 0  0  0  7 13  7]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.22      0.80      0.35        10
          A2       0.58      0.36      0.44        42
          B1       0.78      0.66      0.71        70
          B2       0.71      0.63      0.67        54
          C1       0.50      0.48      0.49        27
          C2       0.00      0.00      0.00         1

    accuracy                           0.57       204
   macro avg       0.46      0.49      0.44       204
weighted avg       0.65      0.57      0.59       204


Fold 4
[[ 5  4  1  0  0  0]
 [14 17 10  1  0  0]
 [ 8 12 38 10  1  0]
 [ 0  1  7 32 12  2]
 [ 0  0  0  9 16  2]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.19      0.50      0.27        10
          A2       0.50      0.40      0.45        42
          B1       0.68      0.55      0.61        69
          B2       0.62      0.59      0.60        54
          C1       0.53      0.59      0.56        27
          C2       0.00      0.00      0.00         1

    accuracy                           0.53       203
   macro avg       0.42      0.44      0.42       203
weighted avg       0.58      0.53      0.55       203


K-fold scores
[0.6248644335402853, 0.47945104115963183, 0.5206057662142362, 0.5939972366337943, 0.5478120428998079]
SKF f1 score mean 0.553346104089551

************for dimension:  Vocabularycontrol  ***************
Printing class statistics
Counter({'B1': 319, 'B2': 278, 'A2': 259, 'C1': 82, 'A1': 77, 'C2': 11})
RandomForestClassifier(bootstrap=True, class_weight='balanced',
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, min_impurity_decrease=0.0,
                       min_impurity_split=None, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=None, oob_score=False,
                       random_state=1234, verbose=0, warm_start=False)
Fold 0
[[ 2 12  2  0  0  0]
 [ 0 35 17  0  0  0]
 [ 0 17 37 10  0  0]
 [ 0  2 11 43  0  0]
 [ 0  0  1 15  1  0]
 [ 0  0  1  2  0  0]]
              precision    recall  f1-score   support

          A1       1.00      0.12      0.22        16
          A2       0.53      0.67      0.59        52
          B1       0.54      0.58      0.56        64
          B2       0.61      0.77      0.68        56
          C1       1.00      0.06      0.11        17
          C2       0.00      0.00      0.00         3

    accuracy                           0.57       208
   macro avg       0.61      0.37      0.36       208
weighted avg       0.62      0.57      0.53       208


Fold 1
[[ 1 11  3  1  0  0]
 [ 0 33 19  0  0  0]
 [ 0 17 41  6  0  0]
 [ 0  1  9 46  0  0]
 [ 0  0  2 15  0  0]
 [ 0  0  0  2  0  0]]
              precision    recall  f1-score   support

          A1       1.00      0.06      0.12        16
          A2       0.53      0.63      0.58        52
          B1       0.55      0.64      0.59        64
          B2       0.66      0.82      0.73        56
          C1       0.00      0.00      0.00        17
          C2       0.00      0.00      0.00         2

    accuracy                           0.58       207
   macro avg       0.46      0.36      0.34       207
weighted avg       0.56      0.58      0.54       207


Fold 2
[[ 0 14  1  0  0  0]
 [ 0 37 13  2  0  0]
 [ 0 18 32 14  0  0]
 [ 0  1 11 44  0  0]
 [ 0  0  1 14  1  0]
 [ 0  0  0  2  0  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        15
          A2       0.53      0.71      0.61        52
          B1       0.55      0.50      0.52        64
          B2       0.58      0.79      0.67        56
          C1       1.00      0.06      0.12        16
          C2       0.00      0.00      0.00         2

    accuracy                           0.56       205
   macro avg       0.44      0.34      0.32       205
weighted avg       0.54      0.56      0.51       205


Fold 3
[[ 2 11  2  0  0  0]
 [ 3 36 13  0  0  0]
 [ 0 20 22 22  0  0]
 [ 0  3 12 40  0  0]
 [ 0  0  1 15  0  0]
 [ 0  0  0  2  0  0]]
              precision    recall  f1-score   support

          A1       0.40      0.13      0.20        15
          A2       0.51      0.69      0.59        52
          B1       0.44      0.34      0.39        64
          B2       0.51      0.73      0.60        55
          C1       0.00      0.00      0.00        16
          C2       0.00      0.00      0.00         2

    accuracy                           0.49       204
   macro avg       0.31      0.32      0.30       204
weighted avg       0.44      0.49      0.45       204


Fold 4
[[ 4  9  2  0  0  0]
 [ 0 32 19  0  0  0]
 [ 0 14 35 14  0  0]
 [ 0  1 12 42  0  0]
 [ 0  0  1 15  0  0]
 [ 0  0  0  2  0  0]]
              precision    recall  f1-score   support

          A1       1.00      0.27      0.42        15
          A2       0.57      0.63      0.60        51
          B1       0.51      0.56      0.53        63
          B2       0.58      0.76      0.66        55
          C1       0.00      0.00      0.00        16
          C2       0.00      0.00      0.00         2

    accuracy                           0.56       202
   macro avg       0.44      0.37      0.37       202
weighted avg       0.53      0.56      0.53       202


K-fold scores
[0.5294382060104629, 0.5357753164019636, 0.5089289774286364, 0.44718676407672175, 0.5263529865345118]
SKF f1 score mean 0.5095364500904592

LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
          verbose=0)
Fold 0
[[ 7  9  0  0  0  0]
 [ 9 33  9  1  0  0]
 [ 2 23 24 15  0  0]
 [ 0  4  7 39  6  0]
 [ 0  0  0 10  7  0]
 [ 0  0  0  3  0  0]]
              precision    recall  f1-score   support

          A1       0.39      0.44      0.41        16
          A2       0.48      0.63      0.55        52
          B1       0.60      0.38      0.46        64
          B2       0.57      0.70      0.63        56
          C1       0.54      0.41      0.47        17
          C2       0.00      0.00      0.00         3

    accuracy                           0.53       208
   macro avg       0.43      0.43      0.42       208
weighted avg       0.53      0.53      0.52       208


Fold 1
[[ 8  5  2  1  0  0]
 [ 7 30 13  2  0  0]
 [ 3 16 34  8  1  2]
 [ 0  4  5 38  5  4]
 [ 0  0  1 13  2  1]
 [ 0  0  0  2  0  0]]
              precision    recall  f1-score   support

          A1       0.44      0.50      0.47        16
          A2       0.55      0.58      0.56        52
          B1       0.62      0.53      0.57        64
          B2       0.59      0.68      0.63        56
          C1       0.25      0.12      0.16        17
          C2       0.00      0.00      0.00         2

    accuracy                           0.54       207
   macro avg       0.41      0.40      0.40       207
weighted avg       0.54      0.54      0.54       207


Fold 2
[[ 3 12  0  0  0  0]
 [ 9 31 10  1  0  1]
 [ 3 18 29  8  2  4]
 [ 1  3  7 26 12  7]
 [ 0  0  0  6  9  1]
 [ 0  0  0  0  2  0]]
              precision    recall  f1-score   support

          A1       0.19      0.20      0.19        15
          A2       0.48      0.60      0.53        52
          B1       0.63      0.45      0.53        64
          B2       0.63      0.46      0.54        56
          C1       0.36      0.56      0.44        16
          C2       0.00      0.00      0.00         2

    accuracy                           0.48       205
   macro avg       0.38      0.38      0.37       205
weighted avg       0.53      0.48      0.50       205


Fold 3
[[ 4  9  2  0  0  0]
 [11 32  9  0  0  0]
 [ 0 23 18 18  0  5]
 [ 0  1  9 33  6  6]
 [ 0  0  0  7  8  1]
 [ 0  0  0  2  0  0]]
              precision    recall  f1-score   support

          A1       0.27      0.27      0.27        15
          A2       0.49      0.62      0.55        52
          B1       0.47      0.28      0.35        64
          B2       0.55      0.60      0.57        55
          C1       0.57      0.50      0.53        16
          C2       0.00      0.00      0.00         2

    accuracy                           0.47       204
   macro avg       0.39      0.38      0.38       204
weighted avg       0.49      0.47      0.47       204


Fold 4
[[10  3  2  0  0  0]
 [ 3 29 18  1  0  0]
 [ 2 15 30 11  0  5]
 [ 0  2  5 26 11 11]
 [ 0  0  0  6  8  2]
 [ 0  0  0  1  0  1]]
              precision    recall  f1-score   support

          A1       0.67      0.67      0.67        15
          A2       0.59      0.57      0.58        51
          B1       0.55      0.48      0.51        63
          B2       0.58      0.47      0.52        55
          C1       0.42      0.50      0.46        16
          C2       0.05      0.50      0.10         2

    accuracy                           0.51       202
   macro avg       0.48      0.53      0.47       202
weighted avg       0.56      0.51      0.53       202


K-fold scores
[0.5175455431786624, 0.5383883357848986, 0.49505752488188043, 0.4663295610941165, 0.5332606941081517]
SKF f1 score mean 0.510116331809542

LogisticRegression(C=1.0, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='multinomial', n_jobs=None,
                   penalty='l2', random_state=1234, solver='lbfgs', tol=0.0001,
                   verbose=0, warm_start=False)
Fold 0
[[ 8  7  1  0  0  0]
 [21 22  8  0  0  1]
 [ 7 27 16  1  0 13]
 [ 1  5  9  5 18 18]
 [ 0  1  0  2  9  5]
 [ 0  1  0  0  0  2]]
              precision    recall  f1-score   support

          A1       0.22      0.50      0.30        16
          A2       0.35      0.42      0.38        52
          B1       0.47      0.25      0.33        64
          B2       0.62      0.09      0.16        56
          C1       0.33      0.53      0.41        17
          C2       0.05      0.67      0.10         3

    accuracy                           0.30       208
   macro avg       0.34      0.41      0.28       208
weighted avg       0.44      0.30      0.30       208


Fold 1
[[10  4  1  0  0  1]
 [19 22  9  0  0  2]
 [ 8 18 26  3  2  7]
 [ 0  7  2  6 17 24]
 [ 0  0  1  1 10  5]
 [ 0  0  0  0  0  2]]
              precision    recall  f1-score   support

          A1       0.27      0.62      0.38        16
          A2       0.43      0.42      0.43        52
          B1       0.67      0.41      0.50        64
          B2       0.60      0.11      0.18        56
          C1       0.34      0.59      0.43        17
          C2       0.05      1.00      0.09         2

    accuracy                           0.37       207
   macro avg       0.39      0.52      0.34       207
weighted avg       0.53      0.37      0.38       207


Fold 2
[[13  2  0  0  0  0]
 [21 21  5  0  0  5]
 [ 4 22 23  3  2 10]
 [ 1  6  4  2 25 18]
 [ 0  0  0  1 13  2]
 [ 0  0  0  0  2  0]]
              precision    recall  f1-score   support

          A1       0.33      0.87      0.48        15
          A2       0.41      0.40      0.41        52
          B1       0.72      0.36      0.48        64
          B2       0.33      0.04      0.06        56
          C1       0.31      0.81      0.45        16
          C2       0.00      0.00      0.00         2

    accuracy                           0.35       205
   macro avg       0.35      0.41      0.31       205
weighted avg       0.47      0.35      0.34       205


Fold 3
[[14  0  1  0  0  0]
 [25 23  4  0  0  0]
 [ 3 25 14  0  1 21]
 [ 0  2  8  3 18 24]
 [ 0  2  0  0 10  4]
 [ 0  0  0  0  0  2]]
              precision    recall  f1-score   support

          A1       0.33      0.93      0.49        15
          A2       0.44      0.44      0.44        52
          B1       0.52      0.22      0.31        64
          B2       1.00      0.05      0.10        55
          C1       0.34      0.62      0.44        16
          C2       0.04      1.00      0.08         2

    accuracy                           0.32       204
   macro avg       0.45      0.55      0.31       204
weighted avg       0.60      0.32      0.31       204


Fold 4
[[11  2  2  0  0  0]
 [17 20 12  0  0  2]
 [ 9 14 24  2  5  9]
 [ 0  2  5  4 22 22]
 [ 0  0  0  1 13  2]
 [ 0  0  0  0  1  1]]
              precision    recall  f1-score   support

          A1       0.30      0.73      0.42        15
          A2       0.53      0.39      0.45        51
          B1       0.56      0.38      0.45        63
          B2       0.57      0.07      0.13        55
          C1       0.32      0.81      0.46        16
          C2       0.03      0.50      0.05         2

    accuracy                           0.36       202
   macro avg       0.38      0.48      0.33       202
weighted avg       0.51      0.36      0.36       202


K-fold scores
[0.296221441236017, 0.378363172632797, 0.3408687287948508, 0.3088845020818166, 0.3579014208565903]
SKF f1 score mean 0.33644785312041436

************for dimension:  CoherenceCohesion  ***************
Printing class statistics
Counter({'B1': 356, 'B2': 269, 'A2': 227, 'C1': 85, 'A1': 84, 'C2': 5})
RandomForestClassifier(bootstrap=True, class_weight='balanced',
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, min_impurity_decrease=0.0,
                       min_impurity_split=None, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=None, oob_score=False,
                       random_state=1234, verbose=0, warm_start=False)
Fold 0
[[ 2 14  1  0  0  0]
 [ 1 21 24  0  0  0]
 [ 0  8 49 15  0  0]
 [ 0  0 13 41  0  0]
 [ 0  0  2 15  0  0]
 [ 0  0  0  1  0  0]]
              precision    recall  f1-score   support

          A1       0.67      0.12      0.20        17
          A2       0.49      0.46      0.47        46
          B1       0.55      0.68      0.61        72
          B2       0.57      0.76      0.65        54
          C1       0.00      0.00      0.00        17
          C2       0.00      0.00      0.00         1

    accuracy                           0.55       207
   macro avg       0.38      0.34      0.32       207
weighted avg       0.50      0.55      0.50       207


Fold 1
[[ 4  9  4  0  0  0]
 [ 0 21 25  0  0  0]
 [ 1 14 49  7  0  0]
 [ 0  1 11 41  1  0]
 [ 0  0  1 16  0  0]
 [ 0  0  0  1  0  0]]
              precision    recall  f1-score   support

          A1       0.80      0.24      0.36        17
          A2       0.47      0.46      0.46        46
          B1       0.54      0.69      0.61        71
          B2       0.63      0.76      0.69        54
          C1       0.00      0.00      0.00        17
          C2       0.00      0.00      0.00         1

    accuracy                           0.56       206
   macro avg       0.41      0.36      0.35       206
weighted avg       0.52      0.56      0.52       206


Fold 2
[[ 3 11  3  0  0  0]
 [ 1 29 15  0  0  0]
 [ 0 11 55  5  0  0]
 [ 0  1 13 40  0  0]
 [ 0  0  0 17  0  0]
 [ 0  0  0  1  0  0]]
              precision    recall  f1-score   support

          A1       0.75      0.18      0.29        17
          A2       0.56      0.64      0.60        45
          B1       0.64      0.77      0.70        71
          B2       0.63      0.74      0.68        54
          C1       0.00      0.00      0.00        17
          C2       0.00      0.00      0.00         1

    accuracy                           0.62       205
   macro avg       0.43      0.39      0.38       205
weighted avg       0.57      0.62      0.58       205


Fold 3
[[ 3 12  2  0  0  0]
 [ 1 25 19  0  0  0]
 [ 0  9 45 17  0  0]
 [ 0  0  9 44  1  0]
 [ 0  0  1 16  0  0]
 [ 0  0  0  1  0  0]]
              precision    recall  f1-score   support

          A1       0.75      0.18      0.29        17
          A2       0.54      0.56      0.55        45
          B1       0.59      0.63      0.61        71
          B2       0.56      0.81      0.67        54
          C1       0.00      0.00      0.00        17
          C2       0.00      0.00      0.00         1

    accuracy                           0.57       205
   macro avg       0.41      0.36      0.35       205
weighted avg       0.54      0.57      0.53       205


Fold 4
[[ 1 10  5  0  0  0]
 [ 2 17 26  0  0  0]
 [ 0 10 49 12  0  0]
 [ 0  0  9 41  3  0]
 [ 0  0  0 17  0  0]
 [ 0  0  0  1  0  0]]
              precision    recall  f1-score   support

          A1       0.33      0.06      0.11        16
          A2       0.46      0.38      0.41        45
          B1       0.55      0.69      0.61        71
          B2       0.58      0.77      0.66        53
          C1       0.00      0.00      0.00        17
          C2       0.00      0.00      0.00         1

    accuracy                           0.53       203
   macro avg       0.32      0.32      0.30       203
weighted avg       0.47      0.53      0.49       203


K-fold scores
[0.5027865182025034, 0.523495450245382, 0.5777202888048851, 0.5319600260366811, 0.48708686802194995]
SKF f1 score mean 0.5246098302622804

LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
          verbose=0)
Fold 0
[[ 5 12  0  0  0  0]
 [ 8 18 20  0  0  0]
 [ 0 12 41 18  1  0]
 [ 0  0  6 30 18  0]
 [ 0  0  0  8  9  0]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.38      0.29      0.33        17
          A2       0.43      0.39      0.41        46
          B1       0.61      0.57      0.59        72
          B2       0.54      0.56      0.55        54
          C1       0.31      0.53      0.39        17
          C2       0.00      0.00      0.00         1

    accuracy                           0.50       207
   macro avg       0.38      0.39      0.38       207
weighted avg       0.50      0.50      0.50       207


Fold 1
[[ 7  9  1  0  0  0]
 [ 7 26 13  0  0  0]
 [ 2 18 40 11  0  0]
 [ 0  2  6 40  6  0]
 [ 0  0  0 14  3  0]
 [ 0  0  0  1  0  0]]
              precision    recall  f1-score   support

          A1       0.44      0.41      0.42        17
          A2       0.47      0.57      0.51        46
          B1       0.67      0.56      0.61        71
          B2       0.61      0.74      0.67        54
          C1       0.33      0.18      0.23        17
          C2       0.00      0.00      0.00         1

    accuracy                           0.56       206
   macro avg       0.42      0.41      0.41       206
weighted avg       0.56      0.56      0.55       206


Fold 2
[[ 6 10  1  0  0  0]
 [ 7 23 14  1  0  0]
 [ 1 17 43 10  0  0]
 [ 1  1  6 40  6  0]
 [ 0  0  0 13  4  0]
 [ 0  0  0  1  0  0]]
              precision    recall  f1-score   support

          A1       0.40      0.35      0.38        17
          A2       0.45      0.51      0.48        45
          B1       0.67      0.61      0.64        71
          B2       0.62      0.74      0.67        54
          C1       0.40      0.24      0.30        17
          C2       0.00      0.00      0.00         1

    accuracy                           0.57       205
   macro avg       0.42      0.41      0.41       205
weighted avg       0.56      0.57      0.56       205


Fold 3
[[ 9  6  2  0  0  0]
 [ 8 22 12  3  0  0]
 [ 2 12 35 22  0  0]
 [ 0  0  9 33 12  0]
 [ 0  0  1 10  6  0]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.47      0.53      0.50        17
          A2       0.55      0.49      0.52        45
          B1       0.59      0.49      0.54        71
          B2       0.49      0.61      0.54        54
          C1       0.32      0.35      0.33        17
          C2       0.00      0.00      0.00         1

    accuracy                           0.51       205
   macro avg       0.40      0.41      0.41       205
weighted avg       0.52      0.51      0.51       205


Fold 4
[[ 6  5  5  0  0  0]
 [ 9 19 15  2  0  0]
 [ 3  7 41 20  0  0]
 [ 0  2  5 34 12  0]
 [ 0  0  0 14  3  0]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.33      0.38      0.35        16
          A2       0.58      0.42      0.49        45
          B1       0.62      0.58      0.60        71
          B2       0.49      0.64      0.55        53
          C1       0.19      0.18      0.18        17
          C2       0.00      0.00      0.00         1

    accuracy                           0.51       203
   macro avg       0.37      0.37      0.36       203
weighted avg       0.51      0.51      0.50       203


K-fold scores
[0.4979052560208807, 0.5542579858154564, 0.5585692081710733, 0.5117300892614296, 0.5047202374906848]
SKF f1 score mean 0.5254365553519049

LogisticRegression(C=1.0, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='multinomial', n_jobs=None,
                   penalty='l2', random_state=1234, solver='lbfgs', tol=0.0001,
                   verbose=0, warm_start=False)
Fold 0
[[11  5  1  0  0  0]
 [17 16 13  0  0  0]
 [ 5 20 35 10  2  0]
 [ 0  1 18 13 20  2]
 [ 0  0  2  5  7  3]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.33      0.65      0.44        17
          A2       0.38      0.35      0.36        46
          B1       0.51      0.49      0.50        72
          B2       0.46      0.24      0.32        54
          C1       0.23      0.41      0.30        17
          C2       0.00      0.00      0.00         1

    accuracy                           0.40       207
   macro avg       0.32      0.36      0.32       207
weighted avg       0.43      0.40      0.40       207


Fold 1
[[14  2  1  0  0  0]
 [20 16 10  0  0  0]
 [10 22 30  8  1  0]
 [ 1  1 20 12 18  2]
 [ 0  0  3  1  8  5]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.31      0.82      0.45        17
          A2       0.39      0.35      0.37        46
          B1       0.47      0.42      0.44        71
          B2       0.57      0.22      0.32        54
          C1       0.29      0.47      0.36        17
          C2       0.00      0.00      0.00         1

    accuracy                           0.39       206
   macro avg       0.34      0.38      0.32       206
weighted avg       0.45      0.39      0.39       206


Fold 2
[[14  3  0  0  0  0]
 [27 11  7  0  0  0]
 [ 8 26 33  3  1  0]
 [ 2  3 18 14 12  5]
 [ 0  0  2  1 11  3]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.27      0.82      0.41        17
          A2       0.26      0.24      0.25        45
          B1       0.55      0.46      0.50        71
          B2       0.78      0.26      0.39        54
          C1       0.44      0.65      0.52        17
          C2       0.00      0.00      0.00         1

    accuracy                           0.40       205
   macro avg       0.38      0.41      0.35       205
weighted avg       0.51      0.40      0.41       205


Fold 3
[[10  6  1  0  0  0]
 [26 13  5  1  0  0]
 [10 24 27  9  1  0]
 [ 0  3 11 20 17  3]
 [ 0  0  1  5 11  0]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.22      0.59      0.32        17
          A2       0.28      0.29      0.29        45
          B1       0.60      0.38      0.47        71
          B2       0.57      0.37      0.45        54
          C1       0.37      0.65      0.47        17
          C2       0.00      0.00      0.00         1

    accuracy                           0.40       205
   macro avg       0.34      0.38      0.33       205
weighted avg       0.47      0.40      0.41       205


Fold 4
[[10  2  4  0  0  0]
 [19 12 14  0  0  0]
 [ 6 13 41  9  1  1]
 [ 0  4 14 14 18  3]
 [ 0  0  4  4  8  1]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.29      0.62      0.39        16
          A2       0.39      0.27      0.32        45
          B1       0.53      0.58      0.55        71
          B2       0.52      0.26      0.35        53
          C1       0.29      0.47      0.36        17
          C2       0.00      0.00      0.00         1

    accuracy                           0.42       203
   macro avg       0.33      0.37      0.33       203
weighted avg       0.45      0.42      0.42       203


K-fold scores
[0.3968006501694821, 0.38581048342098917, 0.40939392327402, 0.4074770835207719, 0.41584885912311986]
SKF f1 score mean 0.40306619990167664

************for dimension:  Sociolinguisticappropriateness  ***************
Printing class statistics
Counter({'B2': 346, 'B1': 299, 'A2': 258, 'C1': 69, 'A1': 54})
RandomForestClassifier(bootstrap=True, class_weight='balanced',
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, min_impurity_decrease=0.0,
                       min_impurity_split=None, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=None, oob_score=False,
                       random_state=1234, verbose=0, warm_start=False)
Fold 0
[[ 1 10  0  0  0]
 [ 0 40 11  1  0]
 [ 0 15 23 22  0]
 [ 0  2 14 54  0]
 [ 0  0  0 14  0]]
              precision    recall  f1-score   support

          A1       1.00      0.09      0.17        11
          A2       0.60      0.77      0.67        52
          B1       0.48      0.38      0.43        60
          B2       0.59      0.77      0.67        70
          C1       0.00      0.00      0.00        14

    accuracy                           0.57       207
   macro avg       0.53      0.40      0.39       207
weighted avg       0.54      0.57      0.53       207


Fold 1
[[ 0  9  2  0  0]
 [ 0 31 19  2  0]
 [ 0 17 33 10  0]
 [ 0  0 16 53  0]
 [ 0  0  0 14  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        11
          A2       0.54      0.60      0.57        52
          B1       0.47      0.55      0.51        60
          B2       0.67      0.77      0.72        69
          C1       0.00      0.00      0.00        14

    accuracy                           0.57       206
   macro avg       0.34      0.38      0.36       206
weighted avg       0.50      0.57      0.53       206


Fold 2
[[ 0 11  0  0  0]
 [ 0 42  9  1  0]
 [ 0 20 26 14  0]
 [ 0  2 16 49  2]
 [ 0  0  0 12  2]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        11
          A2       0.56      0.81      0.66        52
          B1       0.51      0.43      0.47        60
          B2       0.64      0.71      0.68        69
          C1       0.50      0.14      0.22        14

    accuracy                           0.58       206
   macro avg       0.44      0.42      0.41       206
weighted avg       0.54      0.58      0.54       206


Fold 3
[[ 0  8  1  2  0]
 [ 0 33 18  0  0]
 [ 0 11 29 20  0]
 [ 0  3 20 46  0]
 [ 0  0  0 14  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        11
          A2       0.60      0.65      0.62        51
          B1       0.43      0.48      0.45        60
          B2       0.56      0.67      0.61        69
          C1       0.00      0.00      0.00        14

    accuracy                           0.53       205
   macro avg       0.32      0.36      0.34       205
weighted avg       0.46      0.53      0.49       205


Fold 4
[[ 0  8  2  0  0]
 [ 0 38 11  2  0]
 [ 0 19 27 13  0]
 [ 0  2  8 59  0]
 [ 0  0  1 12  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        10
          A2       0.57      0.75      0.64        51
          B1       0.55      0.46      0.50        59
          B2       0.69      0.86      0.76        69
          C1       0.00      0.00      0.00        13

    accuracy                           0.61       202
   macro avg       0.36      0.41      0.38       202
weighted avg       0.54      0.61      0.57       202


K-fold scores
[0.5280357189434621, 0.5313516457855997, 0.5448903046856383, 0.49259488819741376, 0.5686954944811047]
SKF f1 score mean 0.5331136104186436

LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
          verbose=0)
Fold 0
[[ 4  7  0  0  0]
 [ 6 37  9  0  0]
 [ 0 19 19 20  2]
 [ 0  4 15 46  5]
 [ 0  0  0 13  1]]
              precision    recall  f1-score   support

          A1       0.40      0.36      0.38        11
          A2       0.55      0.71      0.62        52
          B1       0.44      0.32      0.37        60
          B2       0.58      0.66      0.62        70
          C1       0.12      0.07      0.09        14

    accuracy                           0.52       207
   macro avg       0.42      0.42      0.42       207
weighted avg       0.49      0.52      0.50       207


Fold 1
[[ 1 10  0  0  0]
 [ 3 36 12  1  0]
 [ 2 22 26 10  0]
 [ 0  5 11 52  1]
 [ 0  0  0  8  6]]
              precision    recall  f1-score   support

          A1       0.17      0.09      0.12        11
          A2       0.49      0.69      0.58        52
          B1       0.53      0.43      0.48        60
          B2       0.73      0.75      0.74        69
          C1       0.86      0.43      0.57        14

    accuracy                           0.59       206
   macro avg       0.56      0.48      0.50       206
weighted avg       0.59      0.59      0.58       206


Fold 2
[[ 0 11  0  0  0]
 [ 2 42  8  0  0]
 [ 2 24 19 15  0]
 [ 0  4 14 43  8]
 [ 0  0  0 10  4]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        11
          A2       0.52      0.81      0.63        52
          B1       0.46      0.32      0.38        60
          B2       0.63      0.62      0.63        69
          C1       0.33      0.29      0.31        14

    accuracy                           0.52       206
   macro avg       0.39      0.41      0.39       206
weighted avg       0.50      0.52      0.50       206


Fold 3
[[ 2  6  2  1  0]
 [ 2 36 11  2  0]
 [ 0 20 18 22  0]
 [ 0  8 13 46  2]
 [ 0  0  0 12  2]]
              precision    recall  f1-score   support

          A1       0.50      0.18      0.27        11
          A2       0.51      0.71      0.60        51
          B1       0.41      0.30      0.35        60
          B2       0.55      0.67      0.61        69
          C1       0.50      0.14      0.22        14

    accuracy                           0.51       205
   macro avg       0.50      0.40      0.41       205
weighted avg       0.50      0.51      0.48       205


Fold 4
[[ 3  3  4  0  0]
 [ 3 42  5  1  0]
 [ 0 30 17 11  1]
 [ 0  2  9 48 10]
 [ 0  0  0  9  4]]
              precision    recall  f1-score   support

          A1       0.50      0.30      0.37        10
          A2       0.55      0.82      0.66        51
          B1       0.49      0.29      0.36        59
          B2       0.70      0.70      0.70        69
          C1       0.27      0.31      0.29        13

    accuracy                           0.56       202
   macro avg       0.50      0.48      0.47       202
weighted avg       0.56      0.56      0.55       202


K-fold scores
[0.4983417234644888, 0.5782869597825769, 0.5001840951928712, 0.48255580754355404, 0.5459082239910921]
SKF f1 score mean 0.5210553619949165

LogisticRegression(C=1.0, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='multinomial', n_jobs=None,
                   penalty='l2', random_state=1234, solver='lbfgs', tol=0.0001,
                   verbose=0, warm_start=False)
Fold 0
[[ 7  4  0  0  0]
 [19 23  9  1  0]
 [ 3 20 19 13  5]
 [ 0  8 20 23 19]
 [ 0  0  2  4  8]]
              precision    recall  f1-score   support

          A1       0.24      0.64      0.35        11
          A2       0.42      0.44      0.43        52
          B1       0.38      0.32      0.35        60
          B2       0.56      0.33      0.41        70
          C1       0.25      0.57      0.35        14

    accuracy                           0.39       207
   macro avg       0.37      0.46      0.38       207
weighted avg       0.43      0.39      0.39       207


Fold 1
[[ 6  5  0  0  0]
 [13 25 14  0  0]
 [ 6 21 29  3  1]
 [ 0  9 21 18 21]
 [ 0  0  2  3  9]]
              precision    recall  f1-score   support

          A1       0.24      0.55      0.33        11
          A2       0.42      0.48      0.45        52
          B1       0.44      0.48      0.46        60
          B2       0.75      0.26      0.39        69
          C1       0.29      0.64      0.40        14

    accuracy                           0.42       206
   macro avg       0.43      0.48      0.41       206
weighted avg       0.52      0.42      0.42       206


Fold 2
[[ 8  3  0  0  0]
 [14 29  8  1  0]
 [10 16 21  7  6]
 [ 1  6 20 19 23]
 [ 0  0  2  6  6]]
              precision    recall  f1-score   support

          A1       0.24      0.73      0.36        11
          A2       0.54      0.56      0.55        52
          B1       0.41      0.35      0.38        60
          B2       0.58      0.28      0.37        69
          C1       0.17      0.43      0.24        14

    accuracy                           0.40       206
   macro avg       0.39      0.47      0.38       206
weighted avg       0.47      0.40      0.41       206


Fold 3
[[ 8  0  1  2  0]
 [19 20 11  1  0]
 [ 3 19 24 10  4]
 [ 1 10 22 18 18]
 [ 0  0  1  3 10]]
              precision    recall  f1-score   support

          A1       0.26      0.73      0.38        11
          A2       0.41      0.39      0.40        51
          B1       0.41      0.40      0.40        60
          B2       0.53      0.26      0.35        69
          C1       0.31      0.71      0.43        14

    accuracy                           0.39       205
   macro avg       0.38      0.50      0.39       205
weighted avg       0.43      0.39      0.39       205


Fold 4
[[ 6  3  1  0  0]
 [25 21  4  1  0]
 [ 6 25 21  6  1]
 [ 0  4 15 21 29]
 [ 0  0  1  2 10]]
              precision    recall  f1-score   support

          A1       0.16      0.60      0.26        10
          A2       0.40      0.41      0.40        51
          B1       0.50      0.36      0.42        59
          B2       0.70      0.30      0.42        69
          C1       0.25      0.77      0.38        13

    accuracy                           0.39       202
   macro avg       0.40      0.49      0.38       202
weighted avg       0.51      0.39      0.41       202


K-fold scores
[0.3903912422250673, 0.42140620106482923, 0.4091746925868668, 0.38534447921391785, 0.4052593388660784]
SKF f1 score mean 0.4023151907913519

FOr lang:  IT
1024
************for dimension:  OverallCEFRrating  ***************
Printing class statistics
Counter({'B1': 392, 'A2': 380, 'A1': 28})
RandomForestClassifier(bootstrap=True, class_weight='balanced',
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, min_impurity_decrease=0.0,
                       min_impurity_split=None, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=None, oob_score=False,
                       random_state=1234, verbose=0, warm_start=False)
Fold 0
[[ 0  6  0]
 [ 0 69  7]
 [ 0 10 69]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         6
          A2       0.81      0.91      0.86        76
          B1       0.91      0.87      0.89        79

    accuracy                           0.86       161
   macro avg       0.57      0.59      0.58       161
weighted avg       0.83      0.86      0.84       161


Fold 1
[[ 0  6  0]
 [ 0 66 10]
 [ 0 11 68]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         6
          A2       0.80      0.87      0.83        76
          B1       0.87      0.86      0.87        79

    accuracy                           0.83       161
   macro avg       0.56      0.58      0.57       161
weighted avg       0.80      0.83      0.82       161


Fold 2
[[ 0  6  0]
 [ 0 71  5]
 [ 0 15 63]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         6
          A2       0.77      0.93      0.85        76
          B1       0.93      0.81      0.86        78

    accuracy                           0.84       160
   macro avg       0.57      0.58      0.57       160
weighted avg       0.82      0.84      0.82       160


Fold 3
[[ 0  5  0]
 [ 0 61 15]
 [ 0 12 66]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         5
          A2       0.78      0.80      0.79        76
          B1       0.81      0.85      0.83        78

    accuracy                           0.80       159
   macro avg       0.53      0.55      0.54       159
weighted avg       0.77      0.80      0.79       159


Fold 4
[[ 0  4  1]
 [ 0 62 14]
 [ 0  8 70]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         5
          A2       0.84      0.82      0.83        76
          B1       0.82      0.90      0.86        78

    accuracy                           0.83       159
   macro avg       0.55      0.57      0.56       159
weighted avg       0.80      0.83      0.82       159


K-fold scores
[0.8414803789678564, 0.8169407493276385, 0.8222072733202872, 0.7859277307479514, 0.8164813314298209]
SKF f1 score mean 0.8166074927587108

LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
          verbose=0)
Fold 0
[[ 0  6  0]
 [ 1 66  9]
 [ 0 12 67]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         6
          A2       0.79      0.87      0.82        76
          B1       0.88      0.85      0.86        79

    accuracy                           0.83       161
   macro avg       0.56      0.57      0.56       161
weighted avg       0.80      0.83      0.81       161


Fold 1
[[ 1  5  0]
 [ 0 62 14]
 [ 0 11 68]]
              precision    recall  f1-score   support

          A1       1.00      0.17      0.29         6
          A2       0.79      0.82      0.81        76
          B1       0.83      0.86      0.84        79

    accuracy                           0.81       161
   macro avg       0.87      0.61      0.65       161
weighted avg       0.82      0.81      0.81       161


Fold 2
[[ 0  6  0]
 [ 0 66 10]
 [ 0 16 62]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         6
          A2       0.75      0.87      0.80        76
          B1       0.86      0.79      0.83        78

    accuracy                           0.80       160
   macro avg       0.54      0.55      0.54       160
weighted avg       0.78      0.80      0.79       160


Fold 3
[[ 0  5  0]
 [ 0 60 16]
 [ 0 13 65]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         5
          A2       0.77      0.79      0.78        76
          B1       0.80      0.83      0.82        78

    accuracy                           0.79       159
   macro avg       0.52      0.54      0.53       159
weighted avg       0.76      0.79      0.77       159


Fold 4
[[ 0  4  1]
 [ 0 57 19]
 [ 0  8 70]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         5
          A2       0.83      0.75      0.79        76
          B1       0.78      0.90      0.83        78

    accuracy                           0.80       159
   macro avg       0.53      0.55      0.54       159
weighted avg       0.78      0.80      0.78       159


K-fold scores
[0.8136445602083751, 0.8052298767934739, 0.7853170731707317, 0.7735494599147145, 0.7846020386033399]
SKF f1 score mean 0.7924686017381269

LogisticRegression(C=1.0, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='multinomial', n_jobs=None,
                   penalty='l2', random_state=1234, solver='lbfgs', tol=0.0001,
                   verbose=0, warm_start=False)
Fold 0
[[ 3  3  0]
 [27 35 14]
 [ 2 11 66]]
              precision    recall  f1-score   support

          A1       0.09      0.50      0.16         6
          A2       0.71      0.46      0.56        76
          B1       0.82      0.84      0.83        79

    accuracy                           0.65       161
   macro avg       0.54      0.60      0.52       161
weighted avg       0.75      0.65      0.68       161


Fold 1
[[ 4  2  0]
 [25 36 15]
 [ 5 12 62]]
              precision    recall  f1-score   support

          A1       0.12      0.67      0.20         6
          A2       0.72      0.47      0.57        76
          B1       0.81      0.78      0.79        79

    accuracy                           0.63       161
   macro avg       0.55      0.64      0.52       161
weighted avg       0.74      0.63      0.67       161


Fold 2
[[ 5  0  1]
 [15 46 15]
 [ 1 16 61]]
              precision    recall  f1-score   support

          A1       0.24      0.83      0.37         6
          A2       0.74      0.61      0.67        76
          B1       0.79      0.78      0.79        78

    accuracy                           0.70       160
   macro avg       0.59      0.74      0.61       160
weighted avg       0.75      0.70      0.71       160


Fold 3
[[ 5  0  0]
 [22 36 18]
 [ 2 13 63]]
              precision    recall  f1-score   support

          A1       0.17      1.00      0.29         5
          A2       0.73      0.47      0.58        76
          B1       0.78      0.81      0.79        78

    accuracy                           0.65       159
   macro avg       0.56      0.76      0.55       159
weighted avg       0.74      0.65      0.67       159


Fold 4
[[ 2  2  1]
 [18 37 21]
 [ 0  7 71]]
              precision    recall  f1-score   support

          A1       0.10      0.40      0.16         5
          A2       0.80      0.49      0.61        76
          B1       0.76      0.91      0.83        78

    accuracy                           0.69       159
   macro avg       0.56      0.60      0.53       159
weighted avg       0.76      0.69      0.70       159


K-fold scores
[0.6775917644809316, 0.6672263554251132, 0.7142652329749104, 0.6733201823271138, 0.7023288709452774]
SKF f1 score mean 0.6869464812306691

************for dimension:  Grammaticalaccuracy  ***************
Printing class statistics
Counter({'B1': 376, 'A2': 242, 'B2': 111, 'A1': 71})
RandomForestClassifier(bootstrap=True, class_weight='balanced',
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, min_impurity_decrease=0.0,
                       min_impurity_split=None, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=None, oob_score=False,
                       random_state=1234, verbose=0, warm_start=False)
Fold 0
[[ 0 11  4  0]
 [ 0 28 21  0]
 [ 1 10 62  3]
 [ 0  0 22  1]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        15
          A2       0.57      0.57      0.57        49
          B1       0.57      0.82      0.67        76
          B2       0.25      0.04      0.07        23

    accuracy                           0.56       163
   macro avg       0.35      0.36      0.33       163
weighted avg       0.47      0.56      0.49       163


Fold 1
[[ 2 11  1  0]
 [ 0 31 18  0]
 [ 0 11 60  4]
 [ 0  0 21  1]]
              precision    recall  f1-score   support

          A1       1.00      0.14      0.25        14
          A2       0.58      0.63      0.61        49
          B1       0.60      0.80      0.69        75
          B2       0.20      0.05      0.07        22

    accuracy                           0.59       160
   macro avg       0.60      0.41      0.40       160
weighted avg       0.58      0.59      0.54       160


Fold 2
[[ 2 11  1  0]
 [ 1 22 25  0]
 [ 0 13 62  0]
 [ 0  0 20  2]]
              precision    recall  f1-score   support

          A1       0.67      0.14      0.24        14
          A2       0.48      0.46      0.47        48
          B1       0.57      0.83      0.68        75
          B2       1.00      0.09      0.17        22

    accuracy                           0.55       159
   macro avg       0.68      0.38      0.39       159
weighted avg       0.61      0.55      0.50       159


Fold 3
[[ 1 11  2  0]
 [ 0 26 22  0]
 [ 0 11 60  4]
 [ 0  0 22  0]]
              precision    recall  f1-score   support

          A1       1.00      0.07      0.13        14
          A2       0.54      0.54      0.54        48
          B1       0.57      0.80      0.66        75
          B2       0.00      0.00      0.00        22

    accuracy                           0.55       159
   macro avg       0.53      0.35      0.33       159
weighted avg       0.52      0.55      0.49       159


Fold 4
[[ 0 11  3  0]
 [ 2 28 18  0]
 [ 0  9 64  2]
 [ 0  0 22  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        14
          A2       0.58      0.58      0.58        48
          B1       0.60      0.85      0.70        75
          B2       0.00      0.00      0.00        22

    accuracy                           0.58       159
   macro avg       0.30      0.36      0.32       159
weighted avg       0.46      0.58      0.51       159


K-fold scores
[0.4947499646886151, 0.5396407173980704, 0.5047078084984655, 0.4879900853631699, 0.5078443569009606]
SKF f1 score mean 0.5069865865698564

LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
          verbose=0)
Fold 0
[[ 6  8  1  0]
 [ 7 22 20  0]
 [ 4 13 49 10]
 [ 0  1 13  9]]
              precision    recall  f1-score   support

          A1       0.35      0.40      0.38        15
          A2       0.50      0.45      0.47        49
          B1       0.59      0.64      0.62        76
          B2       0.47      0.39      0.43        23

    accuracy                           0.53       163
   macro avg       0.48      0.47      0.47       163
weighted avg       0.52      0.53      0.52       163


Fold 1
[[10  4  0  0]
 [ 5 30 13  1]
 [ 3 21 45  6]
 [ 0  1 11 10]]
              precision    recall  f1-score   support

          A1       0.56      0.71      0.63        14
          A2       0.54      0.61      0.57        49
          B1       0.65      0.60      0.63        75
          B2       0.59      0.45      0.51        22

    accuracy                           0.59       160
   macro avg       0.58      0.60      0.58       160
weighted avg       0.60      0.59      0.59       160


Fold 2
[[ 6  7  1  0]
 [ 8 25 15  0]
 [ 3 17 48  7]
 [ 0  1 13  8]]
              precision    recall  f1-score   support

          A1       0.35      0.43      0.39        14
          A2       0.50      0.52      0.51        48
          B1       0.62      0.64      0.63        75
          B2       0.53      0.36      0.43        22

    accuracy                           0.55       159
   macro avg       0.50      0.49      0.49       159
weighted avg       0.55      0.55      0.55       159


Fold 3
[[ 9  4  1  0]
 [ 6 27 14  1]
 [ 0 18 41 16]
 [ 0  1 15  6]]
              precision    recall  f1-score   support

          A1       0.60      0.64      0.62        14
          A2       0.54      0.56      0.55        48
          B1       0.58      0.55      0.56        75
          B2       0.26      0.27      0.27        22

    accuracy                           0.52       159
   macro avg       0.49      0.51      0.50       159
weighted avg       0.52      0.52      0.52       159


Fold 4
[[ 6  7  1  0]
 [ 7 29 11  1]
 [ 4 12 49 10]
 [ 0  2 10 10]]
              precision    recall  f1-score   support

          A1       0.35      0.43      0.39        14
          A2       0.58      0.60      0.59        48
          B1       0.69      0.65      0.67        75
          B2       0.48      0.45      0.47        22

    accuracy                           0.59       159
   macro avg       0.52      0.54      0.53       159
weighted avg       0.60      0.59      0.59       159


K-fold scores
[0.524587152464203, 0.5931690705128205, 0.5458558825359882, 0.5228213151078621, 0.59372667922626]
SKF f1 score mean 0.5560320199694267

LogisticRegression(C=1.0, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='multinomial', n_jobs=None,
                   penalty='l2', random_state=1234, solver='lbfgs', tol=0.0001,
                   verbose=0, warm_start=False)
Fold 0
[[ 9  2  2  2]
 [20 12 12  5]
 [14  9 14 39]
 [ 0  2  3 18]]
              precision    recall  f1-score   support

          A1       0.21      0.60      0.31        15
          A2       0.48      0.24      0.32        49
          B1       0.45      0.18      0.26        76
          B2       0.28      0.78      0.41        23

    accuracy                           0.33       163
   macro avg       0.36      0.45      0.33       163
weighted avg       0.41      0.33      0.31       163


Fold 1
[[13  0  1  0]
 [22 14  7  6]
 [17 11 13 34]
 [ 2  0  2 18]]
              precision    recall  f1-score   support

          A1       0.24      0.93      0.38        14
          A2       0.56      0.29      0.38        49
          B1       0.57      0.17      0.27        75
          B2       0.31      0.82      0.45        22

    accuracy                           0.36       160
   macro avg       0.42      0.55      0.37       160
weighted avg       0.50      0.36      0.34       160


Fold 2
[[ 7  6  1  0]
 [17 20  3  8]
 [18 11 18 28]
 [ 0  2  5 15]]
              precision    recall  f1-score   support

          A1       0.17      0.50      0.25        14
          A2       0.51      0.42      0.46        48
          B1       0.67      0.24      0.35        75
          B2       0.29      0.68      0.41        22

    accuracy                           0.38       159
   macro avg       0.41      0.46      0.37       159
weighted avg       0.52      0.38      0.38       159


Fold 3
[[11  2  0  1]
 [24 12  8  4]
 [13 10 19 33]
 [ 2  2  6 12]]
              precision    recall  f1-score   support

          A1       0.22      0.79      0.34        14
          A2       0.46      0.25      0.32        48
          B1       0.58      0.25      0.35        75
          B2       0.24      0.55      0.33        22

    accuracy                           0.34       159
   macro avg       0.37      0.46      0.34       159
weighted avg       0.46      0.34      0.34       159


Fold 4
[[ 9  4  0  1]
 [25 11  5  7]
 [ 8 12 13 42]
 [ 0  2  2 18]]
              precision    recall  f1-score   support

          A1       0.21      0.64      0.32        14
          A2       0.38      0.23      0.29        48
          B1       0.65      0.17      0.27        75
          B2       0.26      0.82      0.40        22

    accuracy                           0.32       159
   macro avg       0.38      0.47      0.32       159
weighted avg       0.48      0.32      0.30       159


K-fold scores
[0.30645494571954024, 0.33557150562927873, 0.3841550292009211, 0.34026597352069055, 0.2989974937343358]
SKF f1 score mean 0.3330889895609533

************for dimension:  Orthography  ***************
Printing class statistics
Counter({'C1': 262, 'B1': 220, 'A2': 143, 'B2': 77, 'C2': 76, 'A1': 22})
RandomForestClassifier(bootstrap=True, class_weight='balanced',
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, min_impurity_decrease=0.0,
                       min_impurity_split=None, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=None, oob_score=False,
                       random_state=1234, verbose=0, warm_start=False)
Fold 0
[[ 0  0  4  0  1  0]
 [ 0  3 24  0  2  0]
 [ 0  0 35  0  9  0]
 [ 0  0  2  0 14  0]
 [ 0  0  2  0 51  0]
 [ 0  0  2  0 14  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         5
          A2       1.00      0.10      0.19        29
          B1       0.51      0.80      0.62        44
          B2       0.00      0.00      0.00        16
          C1       0.56      0.96      0.71        53
          C2       0.00      0.00      0.00        16

    accuracy                           0.55       163
   macro avg       0.34      0.31      0.25       163
weighted avg       0.50      0.55      0.43       163


Fold 1
[[ 0  2  3  0  0  0]
 [ 0  4 25  0  0  0]
 [ 0  2 38  0  4  0]
 [ 0  0  2  0 14  0]
 [ 0  0  4  0 49  0]
 [ 0  1  1  0 13  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         5
          A2       0.44      0.14      0.21        29
          B1       0.52      0.86      0.65        44
          B2       0.00      0.00      0.00        16
          C1       0.61      0.92      0.74        53
          C2       0.00      0.00      0.00        15

    accuracy                           0.56       162
   macro avg       0.26      0.32      0.27       162
weighted avg       0.42      0.56      0.46       162


Fold 2
[[ 0  0  4  0  0  0]
 [ 0  3 22  0  4  0]
 [ 0  1 37  0  6  0]
 [ 0  0  3  0 12  0]
 [ 0  0  2  0 50  0]
 [ 0  0  1  0 14  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         4
          A2       0.75      0.10      0.18        29
          B1       0.54      0.84      0.65        44
          B2       0.00      0.00      0.00        15
          C1       0.58      0.96      0.72        52
          C2       0.00      0.00      0.00        15

    accuracy                           0.57       159
   macro avg       0.31      0.32      0.26       159
weighted avg       0.48      0.57      0.45       159


Fold 3
[[ 0  2  2  0  0  0]
 [ 0  7 17  0  4  0]
 [ 0 10 33  0  1  0]
 [ 0  0  2  0 13  0]
 [ 0  0  3  0 49  0]
 [ 0  0  3  0 12  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         4
          A2       0.37      0.25      0.30        28
          B1       0.55      0.75      0.63        44
          B2       0.00      0.00      0.00        15
          C1       0.62      0.94      0.75        52
          C2       0.00      0.00      0.00        15

    accuracy                           0.56       158
   macro avg       0.26      0.32      0.28       158
weighted avg       0.42      0.56      0.48       158


Fold 4
[[ 0  2  1  0  1  0]
 [ 0  4 21  0  3  0]
 [ 0  0 37  0  7  0]
 [ 0  0  2  0 13  0]
 [ 0  0  4  0 48  0]
 [ 0  0  2  0 13  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         4
          A2       0.67      0.14      0.24        28
          B1       0.55      0.84      0.67        44
          B2       0.00      0.00      0.00        15
          C1       0.56      0.92      0.70        52
          C2       0.00      0.00      0.00        15

    accuracy                           0.56       158
   macro avg       0.30      0.32      0.27       158
weighted avg       0.46      0.56      0.46       158


K-fold scores
[0.43089450205403845, 0.45517957603727577, 0.45137135839655684, 0.47572320135297747, 0.45797167615082623]
SKF f1 score mean 0.45422806279833494

LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
          verbose=0)
Fold 0
[[ 1  0  3  0  1  0]
 [ 4  6 17  0  2  0]
 [ 3  7 26  1  7  0]
 [ 0  0  2  0 13  1]
 [ 0  0  2  1 48  2]
 [ 0  2  0  1 12  1]]
              precision    recall  f1-score   support

          A1       0.12      0.20      0.15         5
          A2       0.40      0.21      0.27        29
          B1       0.52      0.59      0.55        44
          B2       0.00      0.00      0.00        16
          C1       0.58      0.91      0.71        53
          C2       0.25      0.06      0.10        16

    accuracy                           0.50       163
   macro avg       0.31      0.33      0.30       163
weighted avg       0.43      0.50      0.44       163


Fold 1
[[ 0  3  2  0  0  0]
 [ 1 10 17  1  0  0]
 [ 2  7 31  1  3  0]
 [ 0  0  2  0 12  2]
 [ 0  2  5  0 43  3]
 [ 0  1  1  0 10  3]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         5
          A2       0.43      0.34      0.38        29
          B1       0.53      0.70      0.61        44
          B2       0.00      0.00      0.00        16
          C1       0.63      0.81      0.71        53
          C2       0.38      0.20      0.26        15

    accuracy                           0.54       162
   macro avg       0.33      0.34      0.33       162
weighted avg       0.46      0.54      0.49       162


Fold 2
[[ 1  0  3  0  0  0]
 [ 3  8 16  0  2  0]
 [ 0  7 32  0  5  0]
 [ 0  0  3  0 11  1]
 [ 0  0  3  1 43  5]
 [ 0  0  1  1 10  3]]
              precision    recall  f1-score   support

          A1       0.25      0.25      0.25         4
          A2       0.53      0.28      0.36        29
          B1       0.55      0.73      0.63        44
          B2       0.00      0.00      0.00        15
          C1       0.61      0.83      0.70        52
          C2       0.33      0.20      0.25        15

    accuracy                           0.55       159
   macro avg       0.38      0.38      0.37       159
weighted avg       0.49      0.55      0.50       159


Fold 3
[[ 1  3  0  0  0  0]
 [ 5  8 13  0  1  1]
 [ 3 11 28  1  1  0]
 [ 0  0  1  1 12  1]
 [ 0  0  2  1 42  7]
 [ 0  0  3  0 10  2]]
              precision    recall  f1-score   support

          A1       0.11      0.25      0.15         4
          A2       0.36      0.29      0.32        28
          B1       0.60      0.64      0.62        44
          B2       0.33      0.07      0.11        15
          C1       0.64      0.81      0.71        52
          C2       0.18      0.13      0.15        15

    accuracy                           0.52       158
   macro avg       0.37      0.36      0.34       158
weighted avg       0.49      0.52      0.49       158


Fold 4
[[ 0  3  0  0  1  0]
 [ 2  8 14  1  3  0]
 [ 1  5 32  1  5  0]
 [ 0  0  3  0 10  2]
 [ 0  1  6  1 44  0]
 [ 0  0  2  1 10  2]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         4
          A2       0.47      0.29      0.36        28
          B1       0.56      0.73      0.63        44
          B2       0.00      0.00      0.00        15
          C1       0.60      0.85      0.70        52
          C2       0.50      0.13      0.21        15

    accuracy                           0.54       158
   macro avg       0.36      0.33      0.32       158
weighted avg       0.49      0.54      0.49       158


K-fold scores
[0.4419049810804842, 0.4906259824625063, 0.4984969890562593, 0.4914152899949939, 0.49115593931145285]
SKF f1 score mean 0.48271983638113936

LogisticRegression(C=1.0, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='multinomial', n_jobs=None,
                   penalty='l2', random_state=1234, solver='lbfgs', tol=0.0001,
                   verbose=0, warm_start=False)
Fold 0
[[ 1  0  1  2  0  1]
 [10  4 10  2  2  1]
 [13 11  9  5  3  3]
 [ 1  0  2  1  6  6]
 [ 3  1  1  5 33 10]
 [ 2  1  0  3  6  4]]
              precision    recall  f1-score   support

          A1       0.03      0.20      0.06         5
          A2       0.24      0.14      0.17        29
          B1       0.39      0.20      0.27        44
          B2       0.06      0.06      0.06        16
          C1       0.66      0.62      0.64        53
          C2       0.16      0.25      0.20        16

    accuracy                           0.32       163
   macro avg       0.26      0.25      0.23       163
weighted avg       0.38      0.32      0.34       163


Fold 1
[[ 3  2  0  0  0  0]
 [10 13  5  1  0  0]
 [ 4 12 18  8  1  1]
 [ 3  1  1  1  7  3]
 [ 5  2  1  6 29 10]
 [ 2  1  0  1  8  3]]
              precision    recall  f1-score   support

          A1       0.11      0.60      0.19         5
          A2       0.42      0.45      0.43        29
          B1       0.72      0.41      0.52        44
          B2       0.06      0.06      0.06        16
          C1       0.64      0.55      0.59        53
          C2       0.18      0.20      0.19        15

    accuracy                           0.41       162
   macro avg       0.36      0.38      0.33       162
weighted avg       0.51      0.41      0.44       162


Fold 2
[[ 1  1  2  0  0  0]
 [11  5 10  1  0  2]
 [11 12 13  7  0  1]
 [ 0  0  3  1  8  3]
 [ 1  2  7  6 30  6]
 [ 0  1  1  3  4  6]]
              precision    recall  f1-score   support

          A1       0.04      0.25      0.07         4
          A2       0.24      0.17      0.20        29
          B1       0.36      0.30      0.33        44
          B2       0.06      0.07      0.06        15
          C1       0.71      0.58      0.64        52
          C2       0.33      0.40      0.36        15

    accuracy                           0.35       159
   macro avg       0.29      0.29      0.28       159
weighted avg       0.41      0.35      0.38       159


Fold 3
[[ 2  2  0  0  0  0]
 [ 7  9  9  1  1  1]
 [18 10 11  2  0  3]
 [ 0  2  2  3  8  0]
 [ 1  1  1  5 30 14]
 [ 1  1  4  3  6  0]]
              precision    recall  f1-score   support

          A1       0.07      0.50      0.12         4
          A2       0.36      0.32      0.34        28
          B1       0.41      0.25      0.31        44
          B2       0.21      0.20      0.21        15
          C1       0.67      0.58      0.62        52
          C2       0.00      0.00      0.00        15

    accuracy                           0.35       158
   macro avg       0.29      0.31      0.27       158
weighted avg       0.42      0.35      0.37       158


Fold 4
[[ 3  0  0  0  1  0]
 [14  4  6  2  2  0]
 [11  6 16  7  1  3]
 [ 2  1  0  3  7  2]
 [ 2  1  5  9 29  6]
 [ 0  0  2  3  6  4]]
              precision    recall  f1-score   support

          A1       0.09      0.75      0.17         4
          A2       0.33      0.14      0.20        28
          B1       0.55      0.36      0.44        44
          B2       0.12      0.20      0.15        15
          C1       0.63      0.56      0.59        52
          C2       0.27      0.27      0.27        15

    accuracy                           0.37       158
   macro avg       0.33      0.38      0.30       158
weighted avg       0.46      0.37      0.40       158


K-fold scores
[0.33849313378905543, 0.4420384710757381, 0.376986415163854, 0.37276254426255917, 0.39644012918555266]
SKF f1 score mean 0.3853441386953519

************for dimension:  Vocabularyrange  ***************
Printing class statistics
Counter({'B1': 328, 'A2': 243, 'B2': 188, 'A1': 39, 'C1': 2})
RandomForestClassifier(bootstrap=True, class_weight='balanced',
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, min_impurity_decrease=0.0,
                       min_impurity_split=None, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=None, oob_score=False,
                       random_state=1234, verbose=0, warm_start=False)
Fold 0
[[ 0  6  2  0]
 [ 0 30 19  0]
 [ 0 10 48  8]
 [ 0  0 19 19]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         8
          A2       0.65      0.61      0.63        49
          B1       0.55      0.73      0.62        66
          B2       0.70      0.50      0.58        38

    accuracy                           0.60       161
   macro avg       0.48      0.46      0.46       161
weighted avg       0.59      0.60      0.59       161


Fold 1
[[ 0  8  0  0  0]
 [ 0 38 11  0  0]
 [ 0 13 48  5  0]
 [ 0  0 10 28  0]
 [ 0  0  1  0  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         8
          A2       0.64      0.78      0.70        49
          B1       0.69      0.73      0.71        66
          B2       0.85      0.74      0.79        38
          C1       0.00      0.00      0.00         1

    accuracy                           0.70       162
   macro avg       0.44      0.45      0.44       162
weighted avg       0.67      0.70      0.69       162


Fold 2
[[ 0  8  0  0]
 [ 0 32 17  0]
 [ 0  8 50  8]
 [ 0  0  5 33]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         8
          A2       0.67      0.65      0.66        49
          B1       0.69      0.76      0.72        66
          B2       0.80      0.87      0.84        38

    accuracy                           0.71       161
   macro avg       0.54      0.57      0.55       161
weighted avg       0.68      0.71      0.70       161


Fold 3
[[ 0  5  3  0  0]
 [ 0 35 13  0  0]
 [ 0  3 56  6  0]
 [ 0  0 15 22  0]
 [ 0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         8
          A2       0.81      0.73      0.77        48
          B1       0.64      0.86      0.74        65
          B2       0.76      0.59      0.67        37
          C1       0.00      0.00      0.00         1

    accuracy                           0.71       159
   macro avg       0.44      0.44      0.43       159
weighted avg       0.69      0.71      0.69       159


Fold 4
[[ 0  4  3  0]
 [ 0 32 16  0]
 [ 0 13 43  9]
 [ 0  1 10 26]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         7
          A2       0.64      0.67      0.65        48
          B1       0.60      0.66      0.63        65
          B2       0.74      0.70      0.72        37

    accuracy                           0.64       157
   macro avg       0.50      0.51      0.50       157
weighted avg       0.62      0.64      0.63       157


K-fold scores
[0.5857491315484123, 0.6854416528488556, 0.6950485671228337, 0.6885816379361563, 0.6297584758328767]
SKF f1 score mean 0.6569158930578268

LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
          verbose=0)
Fold 0
[[ 0  8  0  0]
 [ 3 36  9  1]
 [ 0 13 38 15]
 [ 0  0 10 28]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         8
          A2       0.63      0.73      0.68        49
          B1       0.67      0.58      0.62        66
          B2       0.64      0.74      0.68        38

    accuracy                           0.63       161
   macro avg       0.48      0.51      0.50       161
weighted avg       0.62      0.63      0.62       161


Fold 1
[[ 1  7  0  0  0]
 [ 4 36  8  1  0]
 [ 1 18 38  9  0]
 [ 0  0  4 34  0]
 [ 0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.17      0.12      0.14         8
          A2       0.59      0.73      0.65        49
          B1       0.76      0.58      0.66        66
          B2       0.76      0.89      0.82        38
          C1       0.00      0.00      0.00         1

    accuracy                           0.67       162
   macro avg       0.45      0.47      0.45       162
weighted avg       0.67      0.67      0.66       162


Fold 2
[[ 0  8  0  0]
 [ 4 36  9  0]
 [ 1  9 46 10]
 [ 0  1  3 34]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         8
          A2       0.67      0.73      0.70        49
          B1       0.79      0.70      0.74        66
          B2       0.77      0.89      0.83        38

    accuracy                           0.72       161
   macro avg       0.56      0.58      0.57       161
weighted avg       0.71      0.72      0.71       161


Fold 3
[[ 1  4  3  0  0]
 [ 2 35 10  1  0]
 [ 0  4 49 12  0]
 [ 0  1 10 26  0]
 [ 0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.33      0.12      0.18         8
          A2       0.80      0.73      0.76        48
          B1       0.68      0.75      0.72        65
          B2       0.65      0.70      0.68        37
          C1       0.00      0.00      0.00         1

    accuracy                           0.70       159
   macro avg       0.49      0.46      0.47       159
weighted avg       0.69      0.70      0.69       159


Fold 4
[[ 1  4  2  0]
 [ 3 35  9  1]
 [ 3 12 36 14]
 [ 0  1  5 31]]
              precision    recall  f1-score   support

          A1       0.14      0.14      0.14         7
          A2       0.67      0.73      0.70        48
          B1       0.69      0.55      0.62        65
          B2       0.67      0.84      0.75        37

    accuracy                           0.66       157
   macro avg       0.55      0.57      0.55       157
weighted avg       0.66      0.66      0.65       157


K-fold scores
[0.6212094794099235, 0.6641326780642665, 0.712623380384479, 0.6884254587229983, 0.6512009822730412]
SKF f1 score mean 0.6675183957709417

LogisticRegression(C=1.0, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='multinomial', n_jobs=None,
                   penalty='l2', random_state=1234, solver='lbfgs', tol=0.0001,
                   verbose=0, warm_start=False)
Fold 0
[[ 5  2  0  1]
 [17 22  7  3]
 [11  8 28 19]
 [ 0  1  9 26]]
              precision    recall  f1-score   support

          A1       0.15      0.62      0.24         8
          A2       0.67      0.45      0.54        49
          B1       0.64      0.42      0.51        66
          B2       0.53      0.68      0.60        38
          C1       0.00      0.00      0.00         0

    accuracy                           0.50       161
   macro avg       0.40      0.44      0.38       161
weighted avg       0.60      0.50      0.53       161


Fold 1
[[ 5  2  1  0  0]
 [18 21  9  1  0]
 [12 14 30  9  1]
 [ 0  0  4 32  2]
 [ 0  0  1  0  0]]
              precision    recall  f1-score   support

          A1       0.14      0.62      0.23         8
          A2       0.57      0.43      0.49        49
          B1       0.67      0.45      0.54        66
          B2       0.76      0.84      0.80        38
          C1       0.00      0.00      0.00         1

    accuracy                           0.54       162
   macro avg       0.43      0.47      0.41       162
weighted avg       0.63      0.54      0.57       162


Fold 2
[[ 4  4  0  0]
 [16 24  7  2]
 [13 10 32 11]
 [ 2  0  2 32]]
              precision    recall  f1-score   support

          A1       0.11      0.50      0.19         8
          A2       0.63      0.49      0.55        49
          B1       0.78      0.48      0.60        66
          B2       0.71      0.84      0.77        38
          C1       0.00      0.00      0.00         0

    accuracy                           0.57       161
   macro avg       0.45      0.46      0.42       161
weighted avg       0.69      0.57      0.60       161


Fold 3
[[ 3  2  0  3  0]
 [23 15  6  4  0]
 [ 9  5 31 19  1]
 [ 1  0 11 25  0]
 [ 0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.08      0.38      0.14         8
          A2       0.68      0.31      0.43        48
          B1       0.65      0.48      0.55        65
          B2       0.48      0.68      0.56        37
          C1       0.00      0.00      0.00         1

    accuracy                           0.47       159
   macro avg       0.38      0.37      0.34       159
weighted avg       0.59      0.47      0.49       159


Fold 4
[[ 4  1  2  0]
 [19 19  8  2]
 [ 7 10 31 17]
 [ 1  0  6 27]]
              precision    recall  f1-score   support

          A1       0.13      0.57      0.21         7
          A2       0.63      0.40      0.49        48
          B1       0.66      0.48      0.55        65
          B2       0.59      0.73      0.65        37
          C1       0.00      0.00      0.00         0

    accuracy                           0.52       157
   macro avg       0.40      0.43      0.38       157
weighted avg       0.61      0.52      0.54       157


K-fold scores
[0.5251959386160578, 0.5670763787042856, 0.6043521440058369, 0.49127403352471405, 0.5408454242605801]
SKF f1 score mean 0.5457487838222949

************for dimension:  Vocabularycontrol  ***************
Printing class statistics
Counter({'B1': 327, 'A2': 204, 'B2': 196, 'A1': 70, 'C1': 3})
RandomForestClassifier(bootstrap=True, class_weight='balanced',
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, min_impurity_decrease=0.0,
                       min_impurity_split=None, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=None, oob_score=False,
                       random_state=1234, verbose=0, warm_start=False)
Fold 0
[[ 1  7  6  0]
 [ 1 16 24  0]
 [ 0  6 52  8]
 [ 0  0 19 21]]
              precision    recall  f1-score   support

          A1       0.50      0.07      0.12        14
          A2       0.55      0.39      0.46        41
          B1       0.51      0.79      0.62        66
          B2       0.72      0.53      0.61        40

    accuracy                           0.56       161
   macro avg       0.57      0.44      0.45       161
weighted avg       0.57      0.56      0.53       161


Fold 1
[[ 1  7  6  0  0]
 [ 0 20 21  0  0]
 [ 0 12 41 13  0]
 [ 0  0 16 23  0]
 [ 0  0  1  0  0]]
              precision    recall  f1-score   support

          A1       1.00      0.07      0.13        14
          A2       0.51      0.49      0.50        41
          B1       0.48      0.62      0.54        66
          B2       0.64      0.59      0.61        39
          C1       0.00      0.00      0.00         1

    accuracy                           0.53       161
   macro avg       0.53      0.35      0.36       161
weighted avg       0.57      0.53      0.51       161


Fold 2
[[ 0  9  5  0]
 [ 1 27 13  0]
 [ 0 19 38  8]
 [ 0  0 20 19]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        14
          A2       0.49      0.66      0.56        41
          B1       0.50      0.58      0.54        65
          B2       0.70      0.49      0.58        39

    accuracy                           0.53       159
   macro avg       0.42      0.43      0.42       159
weighted avg       0.50      0.53      0.51       159


Fold 3
[[ 1  7  6  0  0]
 [ 0 21 20  0  0]
 [ 0  6 52  7  0]
 [ 0  0 19 20  0]
 [ 0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       1.00      0.07      0.13        14
          A2       0.62      0.51      0.56        41
          B1       0.54      0.80      0.64        65
          B2       0.71      0.51      0.60        39
          C1       0.00      0.00      0.00         1

    accuracy                           0.59       160
   macro avg       0.57      0.38      0.39       160
weighted avg       0.64      0.59      0.56       160


Fold 4
[[ 0  7  7  0  0]
 [ 1 20 19  0  0]
 [ 1  9 42 13  0]
 [ 0  0 16 23  0]
 [ 0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        14
          A2       0.56      0.50      0.53        40
          B1       0.50      0.65      0.56        65
          B2       0.62      0.59      0.61        39
          C1       0.00      0.00      0.00         1

    accuracy                           0.53       159
   macro avg       0.34      0.35      0.34       159
weighted avg       0.50      0.53      0.51       159


K-fold scores
[0.5338042213478218, 0.5101101010516501, 0.5066195374053664, 0.5614915238621706, 0.5113345285462612]
SKF f1 score mean 0.524671982442654

LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
          verbose=0)
Fold 0
[[ 5  6  3  0]
 [12 20  9  0]
 [ 2  6 41 17]
 [ 0  0  7 33]]
              precision    recall  f1-score   support

          A1       0.26      0.36      0.30        14
          A2       0.62      0.49      0.55        41
          B1       0.68      0.62      0.65        66
          B2       0.66      0.82      0.73        40

    accuracy                           0.61       161
   macro avg       0.56      0.57      0.56       161
weighted avg       0.63      0.61      0.61       161


Fold 1
[[ 7  5  2  0  0]
 [ 6 29  5  1  0]
 [ 3 14 25 22  2]
 [ 0  2  5 31  1]
 [ 0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.44      0.50      0.47        14
          A2       0.58      0.71      0.64        41
          B1       0.68      0.38      0.49        66
          B2       0.56      0.79      0.66        39
          C1       0.00      0.00      0.00         1

    accuracy                           0.57       161
   macro avg       0.45      0.48      0.45       161
weighted avg       0.60      0.57      0.56       161


Fold 2
[[ 5  8  1  0]
 [ 3 31  7  0]
 [ 5 19 22 18]
 [ 0  1 11 27]]
              precision    recall  f1-score   support

          A1       0.38      0.36      0.37        14
          A2       0.53      0.76      0.62        41
          B1       0.54      0.34      0.42        65
          B2       0.60      0.69      0.64        39
          C1       0.00      0.00      0.00         0

    accuracy                           0.53       159
   macro avg       0.41      0.43      0.41       159
weighted avg       0.54      0.53      0.52       159


Fold 3
[[ 3  6  5  0  0]
 [ 8 27  5  1  0]
 [ 2  9 32 22  0]
 [ 0  0  6 33  0]
 [ 0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.23      0.21      0.22        14
          A2       0.64      0.66      0.65        41
          B1       0.67      0.49      0.57        65
          B2       0.58      0.85      0.69        39
          C1       0.00      0.00      0.00         1

    accuracy                           0.59       160
   macro avg       0.42      0.44      0.43       160
weighted avg       0.60      0.59      0.58       160


Fold 4
[[ 4  7  3  0  0]
 [ 6 23 10  1  0]
 [ 4 15 23 23  0]
 [ 0  1  8 30  0]
 [ 0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.29      0.29      0.29        14
          A2       0.50      0.57      0.53        40
          B1       0.52      0.35      0.42        65
          B2       0.55      0.77      0.64        39
          C1       0.00      0.00      0.00         1

    accuracy                           0.50       159
   macro avg       0.37      0.40      0.38       159
weighted avg       0.50      0.50      0.49       159


K-fold scores
[0.6148688941167456, 0.561661122186192, 0.5198600366797828, 0.5838279324895452, 0.4888060284216123]
SKF f1 score mean 0.5538048027787756

LogisticRegression(C=1.0, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='multinomial', n_jobs=None,
                   penalty='l2', random_state=1234, solver='lbfgs', tol=0.0001,
                   verbose=0, warm_start=False)
Fold 0
[[ 9  3  1  1]
 [21 14  3  3]
 [10 12 19 18]
 [ 2  1  6 25]]
              precision    recall  f1-score   support

          A1       0.21      0.64      0.32        14
          A2       0.47      0.34      0.39        41
          B1       0.66      0.29      0.40        66
          B2       0.53      0.62      0.57        40
          C1       0.00      0.00      0.00         0

    accuracy                           0.42       161
   macro avg       0.37      0.38      0.34       161
weighted avg       0.54      0.42      0.44       161


Fold 1
[[10  3  1  0  0]
 [19 15  3  3  1]
 [13 11 12 16 14]
 [ 1  3  4 15 16]
 [ 0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.23      0.71      0.35        14
          A2       0.47      0.37      0.41        41
          B1       0.60      0.18      0.28        66
          B2       0.43      0.38      0.41        39
          C1       0.00      0.00      0.00         1

    accuracy                           0.32       161
   macro avg       0.35      0.33      0.29       161
weighted avg       0.49      0.32      0.35       161


Fold 2
[[10  3  1  0]
 [11 23  4  3]
 [16 16 13 16]
 [ 2  2  6 22]]
              precision    recall  f1-score   support

          A1       0.26      0.71      0.38        14
          A2       0.52      0.56      0.54        41
          B1       0.54      0.20      0.29        65
          B2       0.54      0.56      0.55        39
          C1       0.00      0.00      0.00         0

    accuracy                           0.43       159
   macro avg       0.37      0.41      0.35       159
weighted avg       0.51      0.43      0.43       159


Fold 3
[[10  1  2  1  0]
 [17 20  3  1  0]
 [12  8 21 23  1]
 [ 1  0  7 23  8]
 [ 0  0  0  0  1]]
              precision    recall  f1-score   support

          A1       0.25      0.71      0.37        14
          A2       0.69      0.49      0.57        41
          B1       0.64      0.32      0.43        65
          B2       0.48      0.59      0.53        39
          C1       0.10      1.00      0.18         1

    accuracy                           0.47       160
   macro avg       0.43      0.62      0.42       160
weighted avg       0.57      0.47      0.48       160


Fold 4
[[ 6  5  2  1  0]
 [13 19  6  2  0]
 [16 12 12 24  1]
 [ 1  3  7 26  2]
 [ 0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.17      0.43      0.24        14
          A2       0.49      0.47      0.48        40
          B1       0.44      0.18      0.26        65
          B2       0.48      0.67      0.56        39
          C1       0.00      0.00      0.00         1

    accuracy                           0.40       159
   macro avg       0.32      0.35      0.31       159
weighted avg       0.44      0.40      0.39       159


K-fold scores
[0.43513987473064275, 0.3477702561007524, 0.4271070327483396, 0.48295879567431294, 0.3859338344726263]
SKF f1 score mean 0.4157819587453348

************for dimension:  CoherenceCohesion  ***************
Printing class statistics
Counter({'A2': 334, 'B1': 300, 'A1': 109, 'B2': 57})
RandomForestClassifier(bootstrap=True, class_weight='balanced',
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, min_impurity_decrease=0.0,
                       min_impurity_split=None, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=None, oob_score=False,
                       random_state=1234, verbose=0, warm_start=False)
Fold 0
[[ 1 20  1  0]
 [ 1 63  3  0]
 [ 0 10 50  0]
 [ 0  0 12  0]]
              precision    recall  f1-score   support

          A1       0.50      0.05      0.08        22
          A2       0.68      0.94      0.79        67
          B1       0.76      0.83      0.79        60
          B2       0.00      0.00      0.00        12

    accuracy                           0.71       161
   macro avg       0.48      0.45      0.42       161
weighted avg       0.63      0.71      0.63       161


Fold 1
[[ 0 21  1  0]
 [ 1 55 11  0]
 [ 0 18 42  0]
 [ 0  0 12  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        22
          A2       0.59      0.82      0.68        67
          B1       0.64      0.70      0.67        60
          B2       0.00      0.00      0.00        12

    accuracy                           0.60       161
   macro avg       0.31      0.38      0.34       161
weighted avg       0.48      0.60      0.53       161


Fold 2
[[ 1 21  0  0]
 [ 0 53 14  0]
 [ 0 11 49  0]
 [ 0  1 10  0]]
              precision    recall  f1-score   support

          A1       1.00      0.05      0.09        22
          A2       0.62      0.79      0.69        67
          B1       0.67      0.82      0.74        60
          B2       0.00      0.00      0.00        11

    accuracy                           0.64       160
   macro avg       0.57      0.41      0.38       160
weighted avg       0.65      0.64      0.58       160


Fold 3
[[ 1 21  0  0]
 [ 0 59  8  0]
 [ 0  9 51  0]
 [ 0  0 11  0]]
              precision    recall  f1-score   support

          A1       1.00      0.05      0.09        22
          A2       0.66      0.88      0.76        67
          B1       0.73      0.85      0.78        60
          B2       0.00      0.00      0.00        11

    accuracy                           0.69       160
   macro avg       0.60      0.44      0.41       160
weighted avg       0.69      0.69      0.62       160


Fold 4
[[ 1 18  2  0]
 [ 0 57  9  0]
 [ 0 10 50  0]
 [ 0  0 11  0]]
              precision    recall  f1-score   support

          A1       1.00      0.05      0.09        21
          A2       0.67      0.86      0.75        66
          B1       0.69      0.83      0.76        60
          B2       0.00      0.00      0.00        11

    accuracy                           0.68       158
   macro avg       0.59      0.44      0.40       158
weighted avg       0.68      0.68      0.62       158


K-fold scores
[0.6348750369713103, 0.53277265537595, 0.5783866902977819, 0.6229340858416945, 0.6151357653998277]
SKF f1 score mean 0.596820846777313

LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
          verbose=0)
Fold 0
[[ 8 13  1  0]
 [12 49  6  0]
 [ 0 10 50  0]
 [ 0  0 12  0]]
              precision    recall  f1-score   support

          A1       0.40      0.36      0.38        22
          A2       0.68      0.73      0.71        67
          B1       0.72      0.83      0.78        60
          B2       0.00      0.00      0.00        12

    accuracy                           0.66       161
   macro avg       0.45      0.48      0.47       161
weighted avg       0.61      0.66      0.63       161


Fold 1
[[ 2 18  2  0]
 [ 5 50 12  0]
 [ 0 16 44  0]
 [ 0  0 12  0]]
              precision    recall  f1-score   support

          A1       0.29      0.09      0.14        22
          A2       0.60      0.75      0.66        67
          B1       0.63      0.73      0.68        60
          B2       0.00      0.00      0.00        12

    accuracy                           0.60       161
   macro avg       0.38      0.39      0.37       161
weighted avg       0.52      0.60      0.55       161


Fold 2
[[ 5 16  1  0]
 [ 1 47 19  0]
 [ 0  7 53  0]
 [ 0  1 10  0]]
              precision    recall  f1-score   support

          A1       0.83      0.23      0.36        22
          A2       0.66      0.70      0.68        67
          B1       0.64      0.88      0.74        60
          B2       0.00      0.00      0.00        11

    accuracy                           0.66       160
   macro avg       0.53      0.45      0.44       160
weighted avg       0.63      0.66      0.61       160


Fold 3
[[ 3 18  1  0]
 [ 3 52 12  0]
 [ 0  6 54  0]
 [ 0  0 11  0]]
              precision    recall  f1-score   support

          A1       0.50      0.14      0.21        22
          A2       0.68      0.78      0.73        67
          B1       0.69      0.90      0.78        60
          B2       0.00      0.00      0.00        11

    accuracy                           0.68       160
   macro avg       0.47      0.45      0.43       160
weighted avg       0.61      0.68      0.63       160


Fold 4
[[ 3 16  2  0]
 [ 1 54 11  0]
 [ 0 11 49  0]
 [ 0  1 10  0]]
              precision    recall  f1-score   support

          A1       0.75      0.14      0.24        21
          A2       0.66      0.82      0.73        66
          B1       0.68      0.82      0.74        60
          B2       0.00      0.00      0.00        11

    accuracy                           0.67       158
   macro avg       0.52      0.44      0.43       158
weighted avg       0.63      0.67      0.62       158


K-fold scores
[0.6343477662103825, 0.5467125981438361, 0.6123146780755475, 0.6274880011293055, 0.6186558019469413]
SKF f1 score mean 0.6079037691012026

LogisticRegression(C=1.0, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='multinomial', n_jobs=None,
                   penalty='l2', random_state=1234, solver='lbfgs', tol=0.0001,
                   verbose=0, warm_start=False)
Fold 0
[[13  7  2  0]
 [40 20  4  3]
 [ 4  8 14 34]
 [ 0  0  0 12]]
              precision    recall  f1-score   support

          A1       0.23      0.59      0.33        22
          A2       0.57      0.30      0.39        67
          B1       0.70      0.23      0.35        60
          B2       0.24      1.00      0.39        12

    accuracy                           0.37       161
   macro avg       0.44      0.53      0.37       161
weighted avg       0.55      0.37      0.37       161


Fold 1
[[18  3  0  1]
 [32 23  9  3]
 [ 6 15 16 23]
 [ 0  1  3  8]]
              precision    recall  f1-score   support

          A1       0.32      0.82      0.46        22
          A2       0.55      0.34      0.42        67
          B1       0.57      0.27      0.36        60
          B2       0.23      0.67      0.34        12

    accuracy                           0.40       161
   macro avg       0.42      0.52      0.40       161
weighted avg       0.50      0.40      0.40       161


Fold 2
[[15  5  2  0]
 [27 19 18  3]
 [ 4  8 12 36]
 [ 1  2  1  7]]
              precision    recall  f1-score   support

          A1       0.32      0.68      0.43        22
          A2       0.56      0.28      0.38        67
          B1       0.36      0.20      0.26        60
          B2       0.15      0.64      0.25        11

    accuracy                           0.33       160
   macro avg       0.35      0.45      0.33       160
weighted avg       0.42      0.33      0.33       160


Fold 3
[[16  3  2  1]
 [36 19 10  2]
 [ 1 12 17 30]
 [ 0  0  3  8]]
              precision    recall  f1-score   support

          A1       0.30      0.73      0.43        22
          A2       0.56      0.28      0.38        67
          B1       0.53      0.28      0.37        60
          B2       0.20      0.73      0.31        11

    accuracy                           0.38       160
   macro avg       0.40      0.51      0.37       160
weighted avg       0.49      0.38      0.38       160


Fold 4
[[17  2  2  0]
 [30 24  7  5]
 [ 4 10 19 27]
 [ 0  3  0  8]]
              precision    recall  f1-score   support

          A1       0.33      0.81      0.47        21
          A2       0.62      0.36      0.46        66
          B1       0.68      0.32      0.43        60
          B2       0.20      0.73      0.31        11

    accuracy                           0.43       158
   macro avg       0.46      0.55      0.42       158
weighted avg       0.57      0.43      0.44       158


K-fold scores
[0.36792750067357344, 0.3995798988372973, 0.330992272106815, 0.375956974292747, 0.43954535784394316]
SKF f1 score mean 0.3828004007508752

************for dimension:  Sociolinguisticappropriateness  ***************
Printing class statistics
Counter({'B1': 372, 'A2': 336, 'A1': 56, 'B2': 36})
RandomForestClassifier(bootstrap=True, class_weight='balanced',
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, min_impurity_decrease=0.0,
                       min_impurity_split=None, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=None, oob_score=False,
                       random_state=1234, verbose=0, warm_start=False)
Fold 0
[[ 0 10  2  0]
 [ 0 47 21  0]
 [ 0 14 61  0]
 [ 0  0  8  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        12
          A2       0.66      0.69      0.68        68
          B1       0.66      0.81      0.73        75
          B2       0.00      0.00      0.00         8

    accuracy                           0.66       163
   macro avg       0.33      0.38      0.35       163
weighted avg       0.58      0.66      0.62       163


Fold 1
[[ 0  8  3  0]
 [ 0 57 10  0]
 [ 0 13 62  0]
 [ 0  0  7  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        11
          A2       0.73      0.85      0.79        67
          B1       0.76      0.83      0.79        75
          B2       0.00      0.00      0.00         7

    accuracy                           0.74       160
   macro avg       0.37      0.42      0.39       160
weighted avg       0.66      0.74      0.70       160


Fold 2
[[ 0 10  1  0]
 [ 0 51 16  0]
 [ 0  9 65  0]
 [ 0  0  7  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        11
          A2       0.73      0.76      0.74        67
          B1       0.73      0.88      0.80        74
          B2       0.00      0.00      0.00         7

    accuracy                           0.73       159
   macro avg       0.36      0.41      0.39       159
weighted avg       0.65      0.73      0.68       159


Fold 3
[[ 0 11  0  0]
 [ 0 52 15  0]
 [ 0  9 65  0]
 [ 0  0  7  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        11
          A2       0.72      0.78      0.75        67
          B1       0.75      0.88      0.81        74
          B2       0.00      0.00      0.00         7

    accuracy                           0.74       159
   macro avg       0.37      0.41      0.39       159
weighted avg       0.65      0.74      0.69       159


Fold 4
[[ 0  9  2  0]
 [ 0 47 20  0]
 [ 0 16 58  0]
 [ 0  0  7  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        11
          A2       0.65      0.70      0.68        67
          B1       0.67      0.78      0.72        74
          B2       0.00      0.00      0.00         7

    accuracy                           0.66       159
   macro avg       0.33      0.37      0.35       159
weighted avg       0.59      0.66      0.62       159


K-fold scores
[0.6182578568863069, 0.6994470678673401, 0.6849158275899848, 0.6910757811189229, 0.6202900799013901]
SKF f1 score mean 0.662797322672789

LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
          verbose=0)
Fold 0
[[ 1  9  2  0]
 [ 0 48 20  0]
 [ 0 17 58  0]
 [ 0  0  8  0]]
              precision    recall  f1-score   support

          A1       1.00      0.08      0.15        12
          A2       0.65      0.71      0.68        68
          B1       0.66      0.77      0.71        75
          B2       0.00      0.00      0.00         8

    accuracy                           0.66       163
   macro avg       0.58      0.39      0.39       163
weighted avg       0.65      0.66      0.62       163


Fold 1
[[ 1  7  3  0]
 [ 0 56 11  0]
 [ 0 14 60  1]
 [ 0  0  7  0]]
              precision    recall  f1-score   support

          A1       1.00      0.09      0.17        11
          A2       0.73      0.84      0.78        67
          B1       0.74      0.80      0.77        75
          B2       0.00      0.00      0.00         7

    accuracy                           0.73       160
   macro avg       0.62      0.43      0.43       160
weighted avg       0.72      0.73      0.70       160


Fold 2
[[ 0 10  1  0]
 [ 2 46 19  0]
 [ 1 14 58  1]
 [ 0  0  7  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        11
          A2       0.66      0.69      0.67        67
          B1       0.68      0.78      0.73        74
          B2       0.00      0.00      0.00         7

    accuracy                           0.65       159
   macro avg       0.33      0.37      0.35       159
weighted avg       0.59      0.65      0.62       159


Fold 3
[[ 1 10  0  0]
 [ 1 49 17  0]
 [ 0 11 63  0]
 [ 0  0  7  0]]
              precision    recall  f1-score   support

          A1       0.50      0.09      0.15        11
          A2       0.70      0.73      0.72        67
          B1       0.72      0.85      0.78        74
          B2       0.00      0.00      0.00         7

    accuracy                           0.71       159
   macro avg       0.48      0.42      0.41       159
weighted avg       0.67      0.71      0.68       159


Fold 4
[[ 1  9  1  0]
 [ 2 47 18  0]
 [ 0 19 55  0]
 [ 0  0  7  0]]
              precision    recall  f1-score   support

          A1       0.33      0.09      0.14        11
          A2       0.63      0.70      0.66        67
          B1       0.68      0.74      0.71        74
          B2       0.00      0.00      0.00         7

    accuracy                           0.65       159
   macro avg       0.41      0.38      0.38       159
weighted avg       0.60      0.65      0.62       159


K-fold scores
[0.6208111531343785, 0.6977297008547009, 0.6225164912803446, 0.6763041413197399, 0.6191174231430375]
SKF f1 score mean 0.6472957819464403

LogisticRegression(C=1.0, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='multinomial', n_jobs=None,
                   penalty='l2', random_state=1234, solver='lbfgs', tol=0.0001,
                   verbose=0, warm_start=False)
Fold 0
[[ 7  4  1  0]
 [27 28  6  7]
 [ 5 20 20 30]
 [ 0  0  1  7]]
              precision    recall  f1-score   support

          A1       0.18      0.58      0.27        12
          A2       0.54      0.41      0.47        68
          B1       0.71      0.27      0.39        75
          B2       0.16      0.88      0.27         8

    accuracy                           0.38       163
   macro avg       0.40      0.53      0.35       163
weighted avg       0.57      0.38      0.41       163


Fold 1
[[ 4  2  5  0]
 [27 24 11  5]
 [ 7 10 20 38]
 [ 0  0  1  6]]
              precision    recall  f1-score   support

          A1       0.11      0.36      0.16        11
          A2       0.67      0.36      0.47        67
          B1       0.54      0.27      0.36        75
          B2       0.12      0.86      0.21         7

    accuracy                           0.34       160
   macro avg       0.36      0.46      0.30       160
weighted avg       0.55      0.34      0.38       160


Fold 2
[[ 6  3  1  1]
 [22 23 15  7]
 [ 6 18 17 33]
 [ 0  0  1  6]]
              precision    recall  f1-score   support

          A1       0.18      0.55      0.27        11
          A2       0.52      0.34      0.41        67
          B1       0.50      0.23      0.31        74
          B2       0.13      0.86      0.22         7

    accuracy                           0.33       159
   macro avg       0.33      0.49      0.30       159
weighted avg       0.47      0.33      0.35       159


Fold 3
[[ 7  3  0  1]
 [34 19  3 11]
 [ 6  9 22 37]
 [ 0  0  1  6]]
              precision    recall  f1-score   support

          A1       0.15      0.64      0.24        11
          A2       0.61      0.28      0.39        67
          B1       0.85      0.30      0.44        74
          B2       0.11      0.86      0.19         7

    accuracy                           0.34       159
   macro avg       0.43      0.52      0.32       159
weighted avg       0.67      0.34      0.39       159


Fold 4
[[ 6  3  1  1]
 [30 18  8 11]
 [15 13 19 27]
 [ 0  0  2  5]]
              precision    recall  f1-score   support

          A1       0.12      0.55      0.19        11
          A2       0.53      0.27      0.36        67
          B1       0.63      0.26      0.37        74
          B2       0.11      0.71      0.20         7

    accuracy                           0.30       159
   macro avg       0.35      0.45      0.28       159
weighted avg       0.53      0.30      0.34       159


K-fold scores
[0.4067945443341799, 0.3831558351495938, 0.3493770500059808, 0.39339372930946676, 0.34227189267261493]
SKF f1 score mean 0.3749986102943672

FOr lang:  CZ
1024
************for dimension:  OverallCEFRrating  ***************
Printing class statistics
Counter({'A2': 188, 'B1': 165, 'B2': 81})
RandomForestClassifier(bootstrap=True, class_weight='balanced',
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, min_impurity_decrease=0.0,
                       min_impurity_split=None, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=None, oob_score=False,
                       random_state=1234, verbose=0, warm_start=False)
Fold 0
[[36  2  0]
 [ 8 22  3]
 [ 0 13  4]]
              precision    recall  f1-score   support

          A2       0.82      0.95      0.88        38
          B1       0.59      0.67      0.63        33
          B2       0.57      0.24      0.33        17

    accuracy                           0.70        88
   macro avg       0.66      0.62      0.61        88
weighted avg       0.69      0.70      0.68        88


Fold 1
[[35  3  0]
 [11 18  4]
 [ 0  5 11]]
              precision    recall  f1-score   support

          A2       0.76      0.92      0.83        38
          B1       0.69      0.55      0.61        33
          B2       0.73      0.69      0.71        16

    accuracy                           0.74        87
   macro avg       0.73      0.72      0.72        87
weighted avg       0.73      0.74      0.73        87


Fold 2
[[34  4  0]
 [15 16  2]
 [ 0  7  9]]
              precision    recall  f1-score   support

          A2       0.69      0.89      0.78        38
          B1       0.59      0.48      0.53        33
          B2       0.82      0.56      0.67        16

    accuracy                           0.68        87
   macro avg       0.70      0.65      0.66        87
weighted avg       0.68      0.68      0.67        87


Fold 3
[[34  3  0]
 [ 9 19  5]
 [ 0  9  7]]
              precision    recall  f1-score   support

          A2       0.79      0.92      0.85        37
          B1       0.61      0.58      0.59        33
          B2       0.58      0.44      0.50        16

    accuracy                           0.70        86
   macro avg       0.66      0.64      0.65        86
weighted avg       0.68      0.70      0.69        86


Fold 4
[[34  3  0]
 [ 7 21  5]
 [ 0  8  8]]
              precision    recall  f1-score   support

          A2       0.83      0.92      0.87        37
          B1       0.66      0.64      0.65        33
          B2       0.62      0.50      0.55        16

    accuracy                           0.73        86
   macro avg       0.70      0.69      0.69        86
weighted avg       0.72      0.73      0.73        86


K-fold scores
[0.6792656530461408, 0.7259436620308398, 0.6662967366891267, 0.6865552325581395, 0.7256636440277178]
SKF f1 score mean 0.6967449856703929

LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
          verbose=0)
Fold 0
[[35  3  0]
 [12 13  8]
 [ 0  6 11]]
              precision    recall  f1-score   support

          A2       0.74      0.92      0.82        38
          B1       0.59      0.39      0.47        33
          B2       0.58      0.65      0.61        17

    accuracy                           0.67        88
   macro avg       0.64      0.65      0.64        88
weighted avg       0.65      0.67      0.65        88


Fold 1
[[38  0  0]
 [15  9  9]
 [ 0  1 15]]
              precision    recall  f1-score   support

          A2       0.72      1.00      0.84        38
          B1       0.90      0.27      0.42        33
          B2       0.62      0.94      0.75        16

    accuracy                           0.71        87
   macro avg       0.75      0.74      0.67        87
weighted avg       0.77      0.71      0.66        87


Fold 2
[[34  4  0]
 [14 13  6]
 [ 0  3 13]]
              precision    recall  f1-score   support

          A2       0.71      0.89      0.79        38
          B1       0.65      0.39      0.49        33
          B2       0.68      0.81      0.74        16

    accuracy                           0.69        87
   macro avg       0.68      0.70      0.67        87
weighted avg       0.68      0.69      0.67        87


Fold 3
[[35  1  1]
 [13  8 12]
 [ 0  4 12]]
              precision    recall  f1-score   support

          A2       0.73      0.95      0.82        37
          B1       0.62      0.24      0.35        33
          B2       0.48      0.75      0.59        16

    accuracy                           0.64        86
   macro avg       0.61      0.65      0.59        86
weighted avg       0.64      0.64      0.60        86


Fold 4
[[36  1  0]
 [12 10 11]
 [ 1  1 14]]
              precision    recall  f1-score   support

          A2       0.73      0.97      0.84        37
          B1       0.83      0.30      0.44        33
          B2       0.56      0.88      0.68        16

    accuracy                           0.70        86
   macro avg       0.71      0.72      0.65        86
weighted avg       0.74      0.70      0.66        86


K-fold scores
[0.6509432560903149, 0.6614967497084578, 0.6680563811368307, 0.5966825902720456, 0.6577934897791379]
SKF f1 score mean 0.6469944933973574

LogisticRegression(C=1.0, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='multinomial', n_jobs=None,
                   penalty='l2', random_state=1234, solver='lbfgs', tol=0.0001,
                   verbose=0, warm_start=False)
Fold 0
[[33  3  2]
 [13  6 14]
 [ 0  2 15]]
              precision    recall  f1-score   support

          A2       0.72      0.87      0.79        38
          B1       0.55      0.18      0.27        33
          B2       0.48      0.88      0.62        17

    accuracy                           0.61        88
   macro avg       0.58      0.64      0.56        88
weighted avg       0.61      0.61      0.56        88


Fold 1
[[35  0  3]
 [15  6 12]
 [ 0  1 15]]
              precision    recall  f1-score   support

          A2       0.70      0.92      0.80        38
          B1       0.86      0.18      0.30        33
          B2       0.50      0.94      0.65        16

    accuracy                           0.64        87
   macro avg       0.69      0.68      0.58        87
weighted avg       0.72      0.64      0.58        87


Fold 2
[[34  2  2]
 [15  7 11]
 [ 0  1 15]]
              precision    recall  f1-score   support

          A2       0.69      0.89      0.78        38
          B1       0.70      0.21      0.33        33
          B2       0.54      0.94      0.68        16

    accuracy                           0.64        87
   macro avg       0.64      0.68      0.60        87
weighted avg       0.67      0.64      0.59        87


Fold 3
[[34  1  2]
 [13  5 15]
 [ 0  2 14]]
              precision    recall  f1-score   support

          A2       0.72      0.92      0.81        37
          B1       0.62      0.15      0.24        33
          B2       0.45      0.88      0.60        16

    accuracy                           0.62        86
   macro avg       0.60      0.65      0.55        86
weighted avg       0.64      0.62      0.55        86


Fold 4
[[36  0  1]
 [12  6 15]
 [ 1  1 14]]
              precision    recall  f1-score   support

          A2       0.73      0.97      0.84        37
          B1       0.86      0.18      0.30        33
          B2       0.47      0.88      0.61        16

    accuracy                           0.65        86
   macro avg       0.69      0.68      0.58        86
weighted avg       0.73      0.65      0.59        86


K-fold scores
[0.562297077922078, 0.581173049838717, 0.5902807629987343, 0.5527101899279402, 0.5885566816375479]
SKF f1 score mean 0.5750035524650035

************for dimension:  Grammaticalaccuracy  ***************
Printing class statistics
Counter({'A2': 185, 'B1': 156, 'B2': 82, 'A1': 6, 'C1': 5})
RandomForestClassifier(bootstrap=True, class_weight='balanced',
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, min_impurity_decrease=0.0,
                       min_impurity_split=None, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=None, oob_score=False,
                       random_state=1234, verbose=0, warm_start=False)
Fold 0
[[ 0  2  0  0  0]
 [ 0 28  8  1  0]
 [ 0 13 17  2  0]
 [ 0  5  5  7  0]
 [ 0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         2
          A2       0.58      0.76      0.66        37
          B1       0.57      0.53      0.55        32
          B2       0.64      0.41      0.50        17
          C1       0.00      0.00      0.00         1

    accuracy                           0.58        89
   macro avg       0.36      0.34      0.34        89
weighted avg       0.57      0.58      0.57        89


Fold 1
[[ 0  1  0  0  0]
 [ 0 28  8  1  0]
 [ 0 12  9 10  0]
 [ 0  1  6 10  0]
 [ 0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.67      0.76      0.71        37
          B1       0.39      0.29      0.33        31
          B2       0.45      0.59      0.51        17
          C1       0.00      0.00      0.00         1

    accuracy                           0.54        87
   macro avg       0.30      0.33      0.31        87
weighted avg       0.51      0.54      0.52        87


Fold 2
[[ 0  1  0  0  0]
 [ 0 33  4  0  0]
 [ 0 18  6  7  0]
 [ 0  0  5 11  0]
 [ 0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.63      0.89      0.74        37
          B1       0.40      0.19      0.26        31
          B2       0.58      0.69      0.63        16
          C1       0.00      0.00      0.00         1

    accuracy                           0.58        86
   macro avg       0.32      0.35      0.33        86
weighted avg       0.52      0.58      0.53        86


Fold 3
[[ 0  1  0  0  0]
 [ 0 26  9  2  0]
 [ 0 15 10  6  0]
 [ 0  1  6  9  0]
 [ 0  0  1  0  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.60      0.70      0.65        37
          B1       0.38      0.32      0.35        31
          B2       0.53      0.56      0.55        16
          C1       0.00      0.00      0.00         1

    accuracy                           0.52        86
   macro avg       0.30      0.32      0.31        86
weighted avg       0.50      0.52      0.51        86


Fold 4
[[ 0  1  0  0  0]
 [ 0 31  4  2  0]
 [ 0 14  9  8  0]
 [ 0  0  4 12  0]
 [ 0  0  1  0  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.67      0.84      0.75        37
          B1       0.50      0.29      0.37        31
          B2       0.55      0.75      0.63        16
          C1       0.00      0.00      0.00         1

    accuracy                           0.60        86
   macro avg       0.34      0.38      0.35        86
weighted avg       0.57      0.60      0.57        86


K-fold scores
[0.566571434663028, 0.5204497718683664, 0.5300267630938721, 0.5076100663921961, 0.5712973543814306]
SKF f1 score mean 0.5391910780797785

LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
          verbose=0)
Fold 0
[[ 0  2  0  0  0]
 [ 1 29  4  3  0]
 [ 0 20  2 10  0]
 [ 0  2  2 13  0]
 [ 0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         2
          A2       0.55      0.78      0.64        37
          B1       0.25      0.06      0.10        32
          B2       0.48      0.76      0.59        17
          C1       0.00      0.00      0.00         1

    accuracy                           0.49        89
   macro avg       0.26      0.32      0.27        89
weighted avg       0.41      0.49      0.42        89


Fold 1
[[ 0  1  0  0  0]
 [ 1 22 10  4  0]
 [ 0 16  1 13  1]
 [ 0  0  0 17  0]
 [ 0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.56      0.59      0.58        37
          B1       0.09      0.03      0.05        31
          B2       0.49      1.00      0.65        17
          C1       0.00      0.00      0.00         1

    accuracy                           0.46        87
   macro avg       0.23      0.33      0.26        87
weighted avg       0.37      0.46      0.39        87


Fold 2
[[ 0  1  0  0  0]
 [ 0 27  5  5  0]
 [ 0 17  2 12  0]
 [ 0  0  1 15  0]
 [ 0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.60      0.73      0.66        37
          B1       0.25      0.06      0.10        31
          B2       0.45      0.94      0.61        16
          C1       0.00      0.00      0.00         1

    accuracy                           0.51        86
   macro avg       0.26      0.35      0.27        86
weighted avg       0.43      0.51      0.43        86


Fold 3
[[ 0  1  0  0  0]
 [ 2 26  3  6  0]
 [ 0 14  6 11  0]
 [ 0  3  1 12  0]
 [ 0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.59      0.70      0.64        37
          B1       0.60      0.19      0.29        31
          B2       0.40      0.75      0.52        16
          C1       0.00      0.00      0.00         1

    accuracy                           0.51        86
   macro avg       0.32      0.33      0.29        86
weighted avg       0.54      0.51      0.48        86


Fold 4
[[ 0  1  0  0  0]
 [ 0 27  6  4  0]
 [ 0 11  7 13  0]
 [ 0  0  1 14  1]
 [ 0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.69      0.73      0.71        37
          B1       0.50      0.23      0.31        31
          B2       0.44      0.88      0.58        16
          C1       0.00      0.00      0.00         1

    accuracy                           0.56        86
   macro avg       0.33      0.37      0.32        86
weighted avg       0.56      0.56      0.53        86


K-fold scores
[0.4167404380887526, 0.3909497439442993, 0.43420068843454307, 0.478768409749034, 0.5263633890928873]
SKF f1 score mean 0.4494045338619032

LogisticRegression(C=1.0, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='multinomial', n_jobs=None,
                   penalty='l2', random_state=1234, solver='lbfgs', tol=0.0001,
                   verbose=0, warm_start=False)
Fold 0
[[ 0  2  0  0  0]
 [ 6 19  7  5  0]
 [ 2  7 13 10  0]
 [ 1  0  2 13  1]
 [ 0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         2
          A2       0.68      0.51      0.58        37
          B1       0.59      0.41      0.48        32
          B2       0.45      0.76      0.57        17
          C1       0.00      0.00      0.00         1

    accuracy                           0.51        89
   macro avg       0.34      0.34      0.33        89
weighted avg       0.58      0.51      0.52        89


Fold 1
[[ 1  0  0  0  0]
 [ 5  8 18  6  0]
 [ 0  4 13 11  3]
 [ 0  0  0 14  3]
 [ 0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.17      1.00      0.29         1
          A2       0.67      0.22      0.33        37
          B1       0.42      0.42      0.42        31
          B2       0.44      0.82      0.57        17
          C1       0.00      0.00      0.00         1

    accuracy                           0.41        87
   macro avg       0.34      0.49      0.32        87
weighted avg       0.52      0.41      0.40        87


Fold 2
[[ 0  0  0  1  0]
 [ 5  8 10  8  6]
 [ 3  8  6 13  1]
 [ 0  0  1 15  0]
 [ 0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.50      0.22      0.30        37
          B1       0.35      0.19      0.25        31
          B2       0.39      0.94      0.56        16
          C1       0.00      0.00      0.00         1

    accuracy                           0.34        86
   macro avg       0.25      0.27      0.22        86
weighted avg       0.42      0.34      0.32        86


Fold 3
[[ 1  0  0  0  0]
 [ 7  9 13  7  1]
 [ 0  4 14 11  2]
 [ 0  1  0 13  2]
 [ 0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.12      1.00      0.22         1
          A2       0.64      0.24      0.35        37
          B1       0.52      0.45      0.48        31
          B2       0.41      0.81      0.54        16
          C1       0.00      0.00      0.00         1

    accuracy                           0.43        86
   macro avg       0.34      0.50      0.32        86
weighted avg       0.54      0.43      0.43        86


Fold 4
[[ 1  0  0  0  0]
 [ 5  8 21  2  1]
 [ 2  0 16 13  0]
 [ 0  0  2 11  3]
 [ 0  0  0  0  1]]
              precision    recall  f1-score   support

          A1       0.12      1.00      0.22         1
          A2       1.00      0.22      0.36        37
          B1       0.41      0.52      0.46        31
          B2       0.42      0.69      0.52        16
          C1       0.20      1.00      0.33         1

    accuracy                           0.43        86
   macro avg       0.43      0.68      0.38        86
weighted avg       0.66      0.43      0.42        86


K-fold scores
[0.5241221605657366, 0.4032371569317382, 0.3233569791819024, 0.42922360069395304, 0.4216685123661868]
SKF f1 score mean 0.4203216819479034

************for dimension:  Orthography  ***************
Printing class statistics
Counter({'B1': 269, 'B2': 114, 'A2': 46, 'C1': 5})
RandomForestClassifier(bootstrap=True, class_weight='balanced',
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, min_impurity_decrease=0.0,
                       min_impurity_split=None, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=None, oob_score=False,
                       random_state=1234, verbose=0, warm_start=False)
Fold 0
[[ 0 10  0  0]
 [ 0 50  4  0]
 [ 0 16  7  0]
 [ 0  0  1  0]]
              precision    recall  f1-score   support

          A2       0.00      0.00      0.00        10
          B1       0.66      0.93      0.77        54
          B2       0.58      0.30      0.40        23
          C1       0.00      0.00      0.00         1

    accuracy                           0.65        88
   macro avg       0.31      0.31      0.29        88
weighted avg       0.56      0.65      0.58        88


Fold 1
[[ 0  9  0  0]
 [ 0 53  1  0]
 [ 0 13 10  0]
 [ 0  0  1  0]]
              precision    recall  f1-score   support

          A2       0.00      0.00      0.00         9
          B1       0.71      0.98      0.82        54
          B2       0.83      0.43      0.57        23
          C1       0.00      0.00      0.00         1

    accuracy                           0.72        87
   macro avg       0.39      0.35      0.35        87
weighted avg       0.66      0.72      0.66        87


Fold 2
[[ 0  9  0  0]
 [ 0 49  5  0]
 [ 0 14  9  0]
 [ 0  0  1  0]]
              precision    recall  f1-score   support

          A2       0.00      0.00      0.00         9
          B1       0.68      0.91      0.78        54
          B2       0.60      0.39      0.47        23
          C1       0.00      0.00      0.00         1

    accuracy                           0.67        87
   macro avg       0.32      0.32      0.31        87
weighted avg       0.58      0.67      0.61        87


Fold 3
[[ 0  9  0  0]
 [ 0 52  2  0]
 [ 0 17  6  0]
 [ 0  0  1  0]]
              precision    recall  f1-score   support

          A2       0.00      0.00      0.00         9
          B1       0.67      0.96      0.79        54
          B2       0.67      0.26      0.38        23
          C1       0.00      0.00      0.00         1

    accuracy                           0.67        87
   macro avg       0.33      0.31      0.29        87
weighted avg       0.59      0.67      0.59        87


Fold 4
[[ 0  8  1  0]
 [ 0 50  3  0]
 [ 0 13  9  0]
 [ 0  0  1  0]]
              precision    recall  f1-score   support

          A2       0.00      0.00      0.00         9
          B1       0.70      0.94      0.81        53
          B2       0.64      0.41      0.50        22
          C1       0.00      0.00      0.00         1

    accuracy                           0.69        85
   macro avg       0.34      0.34      0.33        85
weighted avg       0.61      0.69      0.63        85


K-fold scores
[0.5765734265734266, 0.6610913812196891, 0.6079854809437387, 0.588166144200627, 0.632258064516129]
SKF f1 score mean 0.6132148994907222

LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
          verbose=0)
Fold 0
[[ 2  8  0  0]
 [ 3 40 11  0]
 [ 0 11 12  0]
 [ 0  0  1  0]]
              precision    recall  f1-score   support

          A2       0.40      0.20      0.27        10
          B1       0.68      0.74      0.71        54
          B2       0.50      0.52      0.51        23
          C1       0.00      0.00      0.00         1

    accuracy                           0.61        88
   macro avg       0.39      0.37      0.37        88
weighted avg       0.59      0.61      0.60        88


Fold 1
[[ 2  7  0  0]
 [ 5 38 11  0]
 [ 0  8 15  0]
 [ 0  0  1  0]]
              precision    recall  f1-score   support

          A2       0.29      0.22      0.25         9
          B1       0.72      0.70      0.71        54
          B2       0.56      0.65      0.60        23
          C1       0.00      0.00      0.00         1

    accuracy                           0.63        87
   macro avg       0.39      0.39      0.39        87
weighted avg       0.62      0.63      0.63        87


Fold 2
[[ 5  4  0  0]
 [ 5 41  8  0]
 [ 0  9 14  0]
 [ 0  0  1  0]]
              precision    recall  f1-score   support

          A2       0.50      0.56      0.53         9
          B1       0.76      0.76      0.76        54
          B2       0.61      0.61      0.61        23
          C1       0.00      0.00      0.00         1

    accuracy                           0.69        87
   macro avg       0.47      0.48      0.47        87
weighted avg       0.68      0.69      0.69        87


Fold 3
[[ 4  3  2  0]
 [ 4 44  6  0]
 [ 0 10 12  1]
 [ 0  0  1  0]]
              precision    recall  f1-score   support

          A2       0.50      0.44      0.47         9
          B1       0.77      0.81      0.79        54
          B2       0.57      0.52      0.55        23
          C1       0.00      0.00      0.00         1

    accuracy                           0.69        87
   macro avg       0.46      0.45      0.45        87
weighted avg       0.68      0.69      0.68        87


Fold 4
[[ 1  6  2  0]
 [ 6 40  7  0]
 [ 0  9 13  0]
 [ 0  0  1  0]]
              precision    recall  f1-score   support

          A2       0.14      0.11      0.12         9
          B1       0.73      0.75      0.74        53
          B2       0.57      0.59      0.58        22
          C1       0.00      0.00      0.00         1

    accuracy                           0.64        85
   macro avg       0.36      0.36      0.36        85
weighted avg       0.61      0.64      0.62        85


K-fold scores
[0.5981981365148376, 0.6253464389300677, 0.6866303690260133, 0.6849604537231313, 0.6246514161220044]
SKF f1 score mean 0.6439573628632108

LogisticRegression(C=1.0, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='multinomial', n_jobs=None,
                   penalty='l2', random_state=1234, solver='lbfgs', tol=0.0001,
                   verbose=0, warm_start=False)
Fold 0
[[ 5  4  1  0]
 [ 7 33 13  1]
 [ 0 10 10  3]
 [ 0  0  0  1]]
              precision    recall  f1-score   support

          A2       0.42      0.50      0.45        10
          B1       0.70      0.61      0.65        54
          B2       0.42      0.43      0.43        23
          C1       0.20      1.00      0.33         1

    accuracy                           0.56        88
   macro avg       0.43      0.64      0.47        88
weighted avg       0.59      0.56      0.57        88


Fold 1
[[ 6  3  0  0]
 [12 29  8  5]
 [ 2  3 10  8]
 [ 0  0  0  1]]
              precision    recall  f1-score   support

          A2       0.30      0.67      0.41         9
          B1       0.83      0.54      0.65        54
          B2       0.56      0.43      0.49        23
          C1       0.07      1.00      0.13         1

    accuracy                           0.53        87
   macro avg       0.44      0.66      0.42        87
weighted avg       0.69      0.53      0.58        87


Fold 2
[[ 7  2  0  0]
 [12 24 16  2]
 [ 2  7  9  5]
 [ 0  0  1  0]]
              precision    recall  f1-score   support

          A2       0.33      0.78      0.47         9
          B1       0.73      0.44      0.55        54
          B2       0.35      0.39      0.37        23
          C1       0.00      0.00      0.00         1

    accuracy                           0.46        87
   macro avg       0.35      0.40      0.35        87
weighted avg       0.58      0.46      0.49        87


Fold 3
[[ 5  2  2  0]
 [ 6 33 12  3]
 [ 0  7  9  7]
 [ 0  0  0  1]]
              precision    recall  f1-score   support

          A2       0.45      0.56      0.50         9
          B1       0.79      0.61      0.69        54
          B2       0.39      0.39      0.39        23
          C1       0.09      1.00      0.17         1

    accuracy                           0.55        87
   macro avg       0.43      0.64      0.44        87
weighted avg       0.64      0.55      0.58        87


Fold 4
[[ 2  4  3  0]
 [11 28 14  0]
 [ 0  6 12  4]
 [ 0  0  0  1]]
              precision    recall  f1-score   support

          A2       0.15      0.22      0.18         9
          B1       0.74      0.53      0.62        53
          B2       0.41      0.55      0.47        22
          C1       0.20      1.00      0.33         1

    accuracy                           0.51        85
   macro avg       0.38      0.57      0.40        85
weighted avg       0.59      0.51      0.53        85


K-fold scores
[0.5676494390251404, 0.5777930424763773, 0.4878400349438229, 0.5838122605363986, 0.5286826207241433]
SKF f1 score mean 0.5491554795411766

************for dimension:  Vocabularyrange  ***************
Printing class statistics
Counter({'B2': 143, 'B1': 141, 'A2': 132, 'C1': 10, 'A1': 8})
RandomForestClassifier(bootstrap=True, class_weight='balanced',
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, min_impurity_decrease=0.0,
                       min_impurity_split=None, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=None, oob_score=False,
                       random_state=1234, verbose=0, warm_start=False)
Fold 0
[[ 0  2  0  0  0]
 [ 0 19  8  0  0]
 [ 0  4 18  7  0]
 [ 0  0  0 29  0]
 [ 0  0  0  2  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         2
          A2       0.76      0.70      0.73        27
          B1       0.69      0.62      0.65        29
          B2       0.76      1.00      0.87        29
          C1       0.00      0.00      0.00         2

    accuracy                           0.74        89
   macro avg       0.44      0.46      0.45        89
weighted avg       0.70      0.74      0.72        89


Fold 1
[[ 0  1  1  0  0]
 [ 0 21  6  0  0]
 [ 0  5 19  4  0]
 [ 0  0  0 29  0]
 [ 0  0  0  2  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         2
          A2       0.78      0.78      0.78        27
          B1       0.73      0.68      0.70        28
          B2       0.83      1.00      0.91        29
          C1       0.00      0.00      0.00         2

    accuracy                           0.78        88
   macro avg       0.47      0.49      0.48        88
weighted avg       0.74      0.78      0.76        88


Fold 2
[[ 0  2  0  0  0]
 [ 0 22  4  0  0]
 [ 0  5 18  5  0]
 [ 0  0  1 28  0]
 [ 0  0  0  2  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         2
          A2       0.76      0.85      0.80        26
          B1       0.78      0.64      0.71        28
          B2       0.80      0.97      0.88        29
          C1       0.00      0.00      0.00         2

    accuracy                           0.78        87
   macro avg       0.47      0.49      0.48        87
weighted avg       0.75      0.78      0.76        87


Fold 3
[[ 0  1  0  0  0]
 [ 0 19  7  0  0]
 [ 0  4 21  3  0]
 [ 0  0  1 27  0]
 [ 0  0  0  2  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.79      0.73      0.76        26
          B1       0.72      0.75      0.74        28
          B2       0.84      0.96      0.90        28
          C1       0.00      0.00      0.00         2

    accuracy                           0.79        85
   macro avg       0.47      0.49      0.48        85
weighted avg       0.76      0.79      0.77        85


Fold 4
[[ 0  1  0  0  0]
 [ 0 15 11  0  0]
 [ 0  5 16  7  0]
 [ 0  0  0 28  0]
 [ 0  0  0  2  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.71      0.58      0.64        26
          B1       0.59      0.57      0.58        28
          B2       0.76      1.00      0.86        28
          C1       0.00      0.00      0.00         2

    accuracy                           0.69        85
   macro avg       0.41      0.43      0.42        85
weighted avg       0.66      0.69      0.67        85


K-fold scores
[0.7170456744328956, 0.7611926557239058, 0.7579276538201487, 0.7716656346749226, 0.6707027140569067]
SKF f1 score mean 0.7357068665417559

LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
          verbose=0)
Fold 0
[[ 0  2  0  0  0]
 [ 0 18  9  0  0]
 [ 0  4 18  7  0]
 [ 0  0  0 29  0]
 [ 0  0  0  2  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         2
          A2       0.75      0.67      0.71        27
          B1       0.67      0.62      0.64        29
          B2       0.76      1.00      0.87        29
          C1       0.00      0.00      0.00         2

    accuracy                           0.73        89
   macro avg       0.44      0.46      0.44        89
weighted avg       0.69      0.73      0.71        89


Fold 1
[[ 1  0  1  0  0]
 [ 1 12 14  0  0]
 [ 0  1 23  4  0]
 [ 0  0  1 28  0]
 [ 0  0  0  2  0]]
              precision    recall  f1-score   support

          A1       0.50      0.50      0.50         2
          A2       0.92      0.44      0.60        27
          B1       0.59      0.82      0.69        28
          B2       0.82      0.97      0.89        29
          C1       0.00      0.00      0.00         2

    accuracy                           0.73        88
   macro avg       0.57      0.55      0.54        88
weighted avg       0.75      0.73      0.71        88


Fold 2
[[ 2  0  0  0  0]
 [ 2 17  6  1  0]
 [ 0  2 22  4  0]
 [ 0  0  1 27  1]
 [ 0  0  0  2  0]]
              precision    recall  f1-score   support

          A1       0.50      1.00      0.67         2
          A2       0.89      0.65      0.76        26
          B1       0.76      0.79      0.77        28
          B2       0.79      0.93      0.86        29
          C1       0.00      0.00      0.00         2

    accuracy                           0.78        87
   macro avg       0.59      0.67      0.61        87
weighted avg       0.79      0.78      0.78        87


Fold 3
[[ 0  1  0  0  0]
 [ 0 17  8  1  0]
 [ 0  3 22  3  0]
 [ 0  0  0 28  0]
 [ 0  0  0  2  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.81      0.65      0.72        26
          B1       0.73      0.79      0.76        28
          B2       0.82      1.00      0.90        28
          C1       0.00      0.00      0.00         2

    accuracy                           0.79        85
   macro avg       0.47      0.49      0.48        85
weighted avg       0.76      0.79      0.77        85


Fold 4
[[ 0  1  0  0  0]
 [ 0 12 14  0  0]
 [ 0  4 16  8  0]
 [ 0  0  0 28  0]
 [ 0  0  0  2  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.71      0.46      0.56        26
          B1       0.53      0.57      0.55        28
          B2       0.74      1.00      0.85        28
          C1       0.00      0.00      0.00         2

    accuracy                           0.66        85
   macro avg       0.40      0.41      0.39        85
weighted avg       0.63      0.66      0.63        85


K-fold scores
[0.7056871717326877, 0.7068370269862808, 0.7752753531337924, 0.7687083826975043, 0.6319703473720172]
SKF f1 score mean 0.7176956563844564

LogisticRegression(C=1.0, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='multinomial', n_jobs=None,
                   penalty='l2', random_state=1234, solver='lbfgs', tol=0.0001,
                   verbose=0, warm_start=False)
Fold 0
[[ 2  0  0  0  0]
 [ 6  7 11  0  3]
 [ 0  2 21  6  0]
 [ 0  0  0 25  4]
 [ 0  0  1  0  1]]
              precision    recall  f1-score   support

          A1       0.25      1.00      0.40         2
          A2       0.78      0.26      0.39        27
          B1       0.64      0.72      0.68        29
          B2       0.81      0.86      0.83        29
          C1       0.12      0.50      0.20         2

    accuracy                           0.63        89
   macro avg       0.52      0.67      0.50        89
weighted avg       0.71      0.63      0.62        89


Fold 1
[[ 1  0  1  0  0]
 [ 2  8 14  1  2]
 [ 0  1 22  4  1]
 [ 0  0  0 28  1]
 [ 0  0  0  1  1]]
              precision    recall  f1-score   support

          A1       0.33      0.50      0.40         2
          A2       0.89      0.30      0.44        27
          B1       0.59      0.79      0.68        28
          B2       0.82      0.97      0.89        29
          C1       0.20      0.50      0.29         2

    accuracy                           0.68        88
   macro avg       0.57      0.61      0.54        88
weighted avg       0.75      0.68      0.66        88


Fold 2
[[ 2  0  0  0  0]
 [ 6 10  9  1  0]
 [ 0  2 20  4  2]
 [ 0  0  2 26  1]
 [ 0  0  0  0  2]]
              precision    recall  f1-score   support

          A1       0.25      1.00      0.40         2
          A2       0.83      0.38      0.53        26
          B1       0.65      0.71      0.68        28
          B2       0.84      0.90      0.87        29
          C1       0.40      1.00      0.57         2

    accuracy                           0.69        87
   macro avg       0.59      0.80      0.61        87
weighted avg       0.75      0.69      0.69        87


Fold 3
[[ 0  0  1  0  0]
 [ 1  9 14  2  0]
 [ 1  1 23  1  2]
 [ 0  0  0 25  3]
 [ 0  0  0  1  1]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.90      0.35      0.50        26
          B1       0.61      0.82      0.70        28
          B2       0.86      0.89      0.88        28
          C1       0.17      0.50      0.25         2

    accuracy                           0.68        85
   macro avg       0.51      0.51      0.46        85
weighted avg       0.76      0.68      0.68        85


Fold 4
[[ 0  1  0  0  0]
 [11  6  8  1  0]
 [ 0  2 18  8  0]
 [ 0  0  0 23  5]
 [ 0  0  0  1  1]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.67      0.23      0.34        26
          B1       0.69      0.64      0.67        28
          B2       0.70      0.82      0.75        28
          C1       0.17      0.50      0.25         2

    accuracy                           0.56        85
   macro avg       0.44      0.44      0.40        85
weighted avg       0.67      0.56      0.58        85


K-fold scores
[0.6237284040111152, 0.6602619602619603, 0.6867063431030332, 0.67737123557557, 0.5787730174036828]
SKF f1 score mean 0.6453681920710723

************for dimension:  Vocabularycontrol  ***************
Printing class statistics
Counter({'B1': 182, 'A2': 131, 'B2': 100, 'C1': 16, 'A1': 5})
RandomForestClassifier(bootstrap=True, class_weight='balanced',
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, min_impurity_decrease=0.0,
                       min_impurity_split=None, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=None, oob_score=False,
                       random_state=1234, verbose=0, warm_start=False)
Fold 0
[[ 0  1  0  0  0]
 [ 0 18  9  0  0]
 [ 0  2 25 10  0]
 [ 0  2  8 10  0]
 [ 0  0  1  3  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.78      0.67      0.72        27
          B1       0.58      0.68      0.63        37
          B2       0.43      0.50      0.47        20
          C1       0.00      0.00      0.00         4

    accuracy                           0.60        89
   macro avg       0.36      0.37      0.36        89
weighted avg       0.58      0.60      0.58        89


Fold 1
[[ 0  1  0  0  0]
 [ 0 11 15  0  0]
 [ 0  6 26  5  0]
 [ 0  1 12  7  0]
 [ 0  0  1  2  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.58      0.42      0.49        26
          B1       0.48      0.70      0.57        37
          B2       0.50      0.35      0.41        20
          C1       0.00      0.00      0.00         3

    accuracy                           0.51        87
   macro avg       0.31      0.30      0.29        87
weighted avg       0.49      0.51      0.48        87


Fold 2
[[ 0  1  0  0  0]
 [ 0 19  7  0  0]
 [ 0 14 18  4  0]
 [ 0  0 12  8  0]
 [ 0  0  1  2  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.56      0.73      0.63        26
          B1       0.47      0.50      0.49        36
          B2       0.57      0.40      0.47        20
          C1       0.00      0.00      0.00         3

    accuracy                           0.52        86
   macro avg       0.32      0.33      0.32        86
weighted avg       0.50      0.52      0.50        86


Fold 3
[[ 0  1  0  0  0]
 [ 0 16 10  0  0]
 [ 0  8 18 10  0]
 [ 0  1 10  9  0]
 [ 0  0  0  3  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.62      0.62      0.62        26
          B1       0.47      0.50      0.49        36
          B2       0.41      0.45      0.43        20
          C1       0.00      0.00      0.00         3

    accuracy                           0.50        86
   macro avg       0.30      0.31      0.31        86
weighted avg       0.48      0.50      0.49        86


Fold 4
[[ 0  1  0  0  0]
 [ 0 12 14  0  0]
 [ 0  1 25 10  0]
 [ 0  0  6 14  0]
 [ 0  0  2  1  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.86      0.46      0.60        26
          B1       0.53      0.69      0.60        36
          B2       0.56      0.70      0.62        20
          C1       0.00      0.00      0.00         3

    accuracy                           0.59        86
   macro avg       0.39      0.37      0.36        86
weighted avg       0.61      0.59      0.58        86


K-fold scores
[0.5827789391168017, 0.48378462496109553, 0.5045574986751458, 0.4893597916853731, 0.578269667818561]
SKF f1 score mean 0.5277501044513955

LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
          verbose=0)
Fold 0
[[ 0  1  0  0  0]
 [ 0 24  2  1  0]
 [ 0 12  9 14  2]
 [ 0  2  1 16  1]
 [ 0  0  0  2  2]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.62      0.89      0.73        27
          B1       0.75      0.24      0.37        37
          B2       0.48      0.80      0.60        20
          C1       0.40      0.50      0.44         4

    accuracy                           0.57        89
   macro avg       0.45      0.49      0.43        89
weighted avg       0.63      0.57      0.53        89


Fold 1
[[ 0  1  0  0  0]
 [ 0 18  8  0  0]
 [ 0 16 10 10  1]
 [ 0  2  1 15  2]
 [ 0  0  0  3  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.49      0.69      0.57        26
          B1       0.53      0.27      0.36        37
          B2       0.54      0.75      0.63        20
          C1       0.00      0.00      0.00         3

    accuracy                           0.49        87
   macro avg       0.31      0.34      0.31        87
weighted avg       0.49      0.49      0.47        87


Fold 2
[[ 0  1  0  0  0]
 [ 0 24  2  0  0]
 [ 0 23  3 10  0]
 [ 0  1  3 16  0]
 [ 0  0  0  3  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.49      0.92      0.64        26
          B1       0.38      0.08      0.14        36
          B2       0.55      0.80      0.65        20
          C1       0.00      0.00      0.00         3

    accuracy                           0.50        86
   macro avg       0.28      0.36      0.29        86
weighted avg       0.43      0.50      0.40        86


Fold 3
[[ 0  1  0  0  0]
 [ 0 24  1  1  0]
 [ 0 14  5 17  0]
 [ 0  2  1 17  0]
 [ 0  0  0  3  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.59      0.92      0.72        26
          B1       0.71      0.14      0.23        36
          B2       0.45      0.85      0.59        20
          C1       0.00      0.00      0.00         3

    accuracy                           0.53        86
   macro avg       0.35      0.38      0.31        86
weighted avg       0.58      0.53      0.45        86


Fold 4
[[ 0  1  0  0  0]
 [ 0 18  7  1  0]
 [ 0 13  6 15  2]
 [ 0  0  1 19  0]
 [ 0  0  0  3  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.56      0.69      0.62        26
          B1       0.43      0.17      0.24        36
          B2       0.50      0.95      0.66        20
          C1       0.00      0.00      0.00         3

    accuracy                           0.50        86
   macro avg       0.30      0.36      0.30        86
weighted avg       0.47      0.50      0.44        86


K-fold scores
[0.5290050544600956, 0.4663382594417077, 0.4024455278940329, 0.45026856541781496, 0.44048115477145144]
SKF f1 score mean 0.45770771239702046

LogisticRegression(C=1.0, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='multinomial', n_jobs=None,
                   penalty='l2', random_state=1234, solver='lbfgs', tol=0.0001,
                   verbose=0, warm_start=False)
Fold 0
[[ 0  1  0  0  0]
 [ 1 22  1  3  0]
 [ 0 17  1 16  3]
 [ 0  2  0 11  7]
 [ 0  0  0  1  3]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.52      0.81      0.64        27
          B1       0.50      0.03      0.05        37
          B2       0.35      0.55      0.43        20
          C1       0.23      0.75      0.35         4

    accuracy                           0.42        89
   macro avg       0.32      0.43      0.29        89
weighted avg       0.46      0.42      0.33        89


Fold 1
[[ 0  1  0  0  0]
 [ 2 22  1  1  0]
 [ 0 21  4  8  4]
 [ 0  2  1 10  7]
 [ 0  0  1  1  1]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.48      0.85      0.61        26
          B1       0.57      0.11      0.18        37
          B2       0.50      0.50      0.50        20
          C1       0.08      0.33      0.13         3

    accuracy                           0.43        87
   macro avg       0.33      0.36      0.29        87
weighted avg       0.50      0.43      0.38        87


Fold 2
[[ 0  1  0  0  0]
 [ 4 21  0  0  1]
 [ 0 25  0  7  4]
 [ 0  3  2 13  2]
 [ 0  0  0  1  2]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.42      0.81      0.55        26
          B1       0.00      0.00      0.00        36
          B2       0.62      0.65      0.63        20
          C1       0.22      0.67      0.33         3

    accuracy                           0.42        86
   macro avg       0.25      0.42      0.30        86
weighted avg       0.28      0.42      0.33        86


Fold 3
[[ 0  1  0  0  0]
 [11 13  1  1  0]
 [ 0 16  3 13  4]
 [ 0  2  1 14  3]
 [ 0  0  0  2  1]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.41      0.50      0.45        26
          B1       0.60      0.08      0.15        36
          B2       0.47      0.70      0.56        20
          C1       0.12      0.33      0.18         3

    accuracy                           0.36        86
   macro avg       0.32      0.32      0.27        86
weighted avg       0.49      0.36      0.33        86


Fold 4
[[ 0  0  0  1  0]
 [ 2 21  1  2  0]
 [ 0 17  2 11  6]
 [ 0  1  0  9 10]
 [ 0  0  0  0  3]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.54      0.81      0.65        26
          B1       0.67      0.06      0.10        36
          B2       0.39      0.45      0.42        20
          C1       0.16      1.00      0.27         3

    accuracy                           0.41        86
   macro avg       0.35      0.46      0.29        86
weighted avg       0.54      0.41      0.35        86


K-fold scores
[0.3275735155961599, 0.3794961105305933, 0.3261784637430218, 0.33335953072295904, 0.34514630853192235]
SKF f1 score mean 0.3423507858249313

************for dimension:  CoherenceCohesion  ***************
Printing class statistics
Counter({'B1': 171, 'B2': 156, 'A2': 101, 'C1': 5, 'A1': 1})
RandomForestClassifier(bootstrap=True, class_weight='balanced',
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, min_impurity_decrease=0.0,
                       min_impurity_split=None, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=None, oob_score=False,
                       random_state=1234, verbose=0, warm_start=False)
Fold 0
[[13  7  1  0]
 [ 4 25  6  0]
 [ 0  2 30  0]
 [ 0  0  1  0]]
              precision    recall  f1-score   support

          A2       0.76      0.62      0.68        21
          B1       0.74      0.71      0.72        35
          B2       0.79      0.94      0.86        32
          C1       0.00      0.00      0.00         1

    accuracy                           0.76        89
   macro avg       0.57      0.57      0.57        89
weighted avg       0.75      0.76      0.75        89


Fold 1
[[ 0  1  0  0  0]
 [ 0 16  4  0  0]
 [ 0  5 26  3  0]
 [ 0  0  1 30  0]
 [ 0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.73      0.80      0.76        20
          B1       0.84      0.76      0.80        34
          B2       0.88      0.97      0.92        31
          C1       0.00      0.00      0.00         1

    accuracy                           0.83        87
   macro avg       0.49      0.51      0.50        87
weighted avg       0.81      0.83      0.82        87


Fold 2
[[13  6  1  0]
 [ 7 22  5  0]
 [ 0  1 30  0]
 [ 0  0  1  0]]
              precision    recall  f1-score   support

          A2       0.65      0.65      0.65        20
          B1       0.76      0.65      0.70        34
          B2       0.81      0.97      0.88        31
          C1       0.00      0.00      0.00         1

    accuracy                           0.76        86
   macro avg       0.55      0.57      0.56        86
weighted avg       0.74      0.76      0.75        86


Fold 3
[[12  6  2  0]
 [ 3 26  5  0]
 [ 0  1 30  0]
 [ 0  0  1  0]]
              precision    recall  f1-score   support

          A2       0.80      0.60      0.69        20
          B1       0.79      0.76      0.78        34
          B2       0.79      0.97      0.87        31
          C1       0.00      0.00      0.00         1

    accuracy                           0.79        86
   macro avg       0.59      0.58      0.58        86
weighted avg       0.78      0.79      0.78        86


Fold 4
[[ 7 13  0  0]
 [ 2 29  3  0]
 [ 0  0 31  0]
 [ 0  0  1  0]]
              precision    recall  f1-score   support

          A2       0.78      0.35      0.48        20
          B1       0.69      0.85      0.76        34
          B2       0.89      1.00      0.94        31
          C1       0.00      0.00      0.00         1

    accuracy                           0.78        86
   macro avg       0.59      0.55      0.55        86
weighted avg       0.77      0.78      0.75        86


K-fold scores
[0.7545990036155362, 0.816706664982527, 0.7453368944477015, 0.7797542692431242, 0.7526017785588124]
SKF f1 score mean 0.7697997221695403

LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
          verbose=0)
Fold 0
[[12  8  1  0]
 [ 4 25  6  0]
 [ 0  2 30  0]
 [ 0  0  1  0]]
              precision    recall  f1-score   support

          A2       0.75      0.57      0.65        21
          B1       0.71      0.71      0.71        35
          B2       0.79      0.94      0.86        32
          C1       0.00      0.00      0.00         1

    accuracy                           0.75        89
   macro avg       0.56      0.56      0.56        89
weighted avg       0.74      0.75      0.74        89


Fold 1
[[ 0  0  1  0  0]
 [ 0 16  4  0  0]
 [ 0  3 28  3  0]
 [ 0  0  1 30  0]
 [ 0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.84      0.80      0.82        20
          B1       0.82      0.82      0.82        34
          B2       0.88      0.97      0.92        31
          C1       0.00      0.00      0.00         1

    accuracy                           0.85        87
   macro avg       0.51      0.52      0.51        87
weighted avg       0.83      0.85      0.84        87


Fold 2
[[13  7  0  0]
 [ 3 25  6  0]
 [ 0  2 29  0]
 [ 0  0  1  0]]
              precision    recall  f1-score   support

          A2       0.81      0.65      0.72        20
          B1       0.74      0.74      0.74        34
          B2       0.81      0.94      0.87        31
          C1       0.00      0.00      0.00         1

    accuracy                           0.78        86
   macro avg       0.59      0.58      0.58        86
weighted avg       0.77      0.78      0.77        86


Fold 3
[[10  9  1  0]
 [ 3 25  6  0]
 [ 0  1 30  0]
 [ 0  0  1  0]]
              precision    recall  f1-score   support

          A2       0.77      0.50      0.61        20
          B1       0.71      0.74      0.72        34
          B2       0.79      0.97      0.87        31
          C1       0.00      0.00      0.00         1

    accuracy                           0.76        86
   macro avg       0.57      0.55      0.55        86
weighted avg       0.75      0.76      0.74        86


Fold 4
[[ 6 13  1  0]
 [ 2 29  3  0]
 [ 0  0 31  0]
 [ 0  0  1  0]]
              precision    recall  f1-score   support

          A2       0.75      0.30      0.43        20
          B1       0.69      0.85      0.76        34
          B2       0.86      1.00      0.93        31
          C1       0.00      0.00      0.00         1

    accuracy                           0.77        86
   macro avg       0.58      0.54      0.53        86
weighted avg       0.76      0.77      0.73        86


K-fold scores
[0.7421370005639669, 0.8393751842027704, 0.7707007597670563, 0.7408769188344517, 0.7349460948448873]
SKF f1 score mean 0.7656071916426266

LogisticRegression(C=1.0, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='multinomial', n_jobs=None,
                   penalty='l2', random_state=1234, solver='lbfgs', tol=0.0001,
                   verbose=0, warm_start=False)
Fold 0
[[10  7  3  0]
 [ 5 26  3  1]
 [ 0  3 29  0]
 [ 0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         0
          A2       0.67      0.48      0.56        21
          B1       0.72      0.74      0.73        35
          B2       0.81      0.91      0.85        32
          C1       0.00      0.00      0.00         1

    accuracy                           0.73        89
   macro avg       0.44      0.43      0.43        89
weighted avg       0.73      0.73      0.73        89


Fold 1
[[ 0  0  1  0  0]
 [ 0 15  4  1  0]
 [ 0  2 27  5  0]
 [ 0  0  1 28  2]
 [ 0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.88      0.75      0.81        20
          B1       0.82      0.79      0.81        34
          B2       0.80      0.90      0.85        31
          C1       0.00      0.00      0.00         1

    accuracy                           0.80        87
   macro avg       0.50      0.49      0.49        87
weighted avg       0.81      0.80      0.80        87


Fold 2
[[11  9  0  0]
 [ 2 25  6  0]
 [ 0  3 26  2]
 [ 0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         0
          A2       0.85      0.55      0.67        20
          B1       0.68      0.74      0.70        34
          B2       0.79      0.84      0.81        31
          C1       0.00      0.00      0.00         1

    accuracy                           0.72        86
   macro avg       0.46      0.42      0.44        86
weighted avg       0.75      0.72      0.73        86


Fold 3
[[ 7  9  2  0]
 [ 4 25  5  0]
 [ 0  1 29  1]
 [ 0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         0
          A2       0.64      0.35      0.45        20
          B1       0.71      0.74      0.72        34
          B2       0.78      0.94      0.85        31
          C1       0.00      0.00      0.00         1

    accuracy                           0.71        86
   macro avg       0.43      0.40      0.41        86
weighted avg       0.71      0.71      0.70        86


Fold 4
[[ 4 12  1  0]
 [ 2 28  4  0]
 [ 0  0 30  1]
 [ 0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         0
          A2       0.67      0.20      0.31        20
          B1       0.70      0.82      0.76        34
          B2       0.83      0.97      0.90        31
          C1       0.00      0.00      0.00         1

    accuracy                           0.72        86
   macro avg       0.44      0.40      0.39        86
weighted avg       0.73      0.72      0.69        86


K-fold scores
[0.7257818778722123, 0.8037038114238321, 0.7263313407577247, 0.69896646156424, 0.6935438362026353]
SKF f1 score mean 0.7296654655641289

************for dimension:  Sociolinguisticappropriateness  ***************
Printing class statistics
Counter({'A1': 261, 'A2': 106, 'B1': 63, 'B2': 4})
RandomForestClassifier(bootstrap=True, class_weight='balanced',
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, min_impurity_decrease=0.0,
                       min_impurity_split=None, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=None, oob_score=False,
                       random_state=1234, verbose=0, warm_start=False)
Fold 0
[[51  2  0  0]
 [ 2 18  2  0]
 [ 0  9  4  0]
 [ 0  1  0  0]]
              precision    recall  f1-score   support

          A1       0.96      0.96      0.96        53
          A2       0.60      0.82      0.69        22
          B1       0.67      0.31      0.42        13
          B2       0.00      0.00      0.00         1

    accuracy                           0.82        89
   macro avg       0.56      0.52      0.52        89
weighted avg       0.82      0.82      0.81        89


Fold 1
[[48  4  0  0]
 [ 1 16  4  0]
 [ 0  8  5  0]
 [ 0  1  0  0]]
              precision    recall  f1-score   support

          A1       0.98      0.92      0.95        52
          A2       0.55      0.76      0.64        21
          B1       0.56      0.38      0.45        13
          B2       0.00      0.00      0.00         1

    accuracy                           0.79        87
   macro avg       0.52      0.52      0.51        87
weighted avg       0.80      0.79      0.79        87


Fold 2
[[50  2  0]
 [ 1 17  3]
 [ 0  9  4]]
              precision    recall  f1-score   support

          A1       0.98      0.96      0.97        52
          A2       0.61      0.81      0.69        21
          B1       0.57      0.31      0.40        13

    accuracy                           0.83        86
   macro avg       0.72      0.69      0.69        86
weighted avg       0.83      0.83      0.82        86


Fold 3
[[48  4  0  0]
 [ 2 19  0  0]
 [ 0  8  4  0]
 [ 0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.96      0.92      0.94        52
          A2       0.61      0.90      0.73        21
          B1       0.80      0.33      0.47        12
          B2       0.00      0.00      0.00         1

    accuracy                           0.83        86
   macro avg       0.59      0.54      0.54        86
weighted avg       0.84      0.83      0.81        86


Fold 4
[[47  4  1  0]
 [ 1 18  2  0]
 [ 0  6  6  0]
 [ 0  1  0  0]]
              precision    recall  f1-score   support

          A1       0.98      0.90      0.94        52
          A2       0.62      0.86      0.72        21
          B1       0.67      0.50      0.57        12
          B2       0.00      0.00      0.00         1

    accuracy                           0.83        86
   macro avg       0.57      0.57      0.56        86
weighted avg       0.84      0.83      0.82        86


K-fold scores
[0.8056680161943319, 0.7905153273948085, 0.8169402961003773, 0.8131905713985056, 0.823920265780731]
SKF f1 score mean 0.8100468953737507

LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
          verbose=0)
Fold 0
[[51  1  1  0]
 [ 2 14  6  0]
 [ 0  6  7  0]
 [ 0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.96      0.96      0.96        53
          A2       0.67      0.64      0.65        22
          B1       0.47      0.54      0.50        13
          B2       0.00      0.00      0.00         1

    accuracy                           0.81        89
   macro avg       0.52      0.53      0.53        89
weighted avg       0.81      0.81      0.81        89


Fold 1
[[47  5  0  0]
 [ 1 18  2  0]
 [ 0  9  4  0]
 [ 0  1  0  0]]
              precision    recall  f1-score   support

          A1       0.98      0.90      0.94        52
          A2       0.55      0.86      0.67        21
          B1       0.67      0.31      0.42        13
          B2       0.00      0.00      0.00         1

    accuracy                           0.79        87
   macro avg       0.55      0.52      0.51        87
weighted avg       0.82      0.79      0.79        87


Fold 2
[[50  2  0]
 [ 0 16  5]
 [ 0  8  5]]
              precision    recall  f1-score   support

          A1       1.00      0.96      0.98        52
          A2       0.62      0.76      0.68        21
          B1       0.50      0.38      0.43        13

    accuracy                           0.83        86
   macro avg       0.71      0.70      0.70        86
weighted avg       0.83      0.83      0.82        86


Fold 3
[[48  4  0  0]
 [ 2 18  1  0]
 [ 0  8  4  0]
 [ 0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.96      0.92      0.94        52
          A2       0.60      0.86      0.71        21
          B1       0.67      0.33      0.44        12
          B2       0.00      0.00      0.00         1

    accuracy                           0.81        86
   macro avg       0.56      0.53      0.52        86
weighted avg       0.82      0.81      0.80        86


Fold 4
[[47  5  0  0]
 [ 1 17  3  0]
 [ 0  7  5  0]
 [ 0  1  0  0]]
              precision    recall  f1-score   support

          A1       0.98      0.90      0.94        52
          A2       0.57      0.81      0.67        21
          B1       0.62      0.42      0.50        12
          B2       0.00      0.00      0.00         1

    accuracy                           0.80        86
   macro avg       0.54      0.53      0.53        86
weighted avg       0.82      0.80      0.80        86


K-fold scores
[0.8070290044421218, 0.7856745311554748, 0.8247725396550205, 0.8034655722754217, 0.8009302325581394]
SKF f1 score mean 0.8043743760172356

LogisticRegression(C=1.0, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='multinomial', n_jobs=None,
                   penalty='l2', random_state=1234, solver='lbfgs', tol=0.0001,
                   verbose=0, warm_start=False)
Fold 0
[[50  0  1  2]
 [ 2  6 14  0]
 [ 0  1 12  0]
 [ 0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.96      0.94      0.95        53
          A2       0.86      0.27      0.41        22
          B1       0.43      0.92      0.59        13
          B2       0.00      0.00      0.00         1

    accuracy                           0.76        89
   macro avg       0.56      0.53      0.49        89
weighted avg       0.85      0.76      0.75        89


Fold 1
[[47  2  2  1]
 [ 1  6 11  3]
 [ 0  2 10  1]
 [ 0  1  0  0]]
              precision    recall  f1-score   support

          A1       0.98      0.90      0.94        52
          A2       0.55      0.29      0.37        21
          B1       0.43      0.77      0.56        13
          B2       0.00      0.00      0.00         1

    accuracy                           0.72        87
   macro avg       0.49      0.49      0.47        87
weighted avg       0.78      0.72      0.74        87


Fold 2
[[49  2  1]
 [ 1  5 14]
 [ 0  1 11]]
              precision    recall  f1-score   support

          A1       0.98      0.94      0.96        52
          A2       0.62      0.24      0.34        21
          B1       0.42      0.85      0.56        13
          B2       0.00      0.00      0.00         0

    accuracy                           0.76        86
   macro avg       0.51      0.51      0.47        86
weighted avg       0.81      0.76      0.75        86


Fold 3
[[48  3  1  0]
 [ 2 12  4  3]
 [ 0  3  9  0]
 [ 0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.96      0.92      0.94        52
          A2       0.67      0.57      0.62        21
          B1       0.60      0.75      0.67        12
          B2       0.00      0.00      0.00         1

    accuracy                           0.80        86
   macro avg       0.56      0.56      0.56        86
weighted avg       0.83      0.80      0.81        86


Fold 4
[[44  5  3  0]
 [ 1  8 10  2]
 [ 0  1  9  2]
 [ 0  1  0  0]]
              precision    recall  f1-score   support

          A1       0.98      0.85      0.91        52
          A2       0.53      0.38      0.44        21
          B1       0.41      0.75      0.53        12
          B2       0.00      0.00      0.00         1

    accuracy                           0.71        86
   macro avg       0.48      0.49      0.47        86
weighted avg       0.78      0.71      0.73        86


K-fold scores
[0.7549370207821745, 0.7353703703703703, 0.7504127553186472, 0.8123750394612227, 0.7309480493228219]
SKF f1 score mean 0.7568086470510473

DOING MULTILANG CLASSIFICATION
1024
1024
1024
************for dimension:  OverallCEFRrating  ***************
RandomForestClassifier(bootstrap=True, class_weight='balanced',
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, min_impurity_decrease=0.0,
                       min_impurity_split=None, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=None, oob_score=False,
                       random_state=1234, verbose=0, warm_start=False)
Fold 0
[[  0  17   0   0   0]
 [  0 135  40   0   0]
 [  0  42 117  18   0]
 [  0   0  22  53   0]
 [  0   0   1   8   0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        17
          A2       0.70      0.77      0.73       175
          B1       0.65      0.66      0.66       177
          B2       0.67      0.71      0.69        75
          C1       0.00      0.00      0.00         9

    accuracy                           0.67       453
   macro avg       0.40      0.43      0.42       453
weighted avg       0.63      0.67      0.65       453


Fold 1
[[  1  16   0   0   0]
 [  0 139  36   0   0]
 [  0  33 125  19   0]
 [  0   2  20  53   0]
 [  0   0   2   7   0]]
              precision    recall  f1-score   support

          A1       1.00      0.06      0.11        17
          A2       0.73      0.79      0.76       175
          B1       0.68      0.71      0.69       177
          B2       0.67      0.71      0.69        75
          C1       0.00      0.00      0.00         9

    accuracy                           0.70       453
   macro avg       0.62      0.45      0.45       453
weighted avg       0.70      0.70      0.68       453


Fold 2
[[  0  17   0   0   0]
 [  0 143  32   0   0]
 [  0  37 126  14   0]
 [  0   1  22  52   0]
 [  0   0   0   8   0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        17
          A2       0.72      0.82      0.77       175
          B1       0.70      0.71      0.71       177
          B2       0.70      0.69      0.70        75
          C1       0.00      0.00      0.00         8

    accuracy                           0.71       452
   macro avg       0.42      0.44      0.43       452
weighted avg       0.67      0.71      0.69       452


Fold 3
[[  0  17   0   0   0]
 [  0 148  27   0   0]
 [  0  30 129  18   0]
 [  0   1  25  49   0]
 [  0   0   0   8   0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        17
          A2       0.76      0.85      0.80       175
          B1       0.71      0.73      0.72       177
          B2       0.65      0.65      0.65        75
          C1       0.00      0.00      0.00         8

    accuracy                           0.72       452
   macro avg       0.42      0.45      0.43       452
weighted avg       0.68      0.72      0.70       452


Fold 4
[[  0  15   2   0   0]
 [  0 149  25   0   0]
 [  0  42 117  18   0]
 [  0   0  26  48   0]
 [  0   0   0   8   0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        17
          A2       0.72      0.86      0.78       174
          B1       0.69      0.66      0.67       177
          B2       0.65      0.65      0.65        74
          C1       0.00      0.00      0.00         8

    accuracy                           0.70       450
   macro avg       0.41      0.43      0.42       450
weighted avg       0.66      0.70      0.68       450


K-fold scores
[0.652735019500818, 0.6837011112843463, 0.6890983968787736, 0.6995161520515731, 0.6751396936144396]
SKF f1 score mean 0.6800380746659901

LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
          verbose=0)
Fold 0
[[  5  12   0   0   0]
 [ 12 128  33   2   0]
 [  1  53  95  27   1]
 [  0   1   6  64   4]
 [  0   0   0   6   3]]
              precision    recall  f1-score   support

          A1       0.28      0.29      0.29        17
          A2       0.66      0.73      0.69       175
          B1       0.71      0.54      0.61       177
          B2       0.65      0.85      0.74        75
          C1       0.38      0.33      0.35         9

    accuracy                           0.65       453
   macro avg       0.53      0.55      0.54       453
weighted avg       0.66      0.65      0.65       453


Fold 1
[[  5  12   0   0   0]
 [ 17 125  30   3   0]
 [  0  43 103  30   1]
 [  0   3   3  65   4]
 [  0   0   0   7   2]]
              precision    recall  f1-score   support

          A1       0.23      0.29      0.26        17
          A2       0.68      0.71      0.70       175
          B1       0.76      0.58      0.66       177
          B2       0.62      0.87      0.72        75
          C1       0.29      0.22      0.25         9

    accuracy                           0.66       453
   macro avg       0.51      0.54      0.52       453
weighted avg       0.68      0.66      0.66       453


Fold 2
[[  8   9   0   0   0]
 [ 18 138  17   2   0]
 [  1  46  97  33   0]
 [  1   1   5  63   5]
 [  0   0   0   7   1]]
              precision    recall  f1-score   support

          A1       0.29      0.47      0.36        17
          A2       0.71      0.79      0.75       175
          B1       0.82      0.55      0.66       177
          B2       0.60      0.84      0.70        75
          C1       0.17      0.12      0.14         8

    accuracy                           0.68       452
   macro avg       0.52      0.55      0.52       452
weighted avg       0.71      0.68      0.68       452


Fold 3
[[  9   7   1   0   0]
 [  4 145  23   3   0]
 [  3  34 101  39   0]
 [  0   1   9  62   3]
 [  0   0   0   7   1]]
              precision    recall  f1-score   support

          A1       0.56      0.53      0.55        17
          A2       0.78      0.83      0.80       175
          B1       0.75      0.57      0.65       177
          B2       0.56      0.83      0.67        75
          C1       0.25      0.12      0.17         8

    accuracy                           0.70       452
   macro avg       0.58      0.58      0.57       452
weighted avg       0.71      0.70      0.70       452


Fold 4
[[  6   8   3   0   0]
 [  7 144  22   1   0]
 [  0  54  93  30   0]
 [  0   2   7  65   0]
 [  0   0   0   7   1]]
              precision    recall  f1-score   support

          A1       0.46      0.35      0.40        17
          A2       0.69      0.83      0.75       174
          B1       0.74      0.53      0.62       177
          B2       0.63      0.88      0.73        74
          C1       1.00      0.12      0.22         8

    accuracy                           0.69       450
   macro avg       0.71      0.54      0.55       450
weighted avg       0.70      0.69      0.67       450


K-fold scores
[0.6462478798281099, 0.6610912973858902, 0.6782928479804154, 0.698593055302847, 0.6736101141556988]
SKF f1 score mean 0.6715670389305923

LogisticRegression(C=1.0, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='multinomial', n_jobs=None,
                   penalty='l2', random_state=1234, solver='lbfgs', tol=0.0001,
                   verbose=0, warm_start=False)
Fold 0
[[15  2  0  0  0]
 [56 82 33  2  2]
 [22 64 60 29  2]
 [ 4  0 18 37 16]
 [ 0  0  1  0  8]]
              precision    recall  f1-score   support

          A1       0.15      0.88      0.26        17
          A2       0.55      0.47      0.51       175
          B1       0.54      0.34      0.42       177
          B2       0.54      0.49      0.52        75
          C1       0.29      0.89      0.43         9

    accuracy                           0.45       453
   macro avg       0.41      0.61      0.43       453
weighted avg       0.52      0.45      0.46       453


Fold 1
[[ 9  8  0  0  0]
 [62 80 21 10  2]
 [16 49 78 31  3]
 [ 2  4 16 29 24]
 [ 0  0  1  1  7]]
              precision    recall  f1-score   support

          A1       0.10      0.53      0.17        17
          A2       0.57      0.46      0.51       175
          B1       0.67      0.44      0.53       177
          B2       0.41      0.39      0.40        75
          C1       0.19      0.78      0.31         9

    accuracy                           0.45       453
   macro avg       0.39      0.52      0.38       453
weighted avg       0.56      0.45      0.48       453


Fold 2
[[15  2  0  0  0]
 [64 85 15 10  1]
 [17 47 80 29  4]
 [ 2  2 11 43 17]
 [ 0  0  1  1  6]]
              precision    recall  f1-score   support

          A1       0.15      0.88      0.26        17
          A2       0.62      0.49      0.55       175
          B1       0.75      0.45      0.56       177
          B2       0.52      0.57      0.54        75
          C1       0.21      0.75      0.33         8

    accuracy                           0.51       452
   macro avg       0.45      0.63      0.45       452
weighted avg       0.63      0.51      0.54       452


Fold 3
[[17  0  0  0  0]
 [61 82 19 10  3]
 [17 45 80 33  2]
 [ 3  4 10 34 24]
 [ 0  0  0  4  4]]
              precision    recall  f1-score   support

          A1       0.17      1.00      0.30        17
          A2       0.63      0.47      0.54       175
          B1       0.73      0.45      0.56       177
          B2       0.42      0.45      0.44        75
          C1       0.12      0.50      0.20         8

    accuracy                           0.48       452
   macro avg       0.41      0.57      0.40       452
weighted avg       0.61      0.48      0.51       452


Fold 4
[[12  3  2  0  0]
 [63 88 14  9  0]
 [14 59 70 32  2]
 [ 0  4  5 49 16]
 [ 0  0  1  3  4]]
              precision    recall  f1-score   support

          A1       0.13      0.71      0.23        17
          A2       0.57      0.51      0.54       174
          B1       0.76      0.40      0.52       177
          B2       0.53      0.66      0.59        74
          C1       0.18      0.50      0.27         8

    accuracy                           0.50       450
   macro avg       0.44      0.55      0.43       450
weighted avg       0.62      0.50      0.52       450


K-fold scores
[0.46252994208890735, 0.48195985825014054, 0.5382781148933232, 0.5134761038778035, 0.5219830053423311]
SKF f1 score mean 0.5036454048905011

************for dimension:  Grammaticalaccuracy  ***************
RandomForestClassifier(bootstrap=True, class_weight='balanced',
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, min_impurity_decrease=0.0,
                       min_impurity_split=None, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=None, oob_score=False,
                       random_state=1234, verbose=0, warm_start=False)
Fold 0
[[  5  28   0   0   0]
 [  2  86  49   6   0]
 [  0  36 109  32   0]
 [  0   1  38  52   0]
 [  0   0   2   9   0]]
              precision    recall  f1-score   support

          A1       0.71      0.15      0.25        33
          A2       0.57      0.60      0.59       143
          B1       0.55      0.62      0.58       177
          B2       0.53      0.57      0.55        91
          C1       0.00      0.00      0.00        11

    accuracy                           0.55       455
   macro avg       0.47      0.39      0.39       455
weighted avg       0.55      0.55      0.54       455


Fold 1
[[  1  30   2   0   0]
 [  2  82  52   6   0]
 [  0  45 102  29   0]
 [  0   4  42  44   0]
 [  0   0   0  11   0]]
              precision    recall  f1-score   support

          A1       0.33      0.03      0.06        33
          A2       0.51      0.58      0.54       142
          B1       0.52      0.58      0.55       176
          B2       0.49      0.49      0.49        90
          C1       0.00      0.00      0.00        11

    accuracy                           0.51       452
   macro avg       0.37      0.34      0.33       452
weighted avg       0.48      0.51      0.48       452


Fold 2
[[  3  27   3   0   0]
 [  4  88  50   0   0]
 [  1  42 114  19   0]
 [  0   5  36  49   0]
 [  0   0   2   8   0]]
              precision    recall  f1-score   support

          A1       0.38      0.09      0.15        33
          A2       0.54      0.62      0.58       142
          B1       0.56      0.65      0.60       176
          B2       0.64      0.54      0.59        90
          C1       0.00      0.00      0.00        10

    accuracy                           0.56       451
   macro avg       0.42      0.38      0.38       451
weighted avg       0.54      0.56      0.54       451


Fold 3
[[  4  23   6   0   0]
 [  0  89  50   3   0]
 [  1  40 103  32   0]
 [  0   1  41  48   0]
 [  0   0   2   8   0]]
              precision    recall  f1-score   support

          A1       0.80      0.12      0.21        33
          A2       0.58      0.63      0.60       142
          B1       0.51      0.59      0.54       176
          B2       0.53      0.53      0.53        90
          C1       0.00      0.00      0.00        10

    accuracy                           0.54       451
   macro avg       0.48      0.37      0.38       451
weighted avg       0.55      0.54      0.52       451


Fold 4
[[  1  26   6   0   0]
 [  1  72  65   4   0]
 [  1  40 118  17   0]
 [  0   1  40  49   0]
 [  0   0   1   9   0]]
              precision    recall  f1-score   support

          A1       0.33      0.03      0.06        33
          A2       0.52      0.51      0.51       142
          B1       0.51      0.67      0.58       176
          B2       0.62      0.54      0.58        90
          C1       0.00      0.00      0.00        10

    accuracy                           0.53       451
   macro avg       0.40      0.35      0.35       451
weighted avg       0.51      0.53      0.51       451


K-fold scores
[0.537618440134874, 0.48383057332281904, 0.5443351649104737, 0.5238999443424261, 0.507975131793775]
SKF f1 score mean 0.5195318509008736

LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
          verbose=0)
Fold 0
[[18 12  3  0  0]
 [22 75 37  9  0]
 [ 3 50 74 50  0]
 [ 0  3 21 60  7]
 [ 0  0  0  9  2]]
              precision    recall  f1-score   support

          A1       0.42      0.55      0.47        33
          A2       0.54      0.52      0.53       143
          B1       0.55      0.42      0.47       177
          B2       0.47      0.66      0.55        91
          C1       0.22      0.18      0.20        11

    accuracy                           0.50       455
   macro avg       0.44      0.47      0.45       455
weighted avg       0.51      0.50      0.50       455


Fold 1
[[14 17  2  0  0]
 [23 69 40  9  1]
 [14 47 72 42  1]
 [ 0  4 23 59  4]
 [ 0  0  0 11  0]]
              precision    recall  f1-score   support

          A1       0.27      0.42      0.33        33
          A2       0.50      0.49      0.49       142
          B1       0.53      0.41      0.46       176
          B2       0.49      0.66      0.56        90
          C1       0.00      0.00      0.00        11

    accuracy                           0.47       452
   macro avg       0.36      0.39      0.37       452
weighted avg       0.48      0.47      0.47       452


Fold 2
[[20 10  3  0  0]
 [29 75 36  2  0]
 [ 9 56 74 36  1]
 [ 0  6 19 60  5]
 [ 0  0  0  7  3]]
              precision    recall  f1-score   support

          A1       0.34      0.61      0.44        33
          A2       0.51      0.53      0.52       142
          B1       0.56      0.42      0.48       176
          B2       0.57      0.67      0.62        90
          C1       0.33      0.30      0.32        10

    accuracy                           0.51       451
   macro avg       0.46      0.50      0.47       451
weighted avg       0.53      0.51      0.51       451


Fold 3
[[18 11  4  0  0]
 [30 70 37  5  0]
 [ 6 49 72 48  1]
 [ 0  2 19 63  6]
 [ 0  0  0 10  0]]
              precision    recall  f1-score   support

          A1       0.33      0.55      0.41        33
          A2       0.53      0.49      0.51       142
          B1       0.55      0.41      0.47       176
          B2       0.50      0.70      0.58        90
          C1       0.00      0.00      0.00        10

    accuracy                           0.49       451
   macro avg       0.38      0.43      0.40       451
weighted avg       0.50      0.49      0.49       451


Fold 4
[[18 11  4  0  0]
 [27 70 35 10  0]
 [ 8 44 86 38  0]
 [ 1  5 21 63  0]
 [ 0  0  0  9  1]]
              precision    recall  f1-score   support

          A1       0.33      0.55      0.41        33
          A2       0.54      0.49      0.51       142
          B1       0.59      0.49      0.53       176
          B2       0.53      0.70      0.60        90
          C1       1.00      0.10      0.18        10

    accuracy                           0.53       451
   macro avg       0.60      0.47      0.45       451
weighted avg       0.55      0.53      0.52       451


K-fold scores
[0.49989271233202326, 0.47022026261211747, 0.5129087701634353, 0.49001248608659603, 0.5245543500805787]
SKF f1 score mean 0.4995177162549501

LogisticRegression(C=1.0, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='multinomial', n_jobs=None,
                   penalty='l2', random_state=1234, solver='lbfgs', tol=0.0001,
                   verbose=0, warm_start=False)
Fold 0
[[27  5  0  1  0]
 [59 47 23 10  4]
 [28 47 50 50  2]
 [ 5  5 14 38 29]
 [ 0  0  1  2  8]]
              precision    recall  f1-score   support

          A1       0.23      0.82      0.36        33
          A2       0.45      0.33      0.38       143
          B1       0.57      0.28      0.38       177
          B2       0.38      0.42      0.40        91
          C1       0.19      0.73      0.30        11

    accuracy                           0.37       455
   macro avg       0.36      0.51      0.36       455
weighted avg       0.46      0.37      0.38       455


Fold 1
[[27  6  0  0  0]
 [76 33 20 12  1]
 [44 42 45 38  7]
 [ 4  6 20 39 21]
 [ 0  0  0  4  7]]
              precision    recall  f1-score   support

          A1       0.18      0.82      0.29        33
          A2       0.38      0.23      0.29       142
          B1       0.53      0.26      0.34       176
          B2       0.42      0.43      0.43        90
          C1       0.19      0.64      0.30        11

    accuracy                           0.33       452
   macro avg       0.34      0.48      0.33       452
weighted avg       0.43      0.33      0.34       452


Fold 2
[[27  3  2  1  0]
 [69 46 17  5  5]
 [39 52 41 38  6]
 [ 2  6 13 41 28]
 [ 0  0  0  3  7]]
              precision    recall  f1-score   support

          A1       0.20      0.82      0.32        33
          A2       0.43      0.32      0.37       142
          B1       0.56      0.23      0.33       176
          B2       0.47      0.46      0.46        90
          C1       0.15      0.70      0.25        10

    accuracy                           0.36       451
   macro avg       0.36      0.51      0.35       451
weighted avg       0.47      0.36      0.37       451


Fold 3
[[26  4  3  0  0]
 [67 44 18 10  3]
 [27 50 48 48  3]
 [ 2  3 15 52 18]
 [ 0  0  0  3  7]]
              precision    recall  f1-score   support

          A1       0.21      0.79      0.34        33
          A2       0.44      0.31      0.36       142
          B1       0.57      0.27      0.37       176
          B2       0.46      0.58      0.51        90
          C1       0.23      0.70      0.34        10

    accuracy                           0.39       451
   macro avg       0.38      0.53      0.38       451
weighted avg       0.47      0.39      0.39       451


Fold 4
[[26  6  1  0  0]
 [63 56  9 11  3]
 [39 42 47 44  4]
 [ 2  5 14 44 25]
 [ 0  0  0  4  6]]
              precision    recall  f1-score   support

          A1       0.20      0.79      0.32        33
          A2       0.51      0.39      0.45       142
          B1       0.66      0.27      0.38       176
          B2       0.43      0.49      0.46        90
          C1       0.16      0.60      0.25        10

    accuracy                           0.40       451
   macro avg       0.39      0.51      0.37       451
weighted avg       0.52      0.40      0.41       451


K-fold scores
[0.37849952146128907, 0.33835719791069674, 0.3655625940348665, 0.39246665181792895, 0.40888289063820854]
SKF f1 score mean 0.37675377117259795

************for dimension:  Orthography  ***************
RandomForestClassifier(bootstrap=True, class_weight='balanced',
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, min_impurity_decrease=0.0,
                       min_impurity_split=None, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=None, oob_score=False,
                       random_state=1234, verbose=0, warm_start=False)
Fold 0
[[  0   2   6   0   0   0]
 [  0   7  60   0   1   0]
 [  0   5 141  14   2   0]
 [  0   1  42  48  15   0]
 [  0   0  28  27  31   0]
 [  0   0   6   8   9   0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         8
          A2       0.47      0.10      0.17        68
          B1       0.50      0.87      0.63       162
          B2       0.49      0.45      0.47       106
          C1       0.53      0.36      0.43        86
          C2       0.00      0.00      0.00        23

    accuracy                           0.50       453
   macro avg       0.33      0.30      0.28       453
weighted avg       0.47      0.50      0.44       453


Fold 1
[[  0   2   6   0   0   0]
 [  0   7  60   1   0   0]
 [  0   3 134  22   3   0]
 [  0   0  44  50  12   0]
 [  0   0   6  30  50   0]
 [  0   0   7   3  13   0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         8
          A2       0.58      0.10      0.18        68
          B1       0.52      0.83      0.64       162
          B2       0.47      0.47      0.47       106
          C1       0.64      0.58      0.61        86
          C2       0.00      0.00      0.00        23

    accuracy                           0.53       453
   macro avg       0.37      0.33      0.32       453
weighted avg       0.51      0.53      0.48       453


Fold 2
[[  0   1   7   0   0   0]
 [  0   5  62   0   1   0]
 [  0   2 142  16   2   0]
 [  0   1  45  46  14   0]
 [  0   0  23  27  36   0]
 [  0   0   6   6  11   0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         8
          A2       0.56      0.07      0.13        68
          B1       0.50      0.88      0.64       162
          B2       0.48      0.43      0.46       106
          C1       0.56      0.42      0.48        86
          C2       0.00      0.00      0.00        23

    accuracy                           0.51       453
   macro avg       0.35      0.30      0.28       453
weighted avg       0.48      0.51      0.44       453


Fold 3
[[  0   1   7   0   0   0]
 [  0   8  60   0   0   0]
 [  0   4 139  17   2   0]
 [  0   0  43  48  15   0]
 [  0   0  17  20  48   0]
 [  0   0   7   6  10   0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         8
          A2       0.62      0.12      0.20        68
          B1       0.51      0.86      0.64       162
          B2       0.53      0.45      0.49       106
          C1       0.64      0.56      0.60        85
          C2       0.00      0.00      0.00        23

    accuracy                           0.54       452
   macro avg       0.38      0.33      0.32       452
weighted avg       0.52      0.54      0.49       452


Fold 4
[[  0   3   5   0   0   0]
 [  0   8  58   1   0   0]
 [  0   4 145  12   1   0]
 [  0   0  41  46  18   0]
 [  0   0  19  26  40   0]
 [  0   0   7   5  10   0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         8
          A2       0.53      0.12      0.20        67
          B1       0.53      0.90      0.66       162
          B2       0.51      0.44      0.47       105
          C1       0.58      0.47      0.52        85
          C2       0.00      0.00      0.00        22

    accuracy                           0.53       449
   macro avg       0.36      0.32      0.31       449
weighted avg       0.50      0.53      0.48       449


K-fold scores
[0.4443408615251378, 0.4811416397683552, 0.4449332367839658, 0.4858804327062303, 0.4772231564583779]
SKF f1 score mean 0.4667038654484134

LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
          verbose=0)
Fold 0
[[ 5  3  0  0  0  0]
 [15 22 25  4  1  1]
 [ 5 43 92 15  7  0]
 [ 1  4 31 36 32  2]
 [ 1  1 12 14 47 11]
 [ 2  0  2  3 14  2]]
              precision    recall  f1-score   support

          A1       0.17      0.62      0.27         8
          A2       0.30      0.32      0.31        68
          B1       0.57      0.57      0.57       162
          B2       0.50      0.34      0.40       106
          C1       0.47      0.55      0.50        86
          C2       0.12      0.09      0.10        23

    accuracy                           0.45       453
   macro avg       0.36      0.41      0.36       453
weighted avg       0.46      0.45      0.45       453


Fold 1
[[ 3  5  0  0  0  0]
 [ 8 32 24  4  0  0]
 [12 29 88 25  8  0]
 [ 0  5 30 43 24  4]
 [ 0  0  3 16 59  8]
 [ 0  2  0  4 13  4]]
              precision    recall  f1-score   support

          A1       0.13      0.38      0.19         8
          A2       0.44      0.47      0.45        68
          B1       0.61      0.54      0.57       162
          B2       0.47      0.41      0.43       106
          C1       0.57      0.69      0.62        86
          C2       0.25      0.17      0.21        23

    accuracy                           0.51       453
   macro avg       0.41      0.44      0.41       453
weighted avg       0.51      0.51      0.51       453


Fold 2
[[ 3  3  1  0  1  0]
 [15 24 22  4  2  1]
 [12 24 92 22 11  1]
 [ 0  4 27 42 30  3]
 [ 0  1  8 20 51  6]
 [ 0  1  0  2 15  5]]
              precision    recall  f1-score   support

          A1       0.10      0.38      0.16         8
          A2       0.42      0.35      0.38        68
          B1       0.61      0.57      0.59       162
          B2       0.47      0.40      0.43       106
          C1       0.46      0.59      0.52        86
          C2       0.31      0.22      0.26        23

    accuracy                           0.48       453
   macro avg       0.40      0.42      0.39       453
weighted avg       0.50      0.48      0.48       453


Fold 3
[[  3   3   1   0   0   1]
 [ 10  21  36   0   0   1]
 [  7  27 103  14   9   2]
 [  0   2  33  31  35   5]
 [  1   1   5  16  55   7]
 [  0   0   4   3  12   4]]
              precision    recall  f1-score   support

          A1       0.14      0.38      0.21         8
          A2       0.39      0.31      0.34        68
          B1       0.57      0.64      0.60       162
          B2       0.48      0.29      0.36       106
          C1       0.50      0.65      0.56        85
          C2       0.20      0.17      0.19        23

    accuracy                           0.48       452
   macro avg       0.38      0.41      0.38       452
weighted avg       0.48      0.48      0.47       452


Fold 4
[[  4   2   2   0   0   0]
 [ 11  22  29   3   1   1]
 [  9  21 109  19   4   0]
 [  2   3  29  40  31   0]
 [  0   0  10  14  57   4]
 [  0   1   2   2  12   5]]
              precision    recall  f1-score   support

          A1       0.15      0.50      0.24         8
          A2       0.45      0.33      0.38        67
          B1       0.60      0.67      0.64       162
          B2       0.51      0.38      0.44       105
          C1       0.54      0.67      0.60        85
          C2       0.50      0.23      0.31        22

    accuracy                           0.53       449
   macro avg       0.46      0.46      0.43       449
weighted avg       0.53      0.53      0.52       449


K-fold scores
[0.449994140608413, 0.5065242352477878, 0.4834320724062297, 0.47061639671648303, 0.5212358229716069]
SKF f1 score mean 0.4863605335901041

LogisticRegression(C=1.0, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='multinomial', n_jobs=None,
                   penalty='l2', random_state=1234, solver='lbfgs', tol=0.0001,
                   verbose=0, warm_start=False)
Fold 0
[[ 6  1  0  0  0  1]
 [31 14 14  2  3  4]
 [41 42 45 22 11  1]
 [10  3 24 36 28  5]
 [10  6  9 12 35 14]
 [ 2  1  2  2 13  3]]
              precision    recall  f1-score   support

          A1       0.06      0.75      0.11         8
          A2       0.21      0.21      0.21        68
          B1       0.48      0.28      0.35       162
          B2       0.49      0.34      0.40       106
          C1       0.39      0.41      0.40        86
          C2       0.11      0.13      0.12        23

    accuracy                           0.31       453
   macro avg       0.29      0.35      0.26       453
weighted avg       0.40      0.31      0.33       453


Fold 1
[[ 7  1  0  0  0  0]
 [29 21 14  2  1  1]
 [47 34 42 26  9  4]
 [ 9 14 18 32 20 13]
 [ 3  0  8 13 49 13]
 [ 2  1  3  3 11  3]]
              precision    recall  f1-score   support

          A1       0.07      0.88      0.13         8
          A2       0.30      0.31      0.30        68
          B1       0.49      0.26      0.34       162
          B2       0.42      0.30      0.35       106
          C1       0.54      0.57      0.56        86
          C2       0.09      0.13      0.11        23

    accuracy                           0.34       453
   macro avg       0.32      0.41      0.30       453
weighted avg       0.43      0.34      0.36       453


Fold 2
[[ 5  3  0  0  0  0]
 [38 16  8  4  1  1]
 [37 46 46 22  6  5]
 [ 7 13 18 29 31  8]
 [ 3  3 11 16 42 11]
 [ 1  0  3  3 12  4]]
              precision    recall  f1-score   support

          A1       0.05      0.62      0.10         8
          A2       0.20      0.24      0.21        68
          B1       0.53      0.28      0.37       162
          B2       0.39      0.27      0.32       106
          C1       0.46      0.49      0.47        86
          C2       0.14      0.17      0.15        23

    accuracy                           0.31       453
   macro avg       0.30      0.35      0.27       453
weighted avg       0.41      0.31      0.34       453


Fold 3
[[ 5  2  0  0  0  1]
 [31 17 17  1  1  1]
 [32 42 56 16  8  8]
 [ 7  6 24 31 35  3]
 [ 5  1 10 15 44 10]
 [ 1  1  5  3 10  3]]
              precision    recall  f1-score   support

          A1       0.06      0.62      0.11         8
          A2       0.25      0.25      0.25        68
          B1       0.50      0.35      0.41       162
          B2       0.47      0.29      0.36       106
          C1       0.45      0.52      0.48        85
          C2       0.12      0.13      0.12        23

    accuracy                           0.35       452
   macro avg       0.31      0.36      0.29       452
weighted avg       0.42      0.35      0.37       452


Fold 4
[[ 6  2  0  0  0  0]
 [35 20  6  2  1  3]
 [39 42 54 21  4  2]
 [ 9  9 13 43 28  3]
 [ 2  4 10 12 48  9]
 [ 2  4  2  2  9  3]]
              precision    recall  f1-score   support

          A1       0.06      0.75      0.12         8
          A2       0.25      0.30      0.27        67
          B1       0.64      0.33      0.44       162
          B2       0.54      0.41      0.46       105
          C1       0.53      0.56      0.55        85
          C2       0.15      0.14      0.14        22

    accuracy                           0.39       449
   macro avg       0.36      0.42      0.33       449
weighted avg       0.50      0.39      0.42       449


K-fold scores
[0.3338987757176142, 0.3626681858899988, 0.33948602340884154, 0.36702148829983994, 0.4197658143363439]
SKF f1 score mean 0.3645680575305277

************for dimension:  Vocabularyrange  ***************
RandomForestClassifier(bootstrap=True, class_weight='balanced',
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, min_impurity_decrease=0.0,
                       min_impurity_split=None, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=None, oob_score=False,
                       random_state=1234, verbose=0, warm_start=False)
Fold 0
[[  0  17   3   0   0   0]
 [  1  82  34   1   0   0]
 [  0  27 120  17   0   0]
 [  0   1  17  96   7   0]
 [  0   0   0  20  10   0]
 [  0   0   0   0   1   0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        20
          A2       0.65      0.69      0.67       118
          B1       0.69      0.73      0.71       164
          B2       0.72      0.79      0.75       121
          C1       0.56      0.33      0.42        30
          C2       0.00      0.00      0.00         1

    accuracy                           0.68       454
   macro avg       0.43      0.43      0.42       454
weighted avg       0.64      0.68      0.66       454


Fold 1
[[  1  13   6   0   0   0]
 [  0  63  53   2   0   0]
 [  0  26 109  29   0   0]
 [  0   0  24  92   5   0]
 [  0   0   2  17  11   0]
 [  0   0   0   0   1   0]]
              precision    recall  f1-score   support

          A1       1.00      0.05      0.10        20
          A2       0.62      0.53      0.57       118
          B1       0.56      0.66      0.61       164
          B2       0.66      0.76      0.70       121
          C1       0.65      0.37      0.47        30
          C2       0.00      0.00      0.00         1

    accuracy                           0.61       454
   macro avg       0.58      0.40      0.41       454
weighted avg       0.63      0.61      0.59       454


Fold 2
[[  0  15   4   0   0   0]
 [  0  77  40   1   0   0]
 [  0  23 122  19   0   0]
 [  0   1  22  94   3   0]
 [  0   0   1  21   8   0]
 [  0   0   0   1   0   0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        19
          A2       0.66      0.65      0.66       118
          B1       0.65      0.74      0.69       164
          B2       0.69      0.78      0.73       120
          C1       0.73      0.27      0.39        30
          C2       0.00      0.00      0.00         1

    accuracy                           0.67       452
   macro avg       0.45      0.41      0.41       452
weighted avg       0.64      0.67      0.64       452


Fold 3
[[  0  15   4   0   0   0]
 [  0  55  59   3   0   0]
 [  0  18 128  17   0   0]
 [  0   0  21  95   4   0]
 [  0   0   0  20  10   0]
 [  0   0   0   0   1   0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        19
          A2       0.62      0.47      0.54       117
          B1       0.60      0.79      0.68       163
          B2       0.70      0.79      0.75       120
          C1       0.67      0.33      0.44        30
          C2       0.00      0.00      0.00         1

    accuracy                           0.64       450
   macro avg       0.43      0.40      0.40       450
weighted avg       0.61      0.64      0.62       450


Fold 4
[[  0  13   6   0   0   0]
 [  0  72  45   0   0   0]
 [  0  19 122  22   0   0]
 [  0   0  25  93   2   0]
 [  0   0   1  18  11   0]
 [  0   0   0   1   0   0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        19
          A2       0.69      0.62      0.65       117
          B1       0.61      0.75      0.67       163
          B2       0.69      0.78      0.73       120
          C1       0.85      0.37      0.51        30
          C2       0.00      0.00      0.00         1

    accuracy                           0.66       450
   macro avg       0.47      0.42      0.43       450
weighted avg       0.64      0.66      0.64       450


K-fold scores
[0.6586857744427177, 0.5918452358108284, 0.6434739161557416, 0.6151116722461343, 0.6429456675331066]
SKF f1 score mean 0.6304124532377057

LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
          verbose=0)
Fold 0
[[  5  14   1   0   0   0]
 [ 10  80  28   0   0   0]
 [  4  34 105  20   1   0]
 [  0   2  11  92  16   0]
 [  0   0   0   7  23   0]
 [  0   0   0   0   1   0]]
              precision    recall  f1-score   support

          A1       0.26      0.25      0.26        20
          A2       0.62      0.68      0.65       118
          B1       0.72      0.64      0.68       164
          B2       0.77      0.76      0.77       121
          C1       0.56      0.77      0.65        30
          C2       0.00      0.00      0.00         1

    accuracy                           0.67       454
   macro avg       0.49      0.52      0.50       454
weighted avg       0.68      0.67      0.67       454


Fold 1
[[ 8  8  4  0  0  0]
 [13 68 34  3  0  0]
 [ 5 31 96 30  2  0]
 [ 0  0 19 88 14  0]
 [ 1  0  0  9 20  0]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.30      0.40      0.34        20
          A2       0.64      0.58      0.60       118
          B1       0.63      0.59      0.61       164
          B2       0.68      0.73      0.70       121
          C1       0.54      0.67      0.60        30
          C2       0.00      0.00      0.00         1

    accuracy                           0.62       454
   macro avg       0.46      0.49      0.47       454
weighted avg       0.62      0.62      0.62       454


Fold 2
[[ 10   6   3   0   0   0]
 [ 13  80  23   2   0   0]
 [  4  32 101  27   0   0]
 [  0   2  16  91  11   0]
 [  0   0   0   3  27   0]
 [  0   0   0   0   1   0]]
              precision    recall  f1-score   support

          A1       0.37      0.53      0.43        19
          A2       0.67      0.68      0.67       118
          B1       0.71      0.62      0.66       164
          B2       0.74      0.76      0.75       120
          C1       0.69      0.90      0.78        30
          C2       0.00      0.00      0.00         1

    accuracy                           0.68       452
   macro avg       0.53      0.58      0.55       452
weighted avg       0.69      0.68      0.68       452


Fold 3
[[  8  10   1   0   0   0]
 [ 17  59  39   2   0   0]
 [  5  27 107  23   1   0]
 [  0   0  14  92  14   0]
 [  0   0   0   8  22   0]
 [  0   0   0   0   1   0]]
              precision    recall  f1-score   support

          A1       0.27      0.42      0.33        19
          A2       0.61      0.50      0.55       117
          B1       0.66      0.66      0.66       163
          B2       0.74      0.77      0.75       120
          C1       0.58      0.73      0.65        30
          C2       0.00      0.00      0.00         1

    accuracy                           0.64       450
   macro avg       0.48      0.51      0.49       450
weighted avg       0.65      0.64      0.64       450


Fold 4
[[  5   8   6   0   0   0]
 [ 17  73  22   5   0   0]
 [  6  26 107  24   0   0]
 [  0   1  13  96  10   0]
 [  0   0   0   5  25   0]
 [  0   0   0   0   1   0]]
              precision    recall  f1-score   support

          A1       0.18      0.26      0.21        19
          A2       0.68      0.62      0.65       117
          B1       0.72      0.66      0.69       163
          B2       0.74      0.80      0.77       120
          C1       0.69      0.83      0.76        30
          C2       0.00      0.00      0.00         1

    accuracy                           0.68       450
   macro avg       0.50      0.53      0.51       450
weighted avg       0.69      0.68      0.68       450


K-fold scores
[0.6716229833719337, 0.6172230278453572, 0.6833013263835613, 0.6404793123416411, 0.6822457724954272]
SKF f1 score mean 0.6589744844875841

LogisticRegression(C=1.0, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='multinomial', n_jobs=None,
                   penalty='l2', random_state=1234, solver='lbfgs', tol=0.0001,
                   verbose=0, warm_start=False)
Fold 0
[[17  2  0  1  0  0]
 [45 48 17  2  4  2]
 [35 27 79 16  7  0]
 [ 2  2 11 70 32  4]
 [ 0  0  0  9 19  2]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.17      0.85      0.29        20
          A2       0.61      0.41      0.49       118
          B1       0.74      0.48      0.58       164
          B2       0.71      0.58      0.64       121
          C1       0.30      0.63      0.41        30
          C2       0.00      0.00      0.00         1

    accuracy                           0.51       454
   macro avg       0.42      0.49      0.40       454
weighted avg       0.64      0.51      0.55       454


Fold 1
[[15  3  2  0  0  0]
 [44 40 24  4  4  2]
 [31 31 71 26  5  0]
 [ 3  0 18 73 25  2]
 [ 1  0  0 10 15  4]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.16      0.75      0.26        20
          A2       0.54      0.34      0.42       118
          B1       0.62      0.43      0.51       164
          B2       0.65      0.60      0.62       121
          C1       0.30      0.50      0.37        30
          C2       0.00      0.00      0.00         1

    accuracy                           0.47       454
   macro avg       0.38      0.44      0.36       454
weighted avg       0.56      0.47      0.49       454


Fold 2
[[15  3  1  0  0  0]
 [60 35 12  4  6  1]
 [38 26 78 20  2  0]
 [ 4  2 12 86 15  1]
 [ 0  0  1  2 23  4]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.13      0.79      0.22        19
          A2       0.53      0.30      0.38       118
          B1       0.75      0.48      0.58       164
          B2       0.77      0.72      0.74       120
          C1       0.49      0.77      0.60        30
          C2       0.00      0.00      0.00         1

    accuracy                           0.52       452
   macro avg       0.44      0.51      0.42       452
weighted avg       0.65      0.52      0.56       452


Fold 3
[[14  5  0  0  0  0]
 [42 40 27  4  4  0]
 [26 35 80 17  4  1]
 [ 1  0 15 79 23  2]
 [ 0  0  0  8 20  2]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.17      0.74      0.27        19
          A2       0.50      0.34      0.41       117
          B1       0.66      0.49      0.56       163
          B2       0.73      0.66      0.69       120
          C1       0.38      0.67      0.49        30
          C2       0.00      0.00      0.00         1

    accuracy                           0.52       450
   macro avg       0.41      0.48      0.40       450
weighted avg       0.60      0.52      0.54       450


Fold 4
[[12  3  4  0  0  0]
 [51 45 14  2  5  0]
 [26 28 81 19  7  2]
 [ 3  4 11 71 29  2]
 [ 0  0  1  4 21  4]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.13      0.63      0.22        19
          A2       0.56      0.38      0.46       117
          B1       0.73      0.50      0.59       163
          B2       0.74      0.59      0.66       120
          C1       0.33      0.70      0.45        30
          C2       0.00      0.00      0.00         1

    accuracy                           0.51       450
   macro avg       0.42      0.47      0.40       450
weighted avg       0.64      0.51      0.55       450


K-fold scores
[0.5472306666021108, 0.49481296279143, 0.5562671737810525, 0.537842643639933, 0.547487607816089]
SKF f1 score mean 0.5367282109261231

************for dimension:  Vocabularycontrol  ***************
RandomForestClassifier(bootstrap=True, class_weight='balanced',
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, min_impurity_decrease=0.0,
                       min_impurity_split=None, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=None, oob_score=False,
                       random_state=1234, verbose=0, warm_start=False)
Fold 0
[[ 1 24  6  0  0  0]
 [ 0 66 52  1  0  0]
 [ 0 31 87 48  0  0]
 [ 0  4 27 84  0  0]
 [ 0  0  1 19  1  0]
 [ 0  0  0  3  0  0]]
              precision    recall  f1-score   support

          A1       1.00      0.03      0.06        31
          A2       0.53      0.55      0.54       119
          B1       0.50      0.52      0.51       166
          B2       0.54      0.73      0.62       115
          C1       1.00      0.05      0.09        21
          C2       0.00      0.00      0.00         3

    accuracy                           0.53       455
   macro avg       0.60      0.31      0.30       455
weighted avg       0.57      0.53      0.49       455


Fold 1
[[  0  26   5   0   0   0]
 [  3  65  51   0   0   0]
 [  0  24 108  34   0   0]
 [  0   1  33  80   1   0]
 [  0   0   4  15   1   0]
 [  0   0   0   2   0   0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        31
          A2       0.56      0.55      0.55       119
          B1       0.54      0.65      0.59       166
          B2       0.61      0.70      0.65       115
          C1       0.50      0.05      0.09        20
          C2       0.00      0.00      0.00         2

    accuracy                           0.56       453
   macro avg       0.37      0.32      0.31       453
weighted avg       0.52      0.56      0.53       453


Fold 2
[[ 2 23  5  0  0  0]
 [ 2 72 44  1  0  0]
 [ 0 33 96 37  0  0]
 [ 0  2 42 71  0  0]
 [ 0  0  0 20  0  0]
 [ 0  0  1  1  0  0]]
              precision    recall  f1-score   support

          A1       0.50      0.07      0.12        30
          A2       0.55      0.61      0.58       119
          B1       0.51      0.58      0.54       166
          B2       0.55      0.62      0.58       115
          C1       0.00      0.00      0.00        20
          C2       0.00      0.00      0.00         2

    accuracy                           0.53       452
   macro avg       0.35      0.31      0.30       452
weighted avg       0.51      0.53      0.51       452


Fold 3
[[  2  21   7   0   0   0]
 [  1  59  57   2   0   0]
 [  0  29 108  28   0   0]
 [  0   1  35  79   0   0]
 [  0   0   2  17   1   0]
 [  0   0   0   2   0   0]]
              precision    recall  f1-score   support

          A1       0.67      0.07      0.12        30
          A2       0.54      0.50      0.52       119
          B1       0.52      0.65      0.58       165
          B2       0.62      0.69      0.65       115
          C1       1.00      0.05      0.10        20
          C2       0.00      0.00      0.00         2

    accuracy                           0.55       451
   macro avg       0.56      0.33      0.33       451
weighted avg       0.58      0.55      0.53       451


Fold 4
[[  1  22   7   0   0   0]
 [  1  70  47   0   0   0]
 [  0  33 106  26   0   0]
 [  0   1  36  77   0   0]
 [  0   0   2  17   1   0]
 [  0   0   0   1   1   0]]
              precision    recall  f1-score   support

          A1       0.50      0.03      0.06        30
          A2       0.56      0.59      0.57       118
          B1       0.54      0.64      0.58       165
          B2       0.64      0.68      0.66       114
          C1       0.50      0.05      0.09        20
          C2       0.00      0.00      0.00         2

    accuracy                           0.57       449
   macro avg       0.45      0.33      0.33       449
weighted avg       0.56      0.57      0.54       449


K-fold scores
[0.4944675504790839, 0.5301213896231083, 0.5067160362891906, 0.52533854330865, 0.5400180828359208]
SKF f1 score mean 0.5193323205071907

LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
          verbose=0)
Fold 0
[[11 17  3  0  0  0]
 [21 67 30  1  0  0]
 [ 6 32 71 46  3  8]
 [ 0  7 21 67  6 14]
 [ 0  0  0  8 10  3]
 [ 0  0  0  1  1  1]]
              precision    recall  f1-score   support

          A1       0.29      0.35      0.32        31
          A2       0.54      0.56      0.55       119
          B1       0.57      0.43      0.49       166
          B2       0.54      0.58      0.56       115
          C1       0.50      0.48      0.49        21
          C2       0.04      0.33      0.07         3

    accuracy                           0.50       455
   macro avg       0.41      0.46      0.41       455
weighted avg       0.53      0.50      0.51       455


Fold 1
[[13 13  5  0  0  0]
 [20 69 29  1  0  0]
 [ 9 37 69 47  1  3]
 [ 0  1 22 69 17  6]
 [ 0  0  0 11  7  2]
 [ 0  0  0  1  0  1]]
              precision    recall  f1-score   support

          A1       0.31      0.42      0.36        31
          A2       0.57      0.58      0.58       119
          B1       0.55      0.42      0.47       166
          B2       0.53      0.60      0.57       115
          C1       0.28      0.35      0.31        20
          C2       0.08      0.50      0.14         2

    accuracy                           0.50       453
   macro avg       0.39      0.48      0.40       453
weighted avg       0.52      0.50      0.51       453


Fold 2
[[18  9  3  0  0  0]
 [26 71 16  6  0  0]
 [11 48 57 39  3  8]
 [ 0  7 23 64 11 10]
 [ 0  0  0  9 11  0]
 [ 0  0  0  1  0  1]]
              precision    recall  f1-score   support

          A1       0.33      0.60      0.42        30
          A2       0.53      0.60      0.56       119
          B1       0.58      0.34      0.43       166
          B2       0.54      0.56      0.55       115
          C1       0.44      0.55      0.49        20
          C2       0.05      0.50      0.10         2

    accuracy                           0.49       452
   macro avg       0.41      0.52      0.42       452
weighted avg       0.53      0.49      0.49       452


Fold 3
[[15 11  3  1  0  0]
 [17 75 23  2  0  2]
 [ 2 49 74 36  0  4]
 [ 0  4 18 75 11  7]
 [ 0  0  1  7  9  3]
 [ 0  0  0  1  0  1]]
              precision    recall  f1-score   support

          A1       0.44      0.50      0.47        30
          A2       0.54      0.63      0.58       119
          B1       0.62      0.45      0.52       165
          B2       0.61      0.65      0.63       115
          C1       0.45      0.45      0.45        20
          C2       0.06      0.50      0.11         2

    accuracy                           0.55       451
   macro avg       0.45      0.53      0.46       451
weighted avg       0.58      0.55      0.56       451


Fold 4
[[11 18  1  0  0  0]
 [13 78 24  2  0  1]
 [ 8 57 61 36  1  2]
 [ 1  3 20 63 18  9]
 [ 0  0  0  8  9  3]
 [ 0  0  0  0  1  1]]
              precision    recall  f1-score   support

          A1       0.33      0.37      0.35        30
          A2       0.50      0.66      0.57       118
          B1       0.58      0.37      0.45       165
          B2       0.58      0.55      0.57       114
          C1       0.31      0.45      0.37        20
          C2       0.06      0.50      0.11         2

    accuracy                           0.50       449
   macro avg       0.39      0.48      0.40       449
weighted avg       0.53      0.50      0.50       449


K-fold scores
[0.5098434165516809, 0.5077769592948579, 0.49451105981640076, 0.5570505508801715, 0.49871009372825714]
SKF f1 score mean 0.5135784160542737

LogisticRegression(C=1.0, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='multinomial', n_jobs=None,
                   penalty='l2', random_state=1234, solver='lbfgs', tol=0.0001,
                   verbose=0, warm_start=False)
Fold 0
[[20  9  1  0  0  1]
 [52 48 10  6  2  1]
 [32 35 40 15 16 28]
 [ 6  5 15 12 37 40]
 [ 0  0  0  3 14  4]
 [ 0  0  0  0  2  1]]
              precision    recall  f1-score   support

          A1       0.18      0.65      0.28        31
          A2       0.49      0.40      0.44       119
          B1       0.61      0.24      0.34       166
          B2       0.33      0.10      0.16       115
          C1       0.20      0.67      0.30        21
          C2       0.01      0.33      0.03         3

    accuracy                           0.30       455
   macro avg       0.30      0.40      0.26       455
weighted avg       0.46      0.30      0.32       455


Fold 1
[[24  5  1  1  0  0]
 [61 44  9  3  0  2]
 [29 44 46 16 12 19]
 [ 2  7 15 19 37 35]
 [ 0  0  1  2 12  5]
 [ 0  0  0  0  0  2]]
              precision    recall  f1-score   support

          A1       0.21      0.77      0.33        31
          A2       0.44      0.37      0.40       119
          B1       0.64      0.28      0.39       166
          B2       0.46      0.17      0.24       115
          C1       0.20      0.60      0.30        20
          C2       0.03      1.00      0.06         2

    accuracy                           0.32       453
   macro avg       0.33      0.53      0.29       453
weighted avg       0.49      0.32      0.34       453


Fold 2
[[25  1  2  2  0  0]
 [65 37  9  4  1  3]
 [37 45 33 19  9 23]
 [ 7 10 15 15 32 36]
 [ 0  0  0  2 16  2]
 [ 0  0  0  0  0  2]]
              precision    recall  f1-score   support

          A1       0.19      0.83      0.30        30
          A2       0.40      0.31      0.35       119
          B1       0.56      0.20      0.29       166
          B2       0.36      0.13      0.19       115
          C1       0.28      0.80      0.41        20
          C2       0.03      1.00      0.06         2

    accuracy                           0.28       452
   macro avg       0.30      0.55      0.27       452
weighted avg       0.43      0.28      0.29       452


Fold 3
[[20  7  0  0  0  3]
 [55 37 12  8  3  4]
 [29 49 47 12  6 22]
 [ 6  8 16 12 28 45]
 [ 0  0  1  0 13  6]
 [ 0  0  0  0  0  2]]
              precision    recall  f1-score   support

          A1       0.18      0.67      0.29        30
          A2       0.37      0.31      0.34       119
          B1       0.62      0.28      0.39       165
          B2       0.38      0.10      0.16       115
          C1       0.26      0.65      0.37        20
          C2       0.02      1.00      0.05         2

    accuracy                           0.29       451
   macro avg       0.30      0.50      0.27       451
weighted avg       0.44      0.29      0.31       451


Fold 4
[[24  5  1  0  0  0]
 [50 37 17  9  2  3]
 [34 47 45  9 11 19]
 [ 1  8 18 12 36 39]
 [ 0  0  0  2 13  5]
 [ 0  0  0  0  1  1]]
              precision    recall  f1-score   support

          A1       0.22      0.80      0.35        30
          A2       0.38      0.31      0.34       118
          B1       0.56      0.27      0.37       165
          B2       0.38      0.11      0.16       114
          C1       0.21      0.65      0.31        20
          C2       0.01      0.50      0.03         2

    accuracy                           0.29       449
   macro avg       0.29      0.44      0.26       449
weighted avg       0.42      0.29      0.30       449


K-fold scores
[0.3157603682647953, 0.3447454551136412, 0.2868909473512167, 0.3087691075379634, 0.30379126204894963]
SKF f1 score mean 0.31199142806331326

************for dimension:  CoherenceCohesion  ***************
RandomForestClassifier(bootstrap=True, class_weight='balanced',
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, min_impurity_decrease=0.0,
                       min_impurity_split=None, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=None, oob_score=False,
                       random_state=1234, verbose=0, warm_start=False)
Fold 0
[[  6  29   4   0   0   0]
 [  1  95  35   2   0   0]
 [  0  22 127  17   0   0]
 [  0   1  30  66   0   0]
 [  0   0   2  16   0   0]
 [  0   0   0   1   0   0]]
              precision    recall  f1-score   support

          A1       0.86      0.15      0.26        39
          A2       0.65      0.71      0.68       133
          B1       0.64      0.77      0.70       166
          B2       0.65      0.68      0.66        97
          C1       0.00      0.00      0.00        18
          C2       0.00      0.00      0.00         1

    accuracy                           0.65       454
   macro avg       0.47      0.39      0.38       454
weighted avg       0.64      0.65      0.62       454


Fold 1
[[  1  36   2   0   0   0]
 [  0  85  46   2   0   0]
 [  0  31 117  18   0   0]
 [  0   1  29  67   0   0]
 [  0   0   3  15   0   0]
 [  0   0   0   1   0   0]]
              precision    recall  f1-score   support

          A1       1.00      0.03      0.05        39
          A2       0.56      0.64      0.59       133
          B1       0.59      0.70      0.64       166
          B2       0.65      0.69      0.67        97
          C1       0.00      0.00      0.00        18
          C2       0.00      0.00      0.00         1

    accuracy                           0.59       454
   macro avg       0.47      0.34      0.33       454
weighted avg       0.60      0.59      0.56       454


Fold 2
[[  4  33   2   0   0   0]
 [  3  88  40   1   0   0]
 [  0  25 125  15   0   0]
 [  0   0  27  69   0   0]
 [  0   0   1  17   0   0]
 [  0   0   0   1   0   0]]
              precision    recall  f1-score   support

          A1       0.57      0.10      0.17        39
          A2       0.60      0.67      0.63       132
          B1       0.64      0.76      0.69       165
          B2       0.67      0.72      0.69        96
          C1       0.00      0.00      0.00        18
          C2       0.00      0.00      0.00         1

    accuracy                           0.63       451
   macro avg       0.41      0.37      0.37       451
weighted avg       0.60      0.63      0.60       451


Fold 3
[[  3  35   1   0   0   0]
 [  1  94  36   1   0   0]
 [  0  21 131  13   0   0]
 [  0   2  29  64   1   0]
 [  0   0   4  13   1   0]
 [  0   0   0   1   0   0]]
              precision    recall  f1-score   support

          A1       0.75      0.08      0.14        39
          A2       0.62      0.71      0.66       132
          B1       0.65      0.79      0.72       165
          B2       0.70      0.67      0.68        96
          C1       0.50      0.06      0.10        18
          C2       0.00      0.00      0.00         1

    accuracy                           0.65       451
   macro avg       0.54      0.38      0.38       451
weighted avg       0.65      0.65      0.62       451


Fold 4
[[  5  26   7   0   0   0]
 [  0  90  40   2   0   0]
 [  0  32 120  13   0   0]
 [  0   1  28  67   0   0]
 [  0   0   3  15   0   0]
 [  0   0   0   1   0   0]]
              precision    recall  f1-score   support

          A1       1.00      0.13      0.23        38
          A2       0.60      0.68      0.64       132
          B1       0.61      0.73      0.66       165
          B2       0.68      0.70      0.69        96
          C1       0.00      0.00      0.00        18
          C2       0.00      0.00      0.00         1

    accuracy                           0.63       450
   macro avg       0.48      0.37      0.37       450
weighted avg       0.63      0.63      0.60       450


K-fold scores
[0.618063406214442, 0.5572779923320572, 0.6020114227812295, 0.6166266039496172, 0.5973167930802197]
SKF f1 score mean 0.5982592436715132

LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
          verbose=0)
Fold 0
[[ 14  20   5   0   0   0]
 [ 17  85  29   2   0   0]
 [  3  30 112  21   0   0]
 [  0   1  20  65  11   0]
 [  0   0   0   8   9   1]
 [  0   0   0   1   0   0]]
              precision    recall  f1-score   support

          A1       0.41      0.36      0.38        39
          A2       0.62      0.64      0.63       133
          B1       0.67      0.67      0.67       166
          B2       0.67      0.67      0.67        97
          C1       0.45      0.50      0.47        18
          C2       0.00      0.00      0.00         1

    accuracy                           0.63       454
   macro avg       0.47      0.47      0.47       454
weighted avg       0.63      0.63      0.63       454


Fold 1
[[ 17  19   3   0   0   0]
 [ 27  68  37   1   0   0]
 [  1  27 111  26   1   0]
 [  1   0  24  65   7   0]
 [  0   0   0   9   9   0]
 [  0   0   0   1   0   0]]
              precision    recall  f1-score   support

          A1       0.37      0.44      0.40        39
          A2       0.60      0.51      0.55       133
          B1       0.63      0.67      0.65       166
          B2       0.64      0.67      0.65        97
          C1       0.53      0.50      0.51        18
          C2       0.00      0.00      0.00         1

    accuracy                           0.59       454
   macro avg       0.46      0.46      0.46       454
weighted avg       0.60      0.59      0.59       454


Fold 2
[[ 17  21   1   0   0   0]
 [ 26  67  38   1   0   0]
 [  4  29 111  19   2   0]
 [  0   3  17  65  11   0]
 [  0   0   0  12   6   0]
 [  0   0   0   0   1   0]]
              precision    recall  f1-score   support

          A1       0.36      0.44      0.40        39
          A2       0.56      0.51      0.53       132
          B1       0.66      0.67      0.67       165
          B2       0.67      0.68      0.67        96
          C1       0.30      0.33      0.32        18
          C2       0.00      0.00      0.00         1

    accuracy                           0.59       451
   macro avg       0.43      0.44      0.43       451
weighted avg       0.59      0.59      0.59       451


Fold 3
[[ 16  19   4   0   0   0]
 [ 18  79  32   3   0   0]
 [  2  26 117  19   1   0]
 [  0   2  17  67  10   0]
 [  0   0   0  12   6   0]
 [  0   0   0   0   1   0]]
              precision    recall  f1-score   support

          A1       0.44      0.41      0.43        39
          A2       0.63      0.60      0.61       132
          B1       0.69      0.71      0.70       165
          B2       0.66      0.70      0.68        96
          C1       0.33      0.33      0.33        18
          C2       0.00      0.00      0.00         1

    accuracy                           0.63       451
   macro avg       0.46      0.46      0.46       451
weighted avg       0.63      0.63      0.63       451


Fold 4
[[ 20  13   5   0   0   0]
 [ 13  81  35   3   0   0]
 [  6  37 103  18   1   0]
 [  0   0  20  68   8   0]
 [  0   0   1  11   6   0]
 [  0   0   0   0   1   0]]
              precision    recall  f1-score   support

          A1       0.51      0.53      0.52        38
          A2       0.62      0.61      0.62       132
          B1       0.63      0.62      0.63       165
          B2       0.68      0.71      0.69        96
          C1       0.38      0.33      0.35        18
          C2       0.00      0.00      0.00         1

    accuracy                           0.62       450
   macro avg       0.47      0.47      0.47       450
weighted avg       0.62      0.62      0.62       450


K-fold scores
[0.6267340627945553, 0.5936676816969998, 0.5904386454642855, 0.6297792306682838, 0.6162811122541747]
SKF f1 score mean 0.6113801465756599

LogisticRegression(C=1.0, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='multinomial', n_jobs=None,
                   penalty='l2', random_state=1234, solver='lbfgs', tol=0.0001,
                   verbose=0, warm_start=False)
Fold 0
[[28  7  4  0  0  0]
 [74 30 20  7  2  0]
 [28 32 92 14  0  0]
 [ 1  4 35 35 21  1]
 [ 0  0  3  2 10  3]
 [ 0  0  0  1  0  0]]
              precision    recall  f1-score   support

          A1       0.21      0.72      0.33        39
          A2       0.41      0.23      0.29       133
          B1       0.60      0.55      0.57       166
          B2       0.59      0.36      0.45        97
          C1       0.30      0.56      0.39        18
          C2       0.00      0.00      0.00         1

    accuracy                           0.43       454
   macro avg       0.35      0.40      0.34       454
weighted avg       0.50      0.43      0.44       454


Fold 1
[[31  6  2  0  0  0]
 [64 42 20  5  2  0]
 [35 29 85 15  2  0]
 [ 3  1 42 35 15  1]
 [ 0  0  3  2 13  0]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.23      0.79      0.36        39
          A2       0.54      0.32      0.40       133
          B1       0.56      0.51      0.53       166
          B2       0.61      0.36      0.45        97
          C1       0.39      0.72      0.51        18
          C2       0.00      0.00      0.00         1

    accuracy                           0.45       454
   macro avg       0.39      0.45      0.38       454
weighted avg       0.53      0.45      0.46       454


Fold 2
[[32  6  1  0  0  0]
 [75 34 15  7  0  1]
 [28 46 83  6  2  0]
 [ 2  4 35 30 23  2]
 [ 0  0  4  2 12  0]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.23      0.82      0.36        39
          A2       0.38      0.26      0.31       132
          B1       0.60      0.50      0.55       165
          B2       0.67      0.31      0.43        96
          C1       0.32      0.67      0.43        18
          C2       0.00      0.00      0.00         1

    accuracy                           0.42       451
   macro avg       0.37      0.43      0.35       451
weighted avg       0.51      0.42      0.43       451


Fold 3
[[31  6  2  0  0  0]
 [76 23 19 11  0  3]
 [23 31 97  9  4  1]
 [ 2  2 39 33 19  1]
 [ 0  0  4  4 10  0]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.23      0.79      0.36        39
          A2       0.37      0.17      0.24       132
          B1       0.60      0.59      0.60       165
          B2       0.58      0.34      0.43        96
          C1       0.29      0.56      0.38        18
          C2       0.00      0.00      0.00         1

    accuracy                           0.43       451
   macro avg       0.35      0.41      0.34       451
weighted avg       0.48      0.43      0.43       451


Fold 4
[[29  5  4  0  0  0]
 [68 27 25  7  2  3]
 [36 27 86 12  3  1]
 [ 0  4 27 42 20  3]
 [ 0  1  2  2 11  2]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.22      0.76      0.34        38
          A2       0.42      0.20      0.28       132
          B1       0.60      0.52      0.56       165
          B2       0.67      0.44      0.53        96
          C1       0.30      0.61      0.40        18
          C2       0.00      0.00      0.00         1

    accuracy                           0.43       450
   macro avg       0.37      0.42      0.35       450
weighted avg       0.52      0.43      0.44       450


K-fold scores
[0.43528499439703106, 0.4603866186726568, 0.42921427885207086, 0.4256415645840288, 0.44226194923092144]
SKF f1 score mean 0.4385578811473418

************for dimension:  Sociolinguisticappropriateness  ***************
RandomForestClassifier(bootstrap=True, class_weight='balanced',
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, min_impurity_decrease=0.0,
                       min_impurity_split=None, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=300, n_jobs=None, oob_score=False,
                       random_state=1234, verbose=0, warm_start=False)
Fold 0
[[ 48  25   2   0   0]
 [  3 100  37   0   0]
 [  0  40 103   4   0]
 [  1   4  29  44   0]
 [  0   0   0  14   0]]
              precision    recall  f1-score   support

          A1       0.92      0.64      0.76        75
          A2       0.59      0.71      0.65       140
          B1       0.60      0.70      0.65       147
          B2       0.71      0.56      0.63        78
          C1       0.00      0.00      0.00        14

    accuracy                           0.65       454
   macro avg       0.57      0.52      0.54       454
weighted avg       0.65      0.65      0.64       454


Fold 1
[[ 49  22   3   0   0]
 [  1 108  31   0   0]
 [  0  35  93  19   0]
 [  3   6  21  47   0]
 [  0   0   1  12   1]]
              precision    recall  f1-score   support

          A1       0.92      0.66      0.77        74
          A2       0.63      0.77      0.69       140
          B1       0.62      0.63      0.63       147
          B2       0.60      0.61      0.61        77
          C1       1.00      0.07      0.13        14

    accuracy                           0.66       452
   macro avg       0.76      0.55      0.57       452
weighted avg       0.68      0.66      0.65       452


Fold 2
[[ 52  17   5   0   0]
 [  1 108  31   0   0]
 [  2  32 100  13   0]
 [  1   7  21  46   2]
 [  0   0   1  12   1]]
              precision    recall  f1-score   support

          A1       0.93      0.70      0.80        74
          A2       0.66      0.77      0.71       140
          B1       0.63      0.68      0.66       147
          B2       0.65      0.60      0.62        77
          C1       0.33      0.07      0.12        14

    accuracy                           0.68       452
   macro avg       0.64      0.56      0.58       452
weighted avg       0.68      0.68      0.67       452


Fold 3
[[47 25  2  0  0]
 [ 1 99 40  0  0]
 [ 1 42 92 12  0]
 [ 1  3 28 45  0]
 [ 1  0  1 12  0]]
              precision    recall  f1-score   support

          A1       0.92      0.64      0.75        74
          A2       0.59      0.71      0.64       140
          B1       0.56      0.63      0.59       147
          B2       0.65      0.58      0.62        77
          C1       0.00      0.00      0.00        14

    accuracy                           0.63       452
   macro avg       0.54      0.51      0.52       452
weighted avg       0.63      0.63      0.62       452


Fold 4
[[ 48  20   6   0   0]
 [  2 103  35   0   0]
 [  0  34  98  14   0]
 [  4   6  26  41   0]
 [  1   0   0  12   0]]
              precision    recall  f1-score   support

          A1       0.87      0.65      0.74        74
          A2       0.63      0.74      0.68       140
          B1       0.59      0.67      0.63       146
          B2       0.61      0.53      0.57        77
          C1       0.00      0.00      0.00        13

    accuracy                           0.64       450
   macro avg       0.54      0.52      0.52       450
weighted avg       0.64      0.64      0.64       450


K-fold scores
[0.6422087811456595, 0.6532569720678406, 0.673847456906795, 0.6196329738760199, 0.6358030434494051]
SKF f1 score mean 0.644949845489144

LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
          verbose=0)
Fold 0
[[ 48  24   1   2   0]
 [  4 103  29   4   0]
 [  5  51  76  14   1]
 [  1   6  19  43   9]
 [  0   0   0  10   4]]
              precision    recall  f1-score   support

          A1       0.83      0.64      0.72        75
          A2       0.56      0.74      0.64       140
          B1       0.61      0.52      0.56       147
          B2       0.59      0.55      0.57        78
          C1       0.29      0.29      0.29        14

    accuracy                           0.60       454
   macro avg       0.57      0.55      0.55       454
weighted avg       0.62      0.60      0.60       454


Fold 1
[[ 50  18   6   0   0]
 [  1 110  27   2   0]
 [  1  51  70  25   0]
 [  0   6  20  42   9]
 [  0   0   0  10   4]]
              precision    recall  f1-score   support

          A1       0.96      0.68      0.79        74
          A2       0.59      0.79      0.68       140
          B1       0.57      0.48      0.52       147
          B2       0.53      0.55      0.54        77
          C1       0.31      0.29      0.30        14

    accuracy                           0.61       452
   macro avg       0.59      0.55      0.56       452
weighted avg       0.63      0.61      0.61       452


Fold 2
[[ 52  19   3   0   0]
 [  1 110  27   2   0]
 [  0  46  85  15   1]
 [  0   8  17  38  14]
 [  0   0   0  10   4]]
              precision    recall  f1-score   support

          A1       0.98      0.70      0.82        74
          A2       0.60      0.79      0.68       140
          B1       0.64      0.58      0.61       147
          B2       0.58      0.49      0.54        77
          C1       0.21      0.29      0.24        14

    accuracy                           0.64       452
   macro avg       0.60      0.57      0.58       452
weighted avg       0.66      0.64      0.64       452


Fold 3
[[ 51  19   3   1   0]
 [  2 101  31   6   0]
 [  1  51  80  14   1]
 [  1   5  20  39  12]
 [  0   0   0   8   6]]
              precision    recall  f1-score   support

          A1       0.93      0.69      0.79        74
          A2       0.57      0.72      0.64       140
          B1       0.60      0.54      0.57       147
          B2       0.57      0.51      0.54        77
          C1       0.32      0.43      0.36        14

    accuracy                           0.61       452
   macro avg       0.60      0.58      0.58       452
weighted avg       0.63      0.61      0.62       452


Fold 4
[[ 49  21   4   0   0]
 [  3 103  28   6   0]
 [  2  44  79  18   3]
 [  4   8  21  41   3]
 [  1   0   0   8   4]]
              precision    recall  f1-score   support

          A1       0.83      0.66      0.74        74
          A2       0.59      0.74      0.65       140
          B1       0.60      0.54      0.57       146
          B2       0.56      0.53      0.55        77
          C1       0.40      0.31      0.35        13

    accuracy                           0.61       450
   macro avg       0.60      0.56      0.57       450
weighted avg       0.62      0.61      0.61       450


K-fold scores
[0.6029043698414297, 0.6091400405559698, 0.6418795615514261, 0.6155264715813994, 0.6119680628983089]
SKF f1 score mean 0.6162837012857068

LogisticRegression(C=1.0, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='multinomial', n_jobs=None,
                   penalty='l2', random_state=1234, solver='lbfgs', tol=0.0001,
                   verbose=0, warm_start=False)
Fold 0
[[ 49  25   0   1   0]
 [ 11 104  22   3   0]
 [  5  60  63  16   3]
 [  2   9  13  35  19]
 [  1   0   0   6   7]]
              precision    recall  f1-score   support

          A1       0.72      0.65      0.69        75
          A2       0.53      0.74      0.62       140
          B1       0.64      0.43      0.51       147
          B2       0.57      0.45      0.50        78
          C1       0.24      0.50      0.33        14

    accuracy                           0.57       454
   macro avg       0.54      0.55      0.53       454
weighted avg       0.60      0.57      0.57       454


Fold 1
[[ 51  17   6   0   0]
 [  9 102  25   4   0]
 [  1  64  54  24   4]
 [  3   9  12  33  20]
 [  0   0   1   3  10]]
              precision    recall  f1-score   support

          A1       0.80      0.69      0.74        74
          A2       0.53      0.73      0.61       140
          B1       0.55      0.37      0.44       147
          B2       0.52      0.43      0.47        77
          C1       0.29      0.71      0.42        14

    accuracy                           0.55       452
   macro avg       0.54      0.59      0.54       452
weighted avg       0.57      0.55      0.55       452


Fold 2
[[ 53  18   1   1   1]
 [ 10 102  27   1   0]
 [  6  64  55  21   1]
 [  0   9  14  33  21]
 [  0   0   1   6   7]]
              precision    recall  f1-score   support

          A1       0.77      0.72      0.74        74
          A2       0.53      0.73      0.61       140
          B1       0.56      0.37      0.45       147
          B2       0.53      0.43      0.47        77
          C1       0.23      0.50      0.32        14

    accuracy                           0.55       452
   macro avg       0.52      0.55      0.52       452
weighted avg       0.57      0.55      0.55       452


Fold 3
[[ 48  23   2   0   1]
 [  4 103  29   4   0]
 [  3  56  60  24   4]
 [  3   7  16  27  24]
 [  0   0   0   4  10]]
              precision    recall  f1-score   support

          A1       0.83      0.65      0.73        74
          A2       0.54      0.74      0.63       140
          B1       0.56      0.41      0.47       147
          B2       0.46      0.35      0.40        77
          C1       0.26      0.71      0.38        14

    accuracy                           0.55       452
   macro avg       0.53      0.57      0.52       452
weighted avg       0.57      0.55      0.55       452


Fold 4
[[ 47  18   6   0   3]
 [  7 100  27   6   0]
 [  4  55  60  21   6]
 [  6  15  13  27  16]
 [  2   0   1   2   8]]
              precision    recall  f1-score   support

          A1       0.71      0.64      0.67        74
          A2       0.53      0.71      0.61       140
          B1       0.56      0.41      0.47       146
          B2       0.48      0.35      0.41        77
          C1       0.24      0.62      0.35        13

    accuracy                           0.54       450
   macro avg       0.51      0.55      0.50       450
weighted avg       0.55      0.54      0.53       450


K-fold scores
[0.5660598295746687, 0.5473354758501724, 0.5478641795411389, 0.5459803616451194, 0.5335232818380666]
SKF f1 score mean 0.5481526256898333

DOING CROSS LANG CLASSIFICATION
1024
1024
1024
************for dimension:  OverallCEFRrating  ***************
DE Train, IT Test
CROSS LANG EVAL
0.57375
[[  0  23   5   0]
 [  0 209 163   8]
 [  0  30 250 112]
 [  0   0   0   0]]
0.6117370485750548
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        28
          A2       0.80      0.55      0.65       380
          B1       0.60      0.64      0.62       392
          B2       0.00      0.00      0.00         0

    accuracy                           0.57       800
   macro avg       0.35      0.30      0.32       800
weighted avg       0.67      0.57      0.61       800


0.5175
[[  2  21   4   1]
 [  4 240 124  12]
 [  2  33 172 185]
 [  0   0   0   0]]
0.5857516356685324
              precision    recall  f1-score   support

          A1       0.25      0.07      0.11        28
          A2       0.82      0.63      0.71       380
          B1       0.57      0.44      0.50       392
          B2       0.00      0.00      0.00         0

    accuracy                           0.52       800
   macro avg       0.41      0.29      0.33       800
weighted avg       0.68      0.52      0.59       800


0.53
[[ 14  10   3   0   1]
 [ 63 185 120   7   5]
 [ 16  42 225 109   0]
 [  0   0   0   0   0]
 [  0   0   0   0   0]]
0.5909181757001118
              precision    recall  f1-score   support

          A1       0.15      0.50      0.23        28
          A2       0.78      0.49      0.60       380
          B1       0.65      0.57      0.61       392
          B2       0.00      0.00      0.00         0
          C1       0.00      0.00      0.00         0

    accuracy                           0.53       800
   macro avg       0.32      0.31      0.29       800
weighted avg       0.69      0.53      0.59       800


DE Train, CZ Test
CROSS LANG EVAL
0.4055299539170507
[[ 37  84  67]
 [  4  59 102]
 [  0   1  80]]
0.3756532896627837
              precision    recall  f1-score   support

          A2       0.90      0.20      0.32       188
          B1       0.41      0.36      0.38       165
          B2       0.32      0.99      0.48        81

    accuracy                           0.41       434
   macro avg       0.54      0.51      0.40       434
weighted avg       0.61      0.41      0.38       434


0.41013824884792627
[[  0   0   0   0   0]
 [  4  40  81  63   0]
 [  0   4  59 102   0]
 [  0   0   1  79   1]
 [  0   0   0   0   0]]
0.38671313070449365
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         0
          A2       0.91      0.21      0.34       188
          B1       0.42      0.36      0.39       165
          B2       0.32      0.98      0.49        81
          C1       0.00      0.00      0.00         0

    accuracy                           0.41       434
   macro avg       0.33      0.31      0.24       434
weighted avg       0.61      0.41      0.39       434


0.19815668202764977
[[ 0  0  0  0  0]
 [24 30 62 22 50]
 [ 3  7 52 15 88]
 [ 0  0  1  4 76]
 [ 0  0  0  0  0]]
0.26896433877622966
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         0
          A2       0.81      0.16      0.27       188
          B1       0.45      0.32      0.37       165
          B2       0.10      0.05      0.07        81
          C1       0.00      0.00      0.00         0

    accuracy                           0.20       434
   macro avg       0.27      0.10      0.14       434
weighted avg       0.54      0.20      0.27       434


************for dimension:  Grammaticalaccuracy  ***************
DE Train, IT Test
CROSS LANG EVAL
0.50875
[[  0  53  18   0]
 [  0 122 117   3]
 [  0  79 264  33]
 [  0   7  83  21]]
0.4706578318550237
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        71
          A2       0.47      0.50      0.49       242
          B1       0.55      0.70      0.62       376
          B2       0.37      0.19      0.25       111

    accuracy                           0.51       800
   macro avg       0.35      0.35      0.34       800
weighted avg       0.45      0.51      0.47       800


0.48
[[  3  60   7   1]
 [  5 161  70   6]
 [  3 110 172  91]
 [  0   7  56  48]]
0.463677916730838
              precision    recall  f1-score   support

          A1       0.27      0.04      0.07        71
          A2       0.48      0.67      0.56       242
          B1       0.56      0.46      0.51       376
          B2       0.33      0.43      0.37       111

    accuracy                           0.48       800
   macro avg       0.41      0.40      0.38       800
weighted avg       0.48      0.48      0.46       800


0.47
[[ 32  33   5   0   1]
 [ 51 119  65   5   2]
 [ 34 106 198  37   1]
 [  1  11  72  27   0]
 [  0   0   0   0   0]]
0.47251245509002643
              precision    recall  f1-score   support

          A1       0.27      0.45      0.34        71
          A2       0.44      0.49      0.47       242
          B1       0.58      0.53      0.55       376
          B2       0.39      0.24      0.30       111
          C1       0.00      0.00      0.00         0

    accuracy                           0.47       800
   macro avg       0.34      0.34      0.33       800
weighted avg       0.49      0.47      0.47       800


DE Train, CZ Test
CROSS LANG EVAL
0.4078341013824885
[[ 0  1  3  2  0]
 [ 0 25 77 83  0]
 [ 0 11 72 73  0]
 [ 0  0  2 80  0]
 [ 0  0  0  5  0]]
0.35599173632472286
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         6
          A2       0.68      0.14      0.23       185
          B1       0.47      0.46      0.46       156
          B2       0.33      0.98      0.49        82
          C1       0.00      0.00      0.00         5

    accuracy                           0.41       434
   macro avg       0.29      0.31      0.24       434
weighted avg       0.52      0.41      0.36       434


0.41244239631336405
[[ 3  0  1  2  0]
 [ 3 36 61 82  3]
 [ 0 25 59 72  0]
 [ 0  0  1 81  0]
 [ 0  0  0  5  0]]
0.3787146746579358
              precision    recall  f1-score   support

          A1       0.50      0.50      0.50         6
          A2       0.59      0.19      0.29       185
          B1       0.48      0.38      0.42       156
          B2       0.33      0.99      0.50        82
          C1       0.00      0.00      0.00         5

    accuracy                           0.41       434
   macro avg       0.38      0.41      0.34       434
weighted avg       0.50      0.41      0.38       434


0.21658986175115208
[[ 2  0  1  3  0]
 [19 34 41 48 43]
 [ 8 29 42 25 52]
 [ 0  0  2 11 69]
 [ 0  0  0  0  5]]
0.26848431705705655
              precision    recall  f1-score   support

          A1       0.07      0.33      0.11         6
          A2       0.54      0.18      0.27       185
          B1       0.49      0.27      0.35       156
          B2       0.13      0.13      0.13        82
          C1       0.03      1.00      0.06         5

    accuracy                           0.22       434
   macro avg       0.25      0.38      0.18       434
weighted avg       0.43      0.22      0.27       434


************for dimension:  Orthography  ***************
DE Train, IT Test
CROSS LANG EVAL
0.29875
[[  0   1  19   2   0   0]
 [  0   6 125  12   0   0]
 [  0   0 187  33   0   0]
 [  0   0  31  46   0   0]
 [  0   0  70 192   0   0]
 [  0   0  31  45   0   0]]
0.1866424082940921
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        22
          A2       0.86      0.04      0.08       143
          B1       0.40      0.85      0.55       220
          B2       0.14      0.60      0.23        77
          C1       0.00      0.00      0.00       262
          C2       0.00      0.00      0.00        76

    accuracy                           0.30       800
   macro avg       0.23      0.25      0.14       800
weighted avg       0.28      0.30      0.19       800


0.37875
[[  0   7  15   0   0   0]
 [  0  34 107   1   1   0]
 [  0  23 186   8   3   0]
 [  0   1  43  18  14   1]
 [  1   5 104  83  65   4]
 [  0   3  41  21  11   0]]
0.33540159359558247
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        22
          A2       0.47      0.24      0.31       143
          B1       0.38      0.85      0.52       220
          B2       0.14      0.23      0.17        77
          C1       0.69      0.25      0.37       262
          C2       0.00      0.00      0.00        76

    accuracy                           0.38       800
   macro avg       0.28      0.26      0.23       800
weighted avg       0.43      0.38      0.34       800


0.27625
[[  0  14   6   2   0   0]
 [  1  69  65   7   1   0]
 [  1  85 109  20   4   1]
 [  1  11  28  25   4   8]
 [  4  21  91  78  12  56]
 [  2   6  39  19   4   6]]
0.23436710950802414
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        22
          A2       0.33      0.48      0.40       143
          B1       0.32      0.50      0.39       220
          B2       0.17      0.32      0.22        77
          C1       0.48      0.05      0.08       262
          C2       0.08      0.08      0.08        76

    accuracy                           0.28       800
   macro avg       0.23      0.24      0.20       800
weighted avg       0.33      0.28      0.23       800


DE Train, CZ Test
CROSS LANG EVAL
0.42626728110599077
[[  0  11  35   0]
 [  0  92 177   0]
 [  0  22  92   0]
 [  0   0   4   1]]
0.4078276343003247
              precision    recall  f1-score   support

          A2       0.00      0.00      0.00        46
          B1       0.74      0.34      0.47       269
          B2       0.30      0.81      0.44       114
          C1       1.00      0.20      0.33         5

    accuracy                           0.43       434
   macro avg       0.51      0.34      0.31       434
weighted avg       0.55      0.43      0.41       434


0.37327188940092165
[[  4  10  32   0   0]
 [ 10 124 103  31   1]
 [  1  29  29  53   2]
 [  0   0   0   5   0]
 [  0   0   0   0   0]]
0.42574838794161146
              precision    recall  f1-score   support

          A2       0.27      0.09      0.13        46
          B1       0.76      0.46      0.57       269
          B2       0.18      0.25      0.21       114
          C1       0.06      1.00      0.11         5
          C2       0.00      0.00      0.00         0

    accuracy                           0.37       434
   macro avg       0.25      0.36      0.20       434
weighted avg       0.55      0.37      0.43       434


0.21658986175115208
[[ 4  8 10 18  6]
 [30 83 38 98 20]
 [ 5 21  5 69 14]
 [ 0  0  0  2  3]
 [ 0  0  0  0  0]]
0.29599545040160047
              precision    recall  f1-score   support

          A2       0.10      0.09      0.09        46
          B1       0.74      0.31      0.44       269
          B2       0.09      0.04      0.06       114
          C1       0.01      0.40      0.02         5
          C2       0.00      0.00      0.00         0

    accuracy                           0.22       434
   macro avg       0.19      0.17      0.12       434
weighted avg       0.50      0.22      0.30       434


************for dimension:  Vocabularyrange  ***************
DE Train, IT Test
CROSS LANG EVAL
0.52875
[[  0  18  20   1   0]
 [  0  44 192   7   0]
 [  0   7 267  52   2]
 [  0   0  76 112   0]
 [  0   0   0   2   0]]
0.4790376114393856
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        39
          A2       0.64      0.18      0.28       243
          B1       0.48      0.81      0.60       328
          B2       0.64      0.60      0.62       188
          C1       0.00      0.00      0.00         2

    accuracy                           0.53       800
   macro avg       0.35      0.32      0.30       800
weighted avg       0.54      0.53      0.48       800


0.57125
[[  2  22  14   1   0   0]
 [  1  81 158   1   0   2]
 [  0  33 231  59   5   0]
 [  0   1  43 142   2   0]
 [  0   0   0   1   1   0]
 [  0   0   0   0   0   0]]
0.5496200624068477
              precision    recall  f1-score   support

          A1       0.67      0.05      0.10        39
          A2       0.59      0.33      0.43       243
          B1       0.52      0.70      0.60       328
          B2       0.70      0.76      0.72       188
          C1       0.12      0.50      0.20         2
          C2       0.00      0.00      0.00         0

    accuracy                           0.57       800
   macro avg       0.43      0.39      0.34       800
weighted avg       0.59      0.57      0.55       800


0.5725
[[ 13  17   8   1   0   0]
 [ 25 116  92   5   1   4]
 [ 22  52 189  57   8   0]
 [  1   9  38 140   0   0]
 [  0   0   0   2   0   0]
 [  0   0   0   0   0   0]]
0.5779742937038912
              precision    recall  f1-score   support

          A1       0.21      0.33      0.26        39
          A2       0.60      0.48      0.53       243
          B1       0.58      0.58      0.58       328
          B2       0.68      0.74      0.71       188
          C1       0.00      0.00      0.00         2
          C2       0.00      0.00      0.00         0

    accuracy                           0.57       800
   macro avg       0.35      0.36      0.35       800
weighted avg       0.59      0.57      0.58       800


DE Train, CZ Test
CROSS LANG EVAL
0.35714285714285715
[[ 0  0  5  3  0]
 [ 0  9 67 56  0]
 [ 0  0 85 46 10]
 [ 0  0  0 55 88]
 [ 0  0  0  4  6]]
0.34464912911465323
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         8
          A2       1.00      0.07      0.13       132
          B1       0.54      0.60      0.57       141
          B2       0.34      0.38      0.36       143
          C1       0.06      0.60      0.11        10

    accuracy                           0.36       434
   macro avg       0.39      0.33      0.23       434
weighted avg       0.59      0.36      0.34       434


0.2995391705069124
[[  1   3   1   0   1   2]
 [  0  15  70   6  37   4]
 [  0   5 101   7  27   1]
 [  0   0   1   3 137   2]
 [  0   0   0   0  10   0]
 [  0   0   0   0   0   0]]
0.2864753423040875
              precision    recall  f1-score   support

          A1       1.00      0.12      0.22         8
          A2       0.65      0.11      0.19       132
          B1       0.58      0.72      0.64       141
          B2       0.19      0.02      0.04       143
          C1       0.05      1.00      0.09        10
          C2       0.00      0.00      0.00         0

    accuracy                           0.30       434
   macro avg       0.41      0.33      0.20       434
weighted avg       0.47      0.30      0.29       434


0.27880184331797236
[[  3   1   1   2   1   0]
 [  6  25  46   3  44   8]
 [  2   9  84   4  36   6]
 [  0   0   0   0 111  32]
 [  0   0   0   0   9   1]
 [  0   0   0   0   0   0]]
0.29951287957636874
              precision    recall  f1-score   support

          A1       0.27      0.38      0.32         8
          A2       0.71      0.19      0.30       132
          B1       0.64      0.60      0.62       141
          B2       0.00      0.00      0.00       143
          C1       0.04      0.90      0.09        10
          C2       0.00      0.00      0.00         0

    accuracy                           0.28       434
   macro avg       0.28      0.34      0.22       434
weighted avg       0.43      0.28      0.30       434


************for dimension:  Vocabularycontrol  ***************
DE Train, IT Test
CROSS LANG EVAL
0.4975
[[  0  47  22   1   0]
 [  0 101  99   4   0]
 [  0  67 213  47   0]
 [  0   4 108  84   0]
 [  0   0   1   2   0]]
0.4711461929691322
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        70
          A2       0.46      0.50      0.48       204
          B1       0.48      0.65      0.55       327
          B2       0.61      0.43      0.50       196
          C1       0.00      0.00      0.00         3

    accuracy                           0.50       800
   macro avg       0.31      0.32      0.31       800
weighted avg       0.46      0.50      0.47       800


0.46875
[[  1  51  16   0   0   2]
 [  3 127  67   6   0   1]
 [  3 101 155  57   0  11]
 [  0   6  66  92   0  32]
 [  0   0   0   2   0   1]
 [  0   0   0   0   0   0]]
0.46324430029166414
              precision    recall  f1-score   support

          A1       0.14      0.01      0.03        70
          A2       0.45      0.62      0.52       204
          B1       0.51      0.47      0.49       327
          B2       0.59      0.47      0.52       196
          C1       0.00      0.00      0.00         3
          C2       0.00      0.00      0.00         0

    accuracy                           0.47       800
   macro avg       0.28      0.26      0.26       800
weighted avg       0.48      0.47      0.46       800


0.34625
[[ 19  37  13   0   0   1]
 [ 28 115  51   4   4   2]
 [ 27  98 131  15   1  55]
 [  2  18  62  12   3  99]
 [  0   0   0   1   0   2]
 [  0   0   0   0   0   0]]
0.3561994893563722
              precision    recall  f1-score   support

          A1       0.25      0.27      0.26        70
          A2       0.43      0.56      0.49       204
          B1       0.51      0.40      0.45       327
          B2       0.38      0.06      0.11       196
          C1       0.00      0.00      0.00         3
          C2       0.00      0.00      0.00         0

    accuracy                           0.35       800
   macro avg       0.26      0.22      0.22       800
weighted avg       0.43      0.35      0.36       800


DE Train, CZ Test
CROSS LANG EVAL
0.4216589861751152
[[ 0  1  1  3  0]
 [ 0 16 63 52  0]
 [ 0 10 76 96  0]
 [ 0  1  8 91  0]
 [ 0  0  0 16  0]]
0.37104394408141134
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         5
          A2       0.57      0.12      0.20       131
          B1       0.51      0.42      0.46       182
          B2       0.35      0.91      0.51       100
          C1       0.00      0.00      0.00        16

    accuracy                           0.42       434
   macro avg       0.29      0.29      0.23       434
weighted avg       0.47      0.42      0.37       434


0.423963133640553
[[ 0  1  1  3  0]
 [ 6 21 58 46  0]
 [ 1 14 75 90  2]
 [ 1  0  7 88  4]
 [ 0  0  0 16  0]]
0.38888982713412473
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         5
          A2       0.58      0.16      0.25       131
          B1       0.53      0.41      0.46       182
          B2       0.36      0.88      0.51       100
          C1       0.00      0.00      0.00        16

    accuracy                           0.42       434
   macro avg       0.30      0.29      0.25       434
weighted avg       0.48      0.42      0.39       434


0.2465437788018433
[[ 1  0  1  3  0]
 [17 23 39 25 27]
 [ 7 16 61 23 75]
 [ 2  0  7  6 85]
 [ 0  0  0  0 16]]
0.2818117228345588
              precision    recall  f1-score   support

          A1       0.04      0.20      0.06         5
          A2       0.59      0.18      0.27       131
          B1       0.56      0.34      0.42       182
          B2       0.11      0.06      0.08       100
          C1       0.08      1.00      0.15        16

    accuracy                           0.25       434
   macro avg       0.28      0.35      0.20       434
weighted avg       0.44      0.25      0.28       434


************for dimension:  CoherenceCohesion  ***************
DE Train, IT Test
CROSS LANG EVAL
0.37125
[[  0  41  67   1]
 [  0  66 256  12]
 [  0   3 205  92]
 [  0   0  31  26]]
0.3228162628422393
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00       109
          A2       0.60      0.20      0.30       334
          B1       0.37      0.68      0.48       300
          B2       0.20      0.46      0.28        57

    accuracy                           0.37       800
   macro avg       0.29      0.33      0.26       800
weighted avg       0.40      0.37      0.32       800


0.36375
[[ 11  44  52   1   1]
 [ 16  96 211  11   0]
 [  0  12 147 141   0]
 [  0   1  19  37   0]
 [  0   0   0   0   0]]
0.3592207522462409
              precision    recall  f1-score   support

          A1       0.41      0.10      0.16       109
          A2       0.63      0.29      0.39       334
          B1       0.34      0.49      0.40       300
          B2       0.19      0.65      0.30        57
          C2       0.00      0.00      0.00         0

    accuracy                           0.36       800
   macro avg       0.31      0.31      0.25       800
weighted avg       0.46      0.36      0.36       800


0.4425
[[ 45  34  28   1   0   1]
 [ 93 105 121   9   3   3]
 [ 11  28 180  78   3   0]
 [  0   3  30  24   0   0]
 [  0   0   0   0   0   0]
 [  0   0   0   0   0   0]]
0.44657993167643667
              precision    recall  f1-score   support

          A1       0.30      0.41      0.35       109
          A2       0.62      0.31      0.42       334
          B1       0.50      0.60      0.55       300
          B2       0.21      0.42      0.28        57
          C1       0.00      0.00      0.00         0
          C2       0.00      0.00      0.00         0

    accuracy                           0.44       800
   macro avg       0.27      0.29      0.27       800
weighted avg       0.50      0.44      0.45       800


DE Train, CZ Test
CROSS LANG EVAL
0.6336405529953917
[[  0   0   1   0   0]
 [  0   7  47  47   0]
 [  0   5 116  50   0]
 [  0   0   4 152   0]
 [  0   0   0   5   0]]
0.5649956582759824
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.58      0.07      0.12       101
          B1       0.69      0.68      0.68       171
          B2       0.60      0.97      0.74       156
          C1       0.00      0.00      0.00         5

    accuracy                           0.63       434
   macro avg       0.37      0.34      0.31       434
weighted avg       0.62      0.63      0.56       434


0.6129032258064516
[[  0   1   0   0   0   0]
 [  9  14  35  37   1   5]
 [  0  14 116  40   0   1]
 [  0   0   5 136  14   1]
 [  0   0   0   5   0   0]
 [  0   0   0   0   0   0]]
0.5910817800134167
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.48      0.14      0.22       101
          B1       0.74      0.68      0.71       171
          B2       0.62      0.87      0.73       156
          C1       0.00      0.00      0.00         5
          C2       0.00      0.00      0.00         0

    accuracy                           0.61       434
   macro avg       0.31      0.28      0.28       434
weighted avg       0.63      0.61      0.59       434


0.2304147465437788
[[  1   0   0   0   0   0]
 [ 22  12  14   9  11  33]
 [  8  30  81  11  28  13]
 [  1   0   3   2 103  47]
 [  0   0   0   0   4   1]
 [  0   0   0   0   0   0]]
0.2851695536655299
              precision    recall  f1-score   support

          A1       0.03      1.00      0.06         1
          A2       0.29      0.12      0.17       101
          B1       0.83      0.47      0.60       171
          B2       0.09      0.01      0.02       156
          C1       0.03      0.80      0.05         5
          C2       0.00      0.00      0.00         0

    accuracy                           0.23       434
   macro avg       0.21      0.40      0.15       434
weighted avg       0.43      0.23      0.29       434


************for dimension:  Sociolinguisticappropriateness  ***************
DE Train, IT Test
CROSS LANG EVAL
0.365
[[  0  34  17   5]
 [  0 122 163  51]
 [  0  48 141 183]
 [  0   0   7  29]]
0.3856918755221386
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        56
          A2       0.60      0.36      0.45       336
          B1       0.43      0.38      0.40       372
          B2       0.11      0.81      0.19        36

    accuracy                           0.36       800
   macro avg       0.28      0.39      0.26       800
weighted avg       0.46      0.36      0.39       800


0.41125
[[  1  39  10   6   0]
 [ 10 170 116  40   0]
 [  2  74 130 165   1]
 [  0   0   8  28   0]
 [  0   0   0   0   0]]
0.4319816303142027
              precision    recall  f1-score   support

          A1       0.08      0.02      0.03        56
          A2       0.60      0.51      0.55       336
          B1       0.49      0.35      0.41       372
          B2       0.12      0.78      0.20        36
          C1       0.00      0.00      0.00         0

    accuracy                           0.41       800
   macro avg       0.26      0.33      0.24       800
weighted avg       0.49      0.41      0.43       800


0.445
[[ 16  25   9   3   3]
 [ 54 145 107  27   3]
 [ 17  74 173 104   4]
 [  0   2  12  22   0]
 [  0   0   0   0   0]]
0.4743190791961443
              precision    recall  f1-score   support

          A1       0.18      0.29      0.22        56
          A2       0.59      0.43      0.50       336
          B1       0.57      0.47      0.51       372
          B2       0.14      0.61      0.23        36
          C1       0.00      0.00      0.00         0

    accuracy                           0.45       800
   macro avg       0.30      0.36      0.29       800
weighted avg       0.53      0.45      0.47       800


DE Train, CZ Test
CROSS LANG EVAL
0.1543778801843318
[[  0   7   9 245]
 [  0  22  56  28]
 [  0   7  43  13]
 [  0   0   2   2]]
0.14796724428163055
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00       261
          A2       0.61      0.21      0.31       106
          B1       0.39      0.68      0.50        63
          B2       0.01      0.50      0.01         4

    accuracy                           0.15       434
   macro avg       0.25      0.35      0.21       434
weighted avg       0.21      0.15      0.15       434


0.18663594470046083
[[  5   9   5 221  21]
 [  9  28  46  23   0]
 [  1  12  47   3   0]
 [  0   0   3   1   0]
 [  0   0   0   0   0]]
0.19330598631793972
              precision    recall  f1-score   support

          A1       0.33      0.02      0.04       261
          A2       0.57      0.26      0.36       106
          B1       0.47      0.75      0.57        63
          B2       0.00      0.25      0.01         4
          C1       0.00      0.00      0.00         0

    accuracy                           0.19       434
   macro avg       0.27      0.26      0.20       434
weighted avg       0.41      0.19      0.19       434


0.18202764976958524
[[  8   5   1  37 210]
 [ 19  31  34  20   2]
 [  5  14  39   5   0]
 [  1   0   2   1   0]
 [  0   0   0   0   0]]
0.21153043256116202
              precision    recall  f1-score   support

          A1       0.24      0.03      0.05       261
          A2       0.62      0.29      0.40       106
          B1       0.51      0.62      0.56        63
          B2       0.02      0.25      0.03         4
          C1       0.00      0.00      0.00         0

    accuracy                           0.18       434
   macro avg       0.28      0.24      0.21       434
weighted avg       0.37      0.18      0.21       434


0:13:23.179689
2020-06-08 16:58:07.747576
2020-06-08 17:11:30.927265
