DOING SINGLE LANG CLASSIFICATION EXPTS
FOr lang:  DE
768
************for dimension:  OverallCEFRrating  ***************
Printing class statistics
Counter({'B1': 328, 'A2': 306, 'B2': 293, 'A1': 57, 'C1': 42})
RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=300,
                       n_jobs=None, oob_score=False, random_state=1234,
                       verbose=0, warm_start=False)
Fold 0
[[ 0 11  1  0  0]
 [ 0 44 17  0  0]
 [ 0 15 32 19  0]
 [ 0  0 12 47  0]
 [ 0  0  0  8  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        12
          A2       0.63      0.72      0.67        61
          B1       0.52      0.48      0.50        66
          B2       0.64      0.80      0.71        59
          C1       0.00      0.00      0.00         8

    accuracy                           0.60       206
   macro avg       0.36      0.40      0.38       206
weighted avg       0.53      0.60      0.56       206


Fold 1
[[ 0  9  1  1  0]
 [ 0 46 16  0  0]
 [ 0 24 28 13  0]
 [ 0  1  6 52  0]
 [ 0  0  0  8  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        11
          A2       0.57      0.74      0.65        62
          B1       0.55      0.43      0.48        65
          B2       0.70      0.88      0.78        59
          C1       0.00      0.00      0.00         8

    accuracy                           0.61       205
   macro avg       0.37      0.41      0.38       205
weighted avg       0.55      0.61      0.57       205


Fold 2
[[ 0 10  1  0  0]
 [ 0 45 16  0  0]
 [ 0 15 38 12  0]
 [ 0  1  7 51  0]
 [ 0  0  1  8  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        11
          A2       0.63      0.74      0.68        61
          B1       0.60      0.58      0.59        65
          B2       0.72      0.86      0.78        59
          C1       0.00      0.00      0.00         9

    accuracy                           0.65       205
   macro avg       0.39      0.44      0.41       205
weighted avg       0.59      0.65      0.62       205


Fold 3
[[ 0  9  2  0  0]
 [ 0 49 12  0  0]
 [ 0 13 38 15  0]
 [ 0  2  6 50  0]
 [ 0  0  1  8  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        11
          A2       0.67      0.80      0.73        61
          B1       0.64      0.58      0.61        66
          B2       0.68      0.86      0.76        58
          C1       0.00      0.00      0.00         9

    accuracy                           0.67       205
   macro avg       0.40      0.45      0.42       205
weighted avg       0.60      0.67      0.63       205


Fold 4
[[ 0 11  1  0  0]
 [ 0 47 14  0  0]
 [ 0 17 33 16  0]
 [ 0  0 10 48  0]
 [ 0  0  0  8  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        12
          A2       0.63      0.77      0.69        61
          B1       0.57      0.50      0.53        66
          B2       0.67      0.83      0.74        58
          C1       0.00      0.00      0.00         8

    accuracy                           0.62       205
   macro avg       0.37      0.42      0.39       205
weighted avg       0.56      0.62      0.59       205


K-fold scores
[0.5615356667812716, 0.5740666476838989, 0.6169608135766673, 0.6293402412625015, 0.58595885948642]
SKF f1 score mean 0.5935724457581519

LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
          verbose=0)
Fold 0
[[ 3  8  1  0  0]
 [ 8 39 13  1  0]
 [ 1 14 35 16  0]
 [ 0  1 11 47  0]
 [ 0  0  0  6  2]]
              precision    recall  f1-score   support

          A1       0.25      0.25      0.25        12
          A2       0.63      0.64      0.63        61
          B1       0.58      0.53      0.56        66
          B2       0.67      0.80      0.73        59
          C1       1.00      0.25      0.40         8

    accuracy                           0.61       206
   macro avg       0.63      0.49      0.51       206
weighted avg       0.62      0.61      0.60       206


Fold 1
[[ 5  6  0  0  0]
 [ 2 45 14  1  0]
 [ 1 15 36 13  0]
 [ 0  0  8 47  4]
 [ 0  0  2  3  3]]
              precision    recall  f1-score   support

          A1       0.62      0.45      0.53        11
          A2       0.68      0.73      0.70        62
          B1       0.60      0.55      0.58        65
          B2       0.73      0.80      0.76        59
          C1       0.43      0.38      0.40         8

    accuracy                           0.66       205
   macro avg       0.61      0.58      0.59       205
weighted avg       0.66      0.66      0.66       205


Fold 2
[[ 4  7  0  0  0]
 [ 3 37 18  2  1]
 [ 1 20 30 12  2]
 [ 0  0 13 41  5]
 [ 0  0  1  4  4]]
              precision    recall  f1-score   support

          A1       0.50      0.36      0.42        11
          A2       0.58      0.61      0.59        61
          B1       0.48      0.46      0.47        65
          B2       0.69      0.69      0.69        59
          C1       0.33      0.44      0.38         9

    accuracy                           0.57       205
   macro avg       0.52      0.51      0.51       205
weighted avg       0.57      0.57      0.57       205


Fold 3
[[ 3  6  2  0  0]
 [ 7 39 15  0  0]
 [ 1 12 41 10  2]
 [ 0  0 15 41  2]
 [ 0  0  1  7  1]]
              precision    recall  f1-score   support

          A1       0.27      0.27      0.27        11
          A2       0.68      0.64      0.66        61
          B1       0.55      0.62      0.59        66
          B2       0.71      0.71      0.71        58
          C1       0.20      0.11      0.14         9

    accuracy                           0.61       205
   macro avg       0.48      0.47      0.47       205
weighted avg       0.61      0.61      0.61       205


Fold 4
[[ 4  6  1  1  0]
 [ 5 41 15  0  0]
 [ 1 17 33 13  2]
 [ 0  0 13 41  4]
 [ 0  0  2  3  3]]
              precision    recall  f1-score   support

          A1       0.40      0.33      0.36        12
          A2       0.64      0.67      0.66        61
          B1       0.52      0.50      0.51        66
          B2       0.71      0.71      0.71        58
          C1       0.33      0.38      0.35         8

    accuracy                           0.60       205
   macro avg       0.52      0.52      0.52       205
weighted avg       0.59      0.60      0.59       205


K-fold scores
[0.6045720463978178, 0.6590861198952168, 0.5652722526500619, 0.6061702002007915, 0.5937115028443579]
SKF f1 score mean 0.6057624243976492

LogisticRegression(C=1.0, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='multinomial', n_jobs=None,
                   penalty='l2', random_state=1234, solver='lbfgs', tol=0.0001,
                   verbose=0, warm_start=False)
Fold 0
[[ 7  5  0  0  0]
 [10 38 12  1  0]
 [ 1 11 35 18  1]
 [ 0  1 10 44  4]
 [ 0  0  0  5  3]]
              precision    recall  f1-score   support

          A1       0.39      0.58      0.47        12
          A2       0.69      0.62      0.66        61
          B1       0.61      0.53      0.57        66
          B2       0.65      0.75      0.69        59
          C1       0.38      0.38      0.38         8

    accuracy                           0.62       206
   macro avg       0.54      0.57      0.55       206
weighted avg       0.62      0.62      0.62       206


Fold 1
[[ 7  4  0  0  0]
 [ 5 42 15  0  0]
 [ 0 20 34 11  0]
 [ 0  0  9 46  4]
 [ 0  0  1  3  4]]
              precision    recall  f1-score   support

          A1       0.58      0.64      0.61        11
          A2       0.64      0.68      0.66        62
          B1       0.58      0.52      0.55        65
          B2       0.77      0.78      0.77        59
          C1       0.50      0.50      0.50         8

    accuracy                           0.65       205
   macro avg       0.61      0.62      0.62       205
weighted avg       0.65      0.65      0.65       205


Fold 2
[[ 8  3  0  0  0]
 [10 35 16  0  0]
 [ 1 16 39  9  0]
 [ 0  0 11 43  5]
 [ 0  0  0  3  6]]
              precision    recall  f1-score   support

          A1       0.42      0.73      0.53        11
          A2       0.65      0.57      0.61        61
          B1       0.59      0.60      0.60        65
          B2       0.78      0.73      0.75        59
          C1       0.55      0.67      0.60         9

    accuracy                           0.64       205
   macro avg       0.60      0.66      0.62       205
weighted avg       0.65      0.64      0.64       205


Fold 3
[[ 4  5  2  0  0]
 [14 38  9  0  0]
 [ 1 13 42  9  1]
 [ 0  0 10 45  3]
 [ 0  0  0  7  2]]
              precision    recall  f1-score   support

          A1       0.21      0.36      0.27        11
          A2       0.68      0.62      0.65        61
          B1       0.67      0.64      0.65        66
          B2       0.74      0.78      0.76        58
          C1       0.33      0.22      0.27         9

    accuracy                           0.64       205
   macro avg       0.53      0.52      0.52       205
weighted avg       0.65      0.64      0.64       205


Fold 4
[[ 6  5  1  0  0]
 [ 4 43 14  0  0]
 [ 1 12 39 13  1]
 [ 0  0 11 42  5]
 [ 0  0  0  5  3]]
              precision    recall  f1-score   support

          A1       0.55      0.50      0.52        12
          A2       0.72      0.70      0.71        61
          B1       0.60      0.59      0.60        66
          B2       0.70      0.72      0.71        58
          C1       0.33      0.38      0.35         8

    accuracy                           0.65       205
   macro avg       0.58      0.58      0.58       205
weighted avg       0.65      0.65      0.65       205


K-fold scores
[0.6165455466743444, 0.6470329699628629, 0.6419910412460283, 0.6429246603014579, 0.6489054458277708]
SKF f1 score mean 0.6394799328024928

************for dimension:  Grammaticalaccuracy  ***************
Printing class statistics
Counter({'B1': 349, 'A2': 284, 'B2': 258, 'A1': 88, 'C1': 47})
RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=300,
                       n_jobs=None, oob_score=False, random_state=1234,
                       verbose=0, warm_start=False)
Fold 0
[[ 2 15  1  0  0]
 [ 0 36 21  0  0]
 [ 0 23 35 12  0]
 [ 0  2 10 39  0]
 [ 0  0  4  6  0]]
              precision    recall  f1-score   support

          A1       1.00      0.11      0.20        18
          A2       0.47      0.63      0.54        57
          B1       0.49      0.50      0.50        70
          B2       0.68      0.76      0.72        51
          C1       0.00      0.00      0.00        10

    accuracy                           0.54       206
   macro avg       0.53      0.40      0.39       206
weighted avg       0.56      0.54      0.51       206


Fold 1
[[ 2 11  4  0  0]
 [ 0 41 16  0  0]
 [ 0 19 40 11  0]
 [ 0  2 13 36  0]
 [ 0  0  0 10  0]]
              precision    recall  f1-score   support

          A1       1.00      0.12      0.21        17
          A2       0.56      0.72      0.63        57
          B1       0.55      0.57      0.56        70
          B2       0.63      0.71      0.67        51
          C1       0.00      0.00      0.00        10

    accuracy                           0.58       205
   macro avg       0.55      0.42      0.41       205
weighted avg       0.58      0.58      0.55       205


Fold 2
[[ 1  8  7  1  0]
 [ 2 25 30  0  0]
 [ 0 22 31 17  0]
 [ 0  1 19 32  0]
 [ 0  0  3  6  0]]
              precision    recall  f1-score   support

          A1       0.33      0.06      0.10        17
          A2       0.45      0.44      0.44        57
          B1       0.34      0.44      0.39        70
          B2       0.57      0.62      0.59        52
          C1       0.00      0.00      0.00         9

    accuracy                           0.43       205
   macro avg       0.34      0.31      0.30       205
weighted avg       0.41      0.43      0.41       205


Fold 3
[[ 0 13  5  0  0]
 [ 1 38 18  0  0]
 [ 2 16 38 13  0]
 [ 0  1 14 37  0]
 [ 0  0  0  9  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        18
          A2       0.56      0.67      0.61        57
          B1       0.51      0.55      0.53        69
          B2       0.63      0.71      0.67        52
          C1       0.00      0.00      0.00         9

    accuracy                           0.55       205
   macro avg       0.34      0.39      0.36       205
weighted avg       0.48      0.55      0.52       205


Fold 4
[[ 1 16  1  0  0]
 [ 3 31 22  0  0]
 [ 0 17 41 12  0]
 [ 0  3 12 37  0]
 [ 0  0  1  8  0]]
              precision    recall  f1-score   support

          A1       0.25      0.06      0.09        18
          A2       0.46      0.55      0.50        56
          B1       0.53      0.59      0.56        70
          B2       0.65      0.71      0.68        52
          C1       0.00      0.00      0.00         9

    accuracy                           0.54       205
   macro avg       0.38      0.38      0.37       205
weighted avg       0.49      0.54      0.51       205


K-fold scores
[0.514768200194765, 0.5497250374785677, 0.4139563597700874, 0.5158016260162602, 0.5083628158730898]
SKF f1 score mean 0.500522807866554

LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
          verbose=0)
Fold 0
[[ 8  6  2  2  0]
 [ 7 30 16  4  0]
 [ 1 26 32 10  1]
 [ 0  2  8 39  2]
 [ 0  0  2  6  2]]
              precision    recall  f1-score   support

          A1       0.50      0.44      0.47        18
          A2       0.47      0.53      0.50        57
          B1       0.53      0.46      0.49        70
          B2       0.64      0.76      0.70        51
          C1       0.40      0.20      0.27        10

    accuracy                           0.54       206
   macro avg       0.51      0.48      0.48       206
weighted avg       0.53      0.54      0.53       206


Fold 1
[[ 5  9  3  0  0]
 [11 31 13  2  0]
 [ 2 24 28 15  1]
 [ 1  2 15 28  5]
 [ 0  1  1  6  2]]
              precision    recall  f1-score   support

          A1       0.26      0.29      0.28        17
          A2       0.46      0.54      0.50        57
          B1       0.47      0.40      0.43        70
          B2       0.55      0.55      0.55        51
          C1       0.25      0.20      0.22        10

    accuracy                           0.46       205
   macro avg       0.40      0.40      0.40       205
weighted avg       0.46      0.46      0.46       205


Fold 2
[[ 6  7  4  0  0]
 [ 9 23 24  1  0]
 [ 0 20 28 22  0]
 [ 1  3 12 28  8]
 [ 0  0  1  5  3]]
              precision    recall  f1-score   support

          A1       0.38      0.35      0.36        17
          A2       0.43      0.40      0.42        57
          B1       0.41      0.40      0.40        70
          B2       0.50      0.54      0.52        52
          C1       0.27      0.33      0.30         9

    accuracy                           0.43       205
   macro avg       0.40      0.41      0.40       205
weighted avg       0.43      0.43      0.43       205


Fold 3
[[ 7 11  0  0  0]
 [ 8 32 16  1  0]
 [ 4 20 33 11  1]
 [ 0  2 16 29  5]
 [ 0  0  0  9  0]]
              precision    recall  f1-score   support

          A1       0.37      0.39      0.38        18
          A2       0.49      0.56      0.52        57
          B1       0.51      0.48      0.49        69
          B2       0.58      0.56      0.57        52
          C1       0.00      0.00      0.00         9

    accuracy                           0.49       205
   macro avg       0.39      0.40      0.39       205
weighted avg       0.49      0.49      0.49       205


Fold 4
[[ 6 12  0  0  0]
 [ 8 28 20  0  0]
 [ 5 14 35 14  2]
 [ 0  2 22 24  4]
 [ 0  0  1  6  2]]
              precision    recall  f1-score   support

          A1       0.32      0.33      0.32        18
          A2       0.50      0.50      0.50        56
          B1       0.45      0.50      0.47        70
          B2       0.55      0.46      0.50        52
          C1       0.25      0.22      0.24         9

    accuracy                           0.46       205
   macro avg       0.41      0.40      0.41       205
weighted avg       0.47      0.46      0.46       205


K-fold scores
[0.5309762782343386, 0.4565770273087347, 0.4286955299027592, 0.48910318162399596, 0.46372484392570473]
SKF f1 score mean 0.47381537219910663

LogisticRegression(C=1.0, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='multinomial', n_jobs=None,
                   penalty='l2', random_state=1234, solver='lbfgs', tol=0.0001,
                   verbose=0, warm_start=False)
Fold 0
[[ 9  9  0  0  0]
 [ 7 39 10  1  0]
 [ 4 23 32 10  1]
 [ 0  2  9 32  8]
 [ 0  1  1  3  5]]
              precision    recall  f1-score   support

          A1       0.45      0.50      0.47        18
          A2       0.53      0.68      0.60        57
          B1       0.62      0.46      0.52        70
          B2       0.70      0.63      0.66        51
          C1       0.36      0.50      0.42        10

    accuracy                           0.57       206
   macro avg       0.53      0.55      0.53       206
weighted avg       0.58      0.57      0.57       206


Fold 1
[[ 7  9  1  0  0]
 [12 30 14  1  0]
 [ 2 23 27 18  0]
 [ 1  2  7 34  7]
 [ 0  0  1  7  2]]
              precision    recall  f1-score   support

          A1       0.32      0.41      0.36        17
          A2       0.47      0.53      0.50        57
          B1       0.54      0.39      0.45        70
          B2       0.57      0.67      0.61        51
          C1       0.22      0.20      0.21        10

    accuracy                           0.49       205
   macro avg       0.42      0.44      0.43       205
weighted avg       0.49      0.49      0.48       205


Fold 2
[[ 9  3  5  0  0]
 [ 9 24 24  0  0]
 [ 2 20 23 25  0]
 [ 0  1 13 28 10]
 [ 0  0  1  4  4]]
              precision    recall  f1-score   support

          A1       0.45      0.53      0.49        17
          A2       0.50      0.42      0.46        57
          B1       0.35      0.33      0.34        70
          B2       0.49      0.54      0.51        52
          C1       0.29      0.44      0.35         9

    accuracy                           0.43       205
   macro avg       0.42      0.45      0.43       205
weighted avg       0.43      0.43      0.43       205


Fold 3
[[ 9  8  1  0  0]
 [ 9 38 10  0  0]
 [ 4 19 29 16  1]
 [ 0  2 13 30  7]
 [ 0  0  0  9  0]]
              precision    recall  f1-score   support

          A1       0.41      0.50      0.45        18
          A2       0.57      0.67      0.61        57
          B1       0.55      0.42      0.48        69
          B2       0.55      0.58      0.56        52
          C1       0.00      0.00      0.00         9

    accuracy                           0.52       205
   macro avg       0.41      0.43      0.42       205
weighted avg       0.52      0.52      0.51       205


Fold 4
[[ 9  9  0  0  0]
 [11 31 14  0  0]
 [ 5 14 36 13  2]
 [ 0  2 17 29  4]
 [ 0  0  1  5  3]]
              precision    recall  f1-score   support

          A1       0.36      0.50      0.42        18
          A2       0.55      0.55      0.55        56
          B1       0.53      0.51      0.52        70
          B2       0.62      0.56      0.59        52
          C1       0.33      0.33      0.33         9

    accuracy                           0.53       205
   macro avg       0.48      0.49      0.48       205
weighted avg       0.53      0.53      0.53       205


K-fold scores
[0.5679743192492358, 0.48397821128594853, 0.4285361698952796, 0.5121836149471475, 0.5293720454439584]
SKF f1 score mean 0.504408872164314

************for dimension:  Orthography  ***************
Printing class statistics
Counter({'B2': 338, 'B1': 321, 'C1': 161, 'A2': 150, 'C2': 38, 'A1': 18})
RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=300,
                       n_jobs=None, oob_score=False, random_state=1234,
                       verbose=0, warm_start=False)
Fold 0
[[ 0  1  3  0  0  0]
 [ 0  7 21  2  0  0]
 [ 0  5 46 13  0  0]
 [ 0  2 20 44  1  0]
 [ 0  0  4 27  2  0]
 [ 0  0  1  5  2  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         4
          A2       0.47      0.23      0.31        30
          B1       0.48      0.72      0.58        64
          B2       0.48      0.66      0.56        67
          C1       0.40      0.06      0.11        33
          C2       0.00      0.00      0.00         8

    accuracy                           0.48       206
   macro avg       0.31      0.28      0.26       206
weighted avg       0.44      0.48      0.42       206


Fold 1
[[ 0  1  3  0  0  0]
 [ 0  3 24  3  0  0]
 [ 0  1 46 17  0  0]
 [ 0  3 13 49  3  0]
 [ 0  0  2 26  4  0]
 [ 0  0  1  6  0  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         4
          A2       0.38      0.10      0.16        30
          B1       0.52      0.72      0.60        64
          B2       0.49      0.72      0.58        68
          C1       0.57      0.12      0.21        32
          C2       0.00      0.00      0.00         7

    accuracy                           0.50       205
   macro avg       0.32      0.28      0.26       205
weighted avg       0.47      0.50      0.44       205


Fold 2
[[ 0  2  2  0  0  0]
 [ 0  8 20  2  0  0]
 [ 0  3 47 14  0  0]
 [ 0  1 21 45  1  0]
 [ 0  0  2 27  3  0]
 [ 0  0  0  6  1  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         4
          A2       0.57      0.27      0.36        30
          B1       0.51      0.73      0.60        64
          B2       0.48      0.66      0.56        68
          C1       0.60      0.09      0.16        32
          C2       0.00      0.00      0.00         7

    accuracy                           0.50       205
   macro avg       0.36      0.29      0.28       205
weighted avg       0.50      0.50      0.45       205


Fold 3
[[ 0  2  1  0  0  0]
 [ 0  4 23  3  0  0]
 [ 0  2 48 14  0  0]
 [ 0  2 16 43  7  0]
 [ 0  1  2 21  8  0]
 [ 0  0  0  7  1  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         3
          A2       0.36      0.13      0.20        30
          B1       0.53      0.75      0.62        64
          B2       0.49      0.63      0.55        68
          C1       0.50      0.25      0.33        32
          C2       0.00      0.00      0.00         8

    accuracy                           0.50       205
   macro avg       0.31      0.29      0.28       205
weighted avg       0.46      0.50      0.46       205


Fold 4
[[ 0  0  3  0  0  0]
 [ 0  6 22  2  0  0]
 [ 0  6 51  8  0  0]
 [ 0  0 24 42  1  0]
 [ 0  0  4 26  2  0]
 [ 0  0  1  5  2  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         3
          A2       0.50      0.20      0.29        30
          B1       0.49      0.78      0.60        65
          B2       0.51      0.63      0.56        67
          C1       0.40      0.06      0.11        32
          C2       0.00      0.00      0.00         8

    accuracy                           0.49       205
   macro avg       0.32      0.28      0.26       205
weighted avg       0.46      0.49      0.43       205


K-fold scores
[0.423082134858945, 0.43520271933076377, 0.45092761190322167, 0.4580663833489532, 0.4319555513701856]
SKF f1 score mean 0.4398468801624139

LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
          verbose=0)
Fold 0
[[ 1  2  0  1  0  0]
 [ 1 15 13  0  1  0]
 [ 0 17 30 15  1  1]
 [ 0  6 18 29 12  2]
 [ 0  0  4 16 11  2]
 [ 0  0  3  1  4  0]]
              precision    recall  f1-score   support

          A1       0.50      0.25      0.33         4
          A2       0.38      0.50      0.43        30
          B1       0.44      0.47      0.45        64
          B2       0.47      0.43      0.45        67
          C1       0.38      0.33      0.35        33
          C2       0.00      0.00      0.00         8

    accuracy                           0.42       206
   macro avg       0.36      0.33      0.34       206
weighted avg       0.41      0.42      0.41       206


Fold 1
[[ 2  1  1  0  0  0]
 [ 2 15 11  2  0  0]
 [ 0 18 25 19  1  1]
 [ 0  7 18 26 15  2]
 [ 0  1  1 16 12  2]
 [ 0  0  0  2  5  0]]
              precision    recall  f1-score   support

          A1       0.50      0.50      0.50         4
          A2       0.36      0.50      0.42        30
          B1       0.45      0.39      0.42        64
          B2       0.40      0.38      0.39        68
          C1       0.36      0.38      0.37        32
          C2       0.00      0.00      0.00         7

    accuracy                           0.39       205
   macro avg       0.34      0.36      0.35       205
weighted avg       0.39      0.39      0.39       205


Fold 2
[[ 0  2  1  1  0  0]
 [ 2 11 15  2  0  0]
 [ 1  8 36 18  1  0]
 [ 0  2 24 29 11  2]
 [ 0  0  2 15 13  2]
 [ 0  0  0  4  3  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         4
          A2       0.48      0.37      0.42        30
          B1       0.46      0.56      0.51        64
          B2       0.42      0.43      0.42        68
          C1       0.46      0.41      0.43        32
          C2       0.00      0.00      0.00         7

    accuracy                           0.43       205
   macro avg       0.30      0.29      0.30       205
weighted avg       0.43      0.43      0.43       205


Fold 3
[[ 0  2  1  0  0  0]
 [ 0  9 20  1  0  0]
 [ 0 17 34 10  2  1]
 [ 1  0 15 29 21  2]
 [ 0  1  0 10 18  3]
 [ 0  0  1  3  3  1]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         3
          A2       0.31      0.30      0.31        30
          B1       0.48      0.53      0.50        64
          B2       0.55      0.43      0.48        68
          C1       0.41      0.56      0.47        32
          C2       0.14      0.12      0.13         8

    accuracy                           0.44       205
   macro avg       0.31      0.32      0.32       205
weighted avg       0.45      0.44      0.44       205


Fold 4
[[ 0  1  2  0  0  0]
 [ 1 16 11  1  1  0]
 [ 0 15 33 15  2  0]
 [ 0  3 25 23 11  5]
 [ 0  0  3 13 11  5]
 [ 0  0  1  3  4  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         3
          A2       0.46      0.53      0.49        30
          B1       0.44      0.51      0.47        65
          B2       0.42      0.34      0.38        67
          C1       0.38      0.34      0.36        32
          C2       0.00      0.00      0.00         8

    accuracy                           0.40       205
   macro avg       0.28      0.29      0.28       205
weighted avg       0.40      0.40      0.40       205


K-fold scores
[0.4131800665460779, 0.3881391094998284, 0.42711474267600597, 0.4400447909060547, 0.4010505687834756]
SKF f1 score mean 0.4139058556822885

LogisticRegression(C=1.0, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='multinomial', n_jobs=None,
                   penalty='l2', random_state=1234, solver='lbfgs', tol=0.0001,
                   verbose=0, warm_start=False)
Fold 0
[[ 0  2  1  1  0  0]
 [ 0 20 10  0  0  0]
 [ 0 15 35 12  1  1]
 [ 0  4 20 23 14  6]
 [ 0  0  3 11 15  4]
 [ 0  0  0  2  6  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         4
          A2       0.49      0.67      0.56        30
          B1       0.51      0.55      0.53        64
          B2       0.47      0.34      0.40        67
          C1       0.42      0.45      0.43        33
          C2       0.00      0.00      0.00         8

    accuracy                           0.45       206
   macro avg       0.31      0.34      0.32       206
weighted avg       0.45      0.45      0.44       206


Fold 1
[[ 2  1  1  0  0  0]
 [ 2 12 15  1  0  0]
 [ 0 16 28 16  3  1]
 [ 0  7 16 25 15  5]
 [ 0  0  1 10 18  3]
 [ 0  0  0  1  5  1]]
              precision    recall  f1-score   support

          A1       0.50      0.50      0.50         4
          A2       0.33      0.40      0.36        30
          B1       0.46      0.44      0.45        64
          B2       0.47      0.37      0.41        68
          C1       0.44      0.56      0.49        32
          C2       0.10      0.14      0.12         7

    accuracy                           0.42       205
   macro avg       0.38      0.40      0.39       205
weighted avg       0.43      0.42      0.42       205


Fold 2
[[ 0  3  1  0  0  0]
 [ 3 15 11  1  0  0]
 [ 1 11 39 12  1  0]
 [ 0  4 18 30 14  2]
 [ 0  0  2 14 13  3]
 [ 0  0  0  4  3  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         4
          A2       0.45      0.50      0.48        30
          B1       0.55      0.61      0.58        64
          B2       0.49      0.44      0.47        68
          C1       0.42      0.41      0.41        32
          C2       0.00      0.00      0.00         7

    accuracy                           0.47       205
   macro avg       0.32      0.33      0.32       205
weighted avg       0.47      0.47      0.47       205


Fold 3
[[ 0  2  1  0  0  0]
 [ 0 11 19  0  0  0]
 [ 1 18 33 11  1  0]
 [ 1  1 15 27 22  2]
 [ 0  1  0  7 21  3]
 [ 0  0  0  1  5  2]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         3
          A2       0.33      0.37      0.35        30
          B1       0.49      0.52      0.50        64
          B2       0.59      0.40      0.47        68
          C1       0.43      0.66      0.52        32
          C2       0.29      0.25      0.27         8

    accuracy                           0.46       205
   macro avg       0.35      0.36      0.35       205
weighted avg       0.47      0.46      0.46       205


Fold 4
[[ 0  2  1  0  0  0]
 [ 3 14 12  0  1  0]
 [ 1 15 37 12  0  0]
 [ 0  5 20 21 16  5]
 [ 0  0  1 10 14  7]
 [ 0  0  1  3  4  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         3
          A2       0.39      0.47      0.42        30
          B1       0.51      0.57      0.54        65
          B2       0.46      0.31      0.37        67
          C1       0.40      0.44      0.42        32
          C2       0.00      0.00      0.00         8

    accuracy                           0.42       205
   macro avg       0.29      0.30      0.29       205
weighted avg       0.43      0.42      0.42       205


K-fold scores
[0.4441864591321258, 0.42090056484089194, 0.46876950364188025, 0.4556714278922238, 0.4200612242633291]
SKF f1 score mean 0.4419178359540902

************for dimension:  Vocabularyrange  ***************
Printing class statistics
Counter({'B1': 349, 'B2': 271, 'A2': 213, 'C1': 138, 'A1': 50, 'C2': 5})
RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=300,
                       n_jobs=None, oob_score=False, random_state=1234,
                       verbose=0, warm_start=False)
Fold 0
[[ 0  5  5  0  0  0]
 [ 0 19 23  1  0  0]
 [ 0  5 58  7  0  0]
 [ 0  0 10 37  7  0]
 [ 0  0  1  6 21  0]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        10
          A2       0.66      0.44      0.53        43
          B1       0.60      0.83      0.69        70
          B2       0.73      0.69      0.70        54
          C1       0.72      0.75      0.74        28
          C2       0.00      0.00      0.00         1

    accuracy                           0.66       206
   macro avg       0.45      0.45      0.44       206
weighted avg       0.63      0.66      0.63       206


Fold 1
[[ 0  4  6  0  0  0]
 [ 0 14 26  2  0  0]
 [ 0 11 54  5  0  0]
 [ 0  0 11 28 15  0]
 [ 0  0  3  9 16  0]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        10
          A2       0.48      0.33      0.39        42
          B1       0.54      0.77      0.64        70
          B2       0.64      0.52      0.57        54
          C1       0.50      0.57      0.53        28
          C2       0.00      0.00      0.00         1

    accuracy                           0.55       205
   macro avg       0.36      0.37      0.36       205
weighted avg       0.52      0.55      0.52       205


Fold 2
[[ 0  3  7  0  0  0]
 [ 1 15 26  0  0  0]
 [ 0  6 56  8  0  0]
 [ 0  0 11 35  8  0]
 [ 0  0  2  9 17  0]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        10
          A2       0.62      0.36      0.45        42
          B1       0.55      0.80      0.65        70
          B2       0.67      0.65      0.66        54
          C1       0.65      0.61      0.63        28
          C2       0.00      0.00      0.00         1

    accuracy                           0.60       205
   macro avg       0.42      0.40      0.40       205
weighted avg       0.58      0.60      0.58       205


Fold 3
[[ 0  6  4  0  0  0]
 [ 0 20 22  1  0  0]
 [ 0  8 56  5  0  0]
 [ 0  1  6 36 12  0]
 [ 0  1  3  7 16  0]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        10
          A2       0.56      0.47      0.51        43
          B1       0.62      0.81      0.70        69
          B2       0.73      0.65      0.69        55
          C1       0.55      0.59      0.57        27
          C2       0.00      0.00      0.00         1

    accuracy                           0.62       205
   macro avg       0.41      0.42      0.41       205
weighted avg       0.59      0.62      0.60       205


Fold 4
[[ 0  1  9  0  0  0]
 [ 0 16 27  0  0  0]
 [ 0 12 53  5  0  0]
 [ 0  0  9 38  7  0]
 [ 0  0  0 11 16  0]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        10
          A2       0.55      0.37      0.44        43
          B1       0.54      0.76      0.63        70
          B2       0.70      0.70      0.70        54
          C1       0.67      0.59      0.63        27
          C2       0.00      0.00      0.00         1

    accuracy                           0.60       205
   macro avg       0.41      0.40      0.40       205
weighted avg       0.57      0.60      0.58       205


K-fold scores
[0.6310967026212315, 0.5210948522315144, 0.5754259094042269, 0.6028177873377009, 0.5766778256017854]
SKF f1 score mean 0.5814226154392917

LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
          verbose=0)
Fold 0
[[ 4  6  0  0  0  0]
 [ 1 26 16  0  0  0]
 [ 2 19 40  9  0  0]
 [ 0  1 10 33 10  0]
 [ 0  0  0 13 15  0]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.57      0.40      0.47        10
          A2       0.50      0.60      0.55        43
          B1       0.61      0.57      0.59        70
          B2       0.60      0.61      0.61        54
          C1       0.58      0.54      0.56        28
          C2       0.00      0.00      0.00         1

    accuracy                           0.57       206
   macro avg       0.48      0.45      0.46       206
weighted avg       0.57      0.57      0.57       206


Fold 1
[[ 2  5  3  0  0  0]
 [ 1 19 21  1  0  0]
 [ 1 14 50  4  1  0]
 [ 0  0  9 34 11  0]
 [ 0  1  1  9 17  0]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.50      0.20      0.29        10
          A2       0.49      0.45      0.47        42
          B1       0.60      0.71      0.65        70
          B2       0.71      0.63      0.67        54
          C1       0.57      0.61      0.59        28
          C2       0.00      0.00      0.00         1

    accuracy                           0.60       205
   macro avg       0.48      0.43      0.44       205
weighted avg       0.59      0.60      0.59       205


Fold 2
[[ 3  4  3  0  0  0]
 [ 8 15 19  0  0  0]
 [ 1 12 48  9  0  0]
 [ 1  0  8 33 12  0]
 [ 0  0  2 11 15  0]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.23      0.30      0.26        10
          A2       0.48      0.36      0.41        42
          B1       0.60      0.69      0.64        70
          B2       0.62      0.61      0.62        54
          C1       0.54      0.54      0.54        28
          C2       0.00      0.00      0.00         1

    accuracy                           0.56       205
   macro avg       0.41      0.41      0.41       205
weighted avg       0.55      0.56      0.55       205


Fold 3
[[ 2  4  4  0  0  0]
 [ 2 29 12  0  0  0]
 [ 0 15 47  7  0  0]
 [ 0  1 10 35  9  0]
 [ 0  0  0 11 16  0]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.50      0.20      0.29        10
          A2       0.59      0.67      0.63        43
          B1       0.64      0.68      0.66        69
          B2       0.66      0.64      0.65        55
          C1       0.62      0.59      0.60        27
          C2       0.00      0.00      0.00         1

    accuracy                           0.63       205
   macro avg       0.50      0.46      0.47       205
weighted avg       0.62      0.63      0.62       205


Fold 4
[[ 5  2  3  0  0  0]
 [ 6 23 12  1  1  0]
 [ 4  8 49  7  2  0]
 [ 0  2  7 35 10  0]
 [ 0  0  1 11 15  0]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.33      0.50      0.40        10
          A2       0.66      0.53      0.59        43
          B1       0.68      0.70      0.69        70
          B2       0.65      0.65      0.65        54
          C1       0.52      0.56      0.54        27
          C2       0.00      0.00      0.00         1

    accuracy                           0.62       205
   macro avg       0.47      0.49      0.48       205
weighted avg       0.63      0.62      0.62       205


K-fold scores
[0.5712232927593068, 0.587459439604099, 0.5511091748279509, 0.6223996575021752, 0.6201615572106812]
SKF f1 score mean 0.5904706243808426

LogisticRegression(C=1.0, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='multinomial', n_jobs=None,
                   penalty='l2', random_state=1234, solver='lbfgs', tol=0.0001,
                   verbose=0, warm_start=False)
Fold 0
[[ 5  5  0  0  0  0]
 [ 3 24 16  0  0  0]
 [ 2 18 43  7  0  0]
 [ 0  0  8 36  9  1]
 [ 0  0  0 10 18  0]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.50      0.50      0.50        10
          A2       0.51      0.56      0.53        43
          B1       0.64      0.61      0.63        70
          B2       0.68      0.67      0.67        54
          C1       0.64      0.64      0.64        28
          C2       0.00      0.00      0.00         1

    accuracy                           0.61       206
   macro avg       0.50      0.50      0.50       206
weighted avg       0.61      0.61      0.61       206


Fold 1
[[ 3  6  1  0  0  0]
 [ 5 20 16  1  0  0]
 [ 3 16 46  5  0  0]
 [ 0  0  6 34 14  0]
 [ 0  0  0  8 20  0]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.27      0.30      0.29        10
          A2       0.48      0.48      0.48        42
          B1       0.67      0.66      0.66        70
          B2       0.71      0.63      0.67        54
          C1       0.57      0.71      0.63        28
          C2       0.00      0.00      0.00         1

    accuracy                           0.60       205
   macro avg       0.45      0.46      0.45       205
weighted avg       0.60      0.60      0.60       205


Fold 2
[[ 3  4  3  0  0  0]
 [ 8 21 13  0  0  0]
 [ 3 12 49  6  0  0]
 [ 1  0  8 30 15  0]
 [ 0  0  1  8 19  0]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.20      0.30      0.24        10
          A2       0.57      0.50      0.53        42
          B1       0.66      0.70      0.68        70
          B2       0.68      0.56      0.61        54
          C1       0.54      0.68      0.60        28
          C2       0.00      0.00      0.00         1

    accuracy                           0.60       205
   macro avg       0.44      0.46      0.44       205
weighted avg       0.61      0.60      0.60       205


Fold 3
[[ 4  3  3  0  0  0]
 [ 3 28 11  1  0  0]
 [ 2 18 43  6  0  0]
 [ 0  1  8 33 12  1]
 [ 0  2  0 10 15  0]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.44      0.40      0.42        10
          A2       0.54      0.65      0.59        43
          B1       0.66      0.62      0.64        69
          B2       0.66      0.60      0.63        55
          C1       0.54      0.56      0.55        27
          C2       0.00      0.00      0.00         1

    accuracy                           0.60       205
   macro avg       0.47      0.47      0.47       205
weighted avg       0.60      0.60      0.60       205


Fold 4
[[ 7  1  2  0  0  0]
 [ 8 28  7  0  0  0]
 [ 3 13 45  9  0  0]
 [ 0  0  6 41  7  0]
 [ 0  0  0 10 17  0]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.39      0.70      0.50        10
          A2       0.67      0.65      0.66        43
          B1       0.75      0.64      0.69        70
          B2       0.68      0.76      0.72        54
          C1       0.68      0.63      0.65        27
          C2       0.00      0.00      0.00         1

    accuracy                           0.67       205
   macro avg       0.53      0.56      0.54       205
weighted avg       0.68      0.67      0.67       205


K-fold scores
[0.6126766396644672, 0.5998334433498498, 0.5966737375201187, 0.6006837957321739, 0.6745702519182849]
SKF f1 score mean 0.6168875736369789

************for dimension:  Vocabularycontrol  ***************
Printing class statistics
Counter({'B1': 319, 'B2': 278, 'A2': 259, 'C1': 82, 'A1': 77, 'C2': 11})
RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=300,
                       n_jobs=None, oob_score=False, random_state=1234,
                       verbose=0, warm_start=False)
Fold 0
[[ 1 10  5  0  0  0]
 [ 0 32 19  0  0  0]
 [ 0 20 31 13  0  0]
 [ 0  1 10 43  1  0]
 [ 0  0  1 16  0  0]
 [ 0  0  1  2  0  0]]
              precision    recall  f1-score   support

          A1       1.00      0.06      0.12        16
          A2       0.51      0.63      0.56        51
          B1       0.46      0.48      0.47        64
          B2       0.58      0.78      0.67        55
          C1       0.00      0.00      0.00        17
          C2       0.00      0.00      0.00         3

    accuracy                           0.52       206
   macro avg       0.43      0.33      0.30       206
weighted avg       0.50      0.52      0.47       206


Fold 1
[[ 0  8  7  0  0  0]
 [ 0 32 17  3  0  0]
 [ 0 11 34 19  0  0]
 [ 0  3  7 44  1  0]
 [ 0  0  1 16  0  0]
 [ 0  0  0  2  0  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        15
          A2       0.59      0.62      0.60        52
          B1       0.52      0.53      0.52        64
          B2       0.52      0.80      0.63        55
          C1       0.00      0.00      0.00        17
          C2       0.00      0.00      0.00         2

    accuracy                           0.54       205
   macro avg       0.27      0.32      0.29       205
weighted avg       0.45      0.54      0.49       205


Fold 2
[[ 0  9  6  0  0  0]
 [ 1 33 17  1  0  0]
 [ 0 17 31 16  0  0]
 [ 0  3  9 44  0  0]
 [ 0  0  1 15  0  0]
 [ 0  0  0  2  0  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        15
          A2       0.53      0.63      0.58        52
          B1       0.48      0.48      0.48        64
          B2       0.56      0.79      0.66        56
          C1       0.00      0.00      0.00        16
          C2       0.00      0.00      0.00         2

    accuracy                           0.53       205
   macro avg       0.26      0.32      0.29       205
weighted avg       0.44      0.53      0.48       205


Fold 3
[[ 0  7  8  0  0  0]
 [ 1 29 22  0  0  0]
 [ 0 13 37 14  0  0]
 [ 0  2 12 42  0  0]
 [ 0  0  0 16  0  0]
 [ 0  0  0  2  0  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        15
          A2       0.57      0.56      0.56        52
          B1       0.47      0.58      0.52        64
          B2       0.57      0.75      0.65        56
          C1       0.00      0.00      0.00        16
          C2       0.00      0.00      0.00         2

    accuracy                           0.53       205
   macro avg       0.27      0.31      0.29       205
weighted avg       0.45      0.53      0.48       205


Fold 4
[[ 0 14  2  0  0  0]
 [ 1 37 14  0  0  0]
 [ 1 27 28  7  0  0]
 [ 0  0 17 38  1  0]
 [ 0  0  4 12  0  0]
 [ 0  0  0  2  0  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        16
          A2       0.47      0.71      0.57        52
          B1       0.43      0.44      0.44        63
          B2       0.64      0.68      0.66        56
          C1       0.00      0.00      0.00        16
          C2       0.00      0.00      0.00         2

    accuracy                           0.50       205
   macro avg       0.26      0.31      0.28       205
weighted avg       0.43      0.50      0.46       205


K-fold scores
[0.4731586159761622, 0.4863087481800464, 0.4774701588335601, 0.48090268244660855, 0.4593716861081655]
SKF f1 score mean 0.4754423783089085

LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
          verbose=0)
Fold 0
[[ 6  8  1  0  1  0]
 [ 5 28 16  2  0  0]
 [ 7 17 28  9  3  0]
 [ 0  2 10 34  8  1]
 [ 0  0  2  7  8  0]
 [ 0  0  2  1  0  0]]
              precision    recall  f1-score   support

          A1       0.33      0.38      0.35        16
          A2       0.51      0.55      0.53        51
          B1       0.47      0.44      0.46        64
          B2       0.64      0.62      0.63        55
          C1       0.40      0.47      0.43        17
          C2       0.00      0.00      0.00         3

    accuracy                           0.50       206
   macro avg       0.39      0.41      0.40       206
weighted avg       0.50      0.50      0.50       206


Fold 1
[[ 4  6  5  0  0  0]
 [ 3 30 17  2  0  0]
 [ 1 16 25 18  4  0]
 [ 0  2  5 29 19  0]
 [ 0  1  1  9  6  0]
 [ 0  0  0  2  0  0]]
              precision    recall  f1-score   support

          A1       0.50      0.27      0.35        15
          A2       0.55      0.58      0.56        52
          B1       0.47      0.39      0.43        64
          B2       0.48      0.53      0.50        55
          C1       0.21      0.35      0.26        17
          C2       0.00      0.00      0.00         2

    accuracy                           0.46       205
   macro avg       0.37      0.35      0.35       205
weighted avg       0.47      0.46      0.46       205


Fold 2
[[ 6  8  0  1  0  0]
 [ 9 29 12  2  0  0]
 [ 3 13 35 11  2  0]
 [ 0  2 16 31  7  0]
 [ 0  0  1 13  2  0]
 [ 0  0  0  2  0  0]]
              precision    recall  f1-score   support

          A1       0.33      0.40      0.36        15
          A2       0.56      0.56      0.56        52
          B1       0.55      0.55      0.55        64
          B2       0.52      0.55      0.53        56
          C1       0.18      0.12      0.15        16
          C2       0.00      0.00      0.00         2

    accuracy                           0.50       205
   macro avg       0.36      0.36      0.36       205
weighted avg       0.49      0.50      0.50       205


Fold 3
[[ 6  7  2  0  0  0]
 [ 6 28 17  1  0  0]
 [ 0 21 30 13  0  0]
 [ 0  1 11 34  9  1]
 [ 0  0  0 12  4  0]
 [ 0  0  0  1  1  0]]
              precision    recall  f1-score   support

          A1       0.50      0.40      0.44        15
          A2       0.49      0.54      0.51        52
          B1       0.50      0.47      0.48        64
          B2       0.56      0.61      0.58        56
          C1       0.29      0.25      0.27        16
          C2       0.00      0.00      0.00         2

    accuracy                           0.50       205
   macro avg       0.39      0.38      0.38       205
weighted avg       0.49      0.50      0.49       205


Fold 4
[[ 7  9  0  0  0  0]
 [ 9 27 14  1  1  0]
 [ 4 20 23 14  2  0]
 [ 0  1 17 25 11  2]
 [ 0  1  4  5  6  0]
 [ 0  0  0  1  1  0]]
              precision    recall  f1-score   support

          A1       0.35      0.44      0.39        16
          A2       0.47      0.52      0.49        52
          B1       0.40      0.37      0.38        63
          B2       0.54      0.45      0.49        56
          C1       0.29      0.38      0.32        16
          C2       0.00      0.00      0.00         2

    accuracy                           0.43       205
   macro avg       0.34      0.36      0.35       205
weighted avg       0.44      0.43      0.43       205


K-fold scores
[0.5034448903545597, 0.4580517570874455, 0.49637048930572897, 0.4934813665663462, 0.43092720855600736]
SKF f1 score mean 0.47645514237401754

LogisticRegression(C=1.0, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='multinomial', n_jobs=None,
                   penalty='l2', random_state=1234, solver='lbfgs', tol=0.0001,
                   verbose=0, warm_start=False)
Fold 0
[[ 7  8  1  0  0  0]
 [ 7 31 11  2  0  0]
 [ 7 15 32  8  2  0]
 [ 0  1  7 39  6  2]
 [ 0  0  0  9  8  0]
 [ 0  0  1  2  0  0]]
              precision    recall  f1-score   support

          A1       0.33      0.44      0.38        16
          A2       0.56      0.61      0.58        51
          B1       0.62      0.50      0.55        64
          B2       0.65      0.71      0.68        55
          C1       0.50      0.47      0.48        17
          C2       0.00      0.00      0.00         3

    accuracy                           0.57       206
   macro avg       0.44      0.45      0.45       206
weighted avg       0.57      0.57      0.57       206


Fold 1
[[ 3  7  5  0  0  0]
 [ 9 27 14  2  0  0]
 [ 1 14 30 13  5  1]
 [ 1  2  7 24 19  2]
 [ 0  0  1  9  7  0]
 [ 0  0  0  2  0  0]]
              precision    recall  f1-score   support

          A1       0.21      0.20      0.21        15
          A2       0.54      0.52      0.53        52
          B1       0.53      0.47      0.50        64
          B2       0.48      0.44      0.46        55
          C1       0.23      0.41      0.29        17
          C2       0.00      0.00      0.00         2

    accuracy                           0.44       205
   macro avg       0.33      0.34      0.33       205
weighted avg       0.46      0.44      0.45       205


Fold 2
[[ 7  8  0  0  0  0]
 [11 30  9  2  0  0]
 [ 1 17 30 13  2  1]
 [ 0  3  9 34 10  0]
 [ 0  0  1  8  6  1]
 [ 0  0  0  2  0  0]]
              precision    recall  f1-score   support

          A1       0.37      0.47      0.41        15
          A2       0.52      0.58      0.55        52
          B1       0.61      0.47      0.53        64
          B2       0.58      0.61      0.59        56
          C1       0.33      0.38      0.35        16
          C2       0.00      0.00      0.00         2

    accuracy                           0.52       205
   macro avg       0.40      0.42      0.41       205
weighted avg       0.53      0.52      0.52       205


Fold 3
[[11  4  0  0  0  0]
 [11 27 14  0  0  0]
 [ 0 17 32 15  0  0]
 [ 0  1 10 30 13  2]
 [ 0  0  0  9  7  0]
 [ 0  0  0  1  1  0]]
              precision    recall  f1-score   support

          A1       0.50      0.73      0.59        15
          A2       0.55      0.52      0.53        52
          B1       0.57      0.50      0.53        64
          B2       0.55      0.54      0.54        56
          C1       0.33      0.44      0.38        16
          C2       0.00      0.00      0.00         2

    accuracy                           0.52       205
   macro avg       0.42      0.45      0.43       205
weighted avg       0.53      0.52      0.52       205


Fold 4
[[10  6  0  0  0  0]
 [ 9 31 12  0  0  0]
 [ 4 29 20  7  2  1]
 [ 0  1 14 24 15  2]
 [ 0  1  1  4 10  0]
 [ 0  0  0  0  2  0]]
              precision    recall  f1-score   support

          A1       0.43      0.62      0.51        16
          A2       0.46      0.60      0.52        52
          B1       0.43      0.32      0.36        63
          B2       0.69      0.43      0.53        56
          C1       0.34      0.62      0.44        16
          C2       0.00      0.00      0.00         2

    accuracy                           0.46       205
   macro avg       0.39      0.43      0.39       205
weighted avg       0.49      0.46      0.46       205


K-fold scores
[0.5667056292689161, 0.4510711595455662, 0.5233293177493544, 0.5228222281687629, 0.4616119923436996]
SKF f1 score mean 0.5051080654152599

************for dimension:  CoherenceCohesion  ***************
Printing class statistics
Counter({'B1': 356, 'B2': 269, 'A2': 227, 'C1': 85, 'A1': 84, 'C2': 5})
RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=300,
                       n_jobs=None, oob_score=False, random_state=1234,
                       verbose=0, warm_start=False)
Fold 0
[[ 3  6  8  0  0  0]
 [ 0 14 32  0  0  0]
 [ 1  8 47 15  0  0]
 [ 0  2  9 43  0  0]
 [ 0  0  0 16  1  0]
 [ 0  0  0  1  0  0]]
              precision    recall  f1-score   support

          A1       0.75      0.18      0.29        17
          A2       0.47      0.30      0.37        46
          B1       0.49      0.66      0.56        71
          B2       0.57      0.80      0.67        54
          C1       1.00      0.06      0.11        17
          C2       0.00      0.00      0.00         1

    accuracy                           0.52       206
   macro avg       0.55      0.33      0.33       206
weighted avg       0.57      0.52      0.48       206


Fold 1
[[ 2  7  7  0  0  0]
 [ 1 19 26  0  0  0]
 [ 0  7 51 13  0  0]
 [ 0  0 11 43  0  0]
 [ 0  0  1 16  0  0]
 [ 0  0  0  1  0  0]]
              precision    recall  f1-score   support

          A1       0.67      0.12      0.21        16
          A2       0.58      0.41      0.48        46
          B1       0.53      0.72      0.61        71
          B2       0.59      0.80      0.68        54
          C1       0.00      0.00      0.00        17
          C2       0.00      0.00      0.00         1

    accuracy                           0.56       205
   macro avg       0.39      0.34      0.33       205
weighted avg       0.52      0.56      0.51       205


Fold 2
[[ 4  9  3  1  0  0]
 [ 2 15 28  0  0  0]
 [ 0 15 48  8  0  0]
 [ 0  1  8 45  0  0]
 [ 0  0  1 16  0  0]
 [ 0  0  0  1  0  0]]
              precision    recall  f1-score   support

          A1       0.67      0.24      0.35        17
          A2       0.38      0.33      0.35        45
          B1       0.55      0.68      0.60        71
          B2       0.63      0.83      0.72        54
          C1       0.00      0.00      0.00        17
          C2       0.00      0.00      0.00         1

    accuracy                           0.55       205
   macro avg       0.37      0.35      0.34       205
weighted avg       0.49      0.55      0.51       205


Fold 3
[[ 0  9  8  0  0  0]
 [ 0 18 26  1  0  0]
 [ 0 11 47 13  0  0]
 [ 0  1 14 38  1  0]
 [ 0  0  1 16  0  0]
 [ 0  0  0  1  0  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        17
          A2       0.46      0.40      0.43        45
          B1       0.49      0.66      0.56        71
          B2       0.55      0.70      0.62        54
          C1       0.00      0.00      0.00        17
          C2       0.00      0.00      0.00         1

    accuracy                           0.50       205
   macro avg       0.25      0.29      0.27       205
weighted avg       0.42      0.50      0.45       205


Fold 4
[[ 2  7  8  0  0  0]
 [ 0 27 18  0  0  0]
 [ 0 16 44 12  0  0]
 [ 0  0 12 41  0  0]
 [ 0  0  0 17  0  0]
 [ 0  0  0  1  0  0]]
              precision    recall  f1-score   support

          A1       1.00      0.12      0.21        17
          A2       0.54      0.60      0.57        45
          B1       0.54      0.61      0.57        72
          B2       0.58      0.77      0.66        53
          C1       0.00      0.00      0.00        17
          C2       0.00      0.00      0.00         1

    accuracy                           0.56       205
   macro avg       0.44      0.35      0.34       205
weighted avg       0.54      0.56      0.51       205


K-fold scores
[0.4837741360357855, 0.5142790337856034, 0.5050893704767767, 0.4517836087831137, 0.5138982389096265]
SKF f1 score mean 0.49376487759818116

LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
          verbose=0)
Fold 0
[[ 8  7  1  1  0  0]
 [10 18 17  1  0  0]
 [ 1 16 39 12  3  0]
 [ 0  3  9 36  6  0]
 [ 0  0  4  8  5  0]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.42      0.47      0.44        17
          A2       0.41      0.39      0.40        46
          B1       0.56      0.55      0.55        71
          B2       0.62      0.67      0.64        54
          C1       0.33      0.29      0.31        17
          C2       0.00      0.00      0.00         1

    accuracy                           0.51       206
   macro avg       0.39      0.40      0.39       206
weighted avg       0.51      0.51      0.51       206


Fold 1
[[ 9  5  2  0  0  0]
 [ 8 17 20  1  0  0]
 [ 2 11 44 13  1  0]
 [ 0  1  8 36  9  0]
 [ 0  0  0  9  8  0]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.47      0.56      0.51        16
          A2       0.50      0.37      0.42        46
          B1       0.59      0.62      0.61        71
          B2       0.61      0.67      0.64        54
          C1       0.42      0.47      0.44        17
          C2       0.00      0.00      0.00         1

    accuracy                           0.56       205
   macro avg       0.43      0.45      0.44       205
weighted avg       0.55      0.56      0.55       205


Fold 2
[[ 6  9  2  0  0  0]
 [12 22  9  2  0  0]
 [ 2 24 34 11  0  0]
 [ 0  1 11 39  3  0]
 [ 0  0  1  7  9  0]
 [ 0  0  0  1  0  0]]
              precision    recall  f1-score   support

          A1       0.30      0.35      0.32        17
          A2       0.39      0.49      0.44        45
          B1       0.60      0.48      0.53        71
          B2       0.65      0.72      0.68        54
          C1       0.75      0.53      0.62        17
          C2       0.00      0.00      0.00         1

    accuracy                           0.54       205
   macro avg       0.45      0.43      0.43       205
weighted avg       0.55      0.54      0.54       205


Fold 3
[[ 2 12  3  0  0  0]
 [ 6 18 19  2  0  0]
 [ 4 13 41 12  1  0]
 [ 0  1 14 31  8  0]
 [ 0  0  0 10  7  0]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.17      0.12      0.14        17
          A2       0.41      0.40      0.40        45
          B1       0.53      0.58      0.55        71
          B2       0.56      0.57      0.57        54
          C1       0.41      0.41      0.41        17
          C2       0.00      0.00      0.00         1

    accuracy                           0.48       205
   macro avg       0.35      0.35      0.35       205
weighted avg       0.47      0.48      0.48       205


Fold 4
[[ 7  6  2  2  0  0]
 [ 9 18 17  0  1  0]
 [ 5 17 38 12  0  0]
 [ 1  1 12 33  6  0]
 [ 0  1  1  7  8  0]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.32      0.41      0.36        17
          A2       0.42      0.40      0.41        45
          B1       0.54      0.53      0.54        72
          B2       0.61      0.62      0.62        53
          C1       0.50      0.47      0.48        17
          C2       0.00      0.00      0.00         1

    accuracy                           0.51       205
   macro avg       0.40      0.41      0.40       205
weighted avg       0.51      0.51      0.51       205


K-fold scores
[0.5109657136627288, 0.5503944478173585, 0.5382210559440819, 0.47610004363576197, 0.5072238014962518]
SKF f1 score mean 0.5165810125112366

LogisticRegression(C=1.0, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='multinomial', n_jobs=None,
                   penalty='l2', random_state=1234, solver='lbfgs', tol=0.0001,
                   verbose=0, warm_start=False)
Fold 0
[[ 9  6  2  0  0  0]
 [12 17 16  1  0  0]
 [ 1 18 41 10  1  0]
 [ 0  3 10 32  9  0]
 [ 0  0  0  9  7  1]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.41      0.53      0.46        17
          A2       0.39      0.37      0.38        46
          B1       0.59      0.58      0.59        71
          B2       0.62      0.59      0.60        54
          C1       0.39      0.41      0.40        17
          C2       0.00      0.00      0.00         1

    accuracy                           0.51       206
   macro avg       0.40      0.41      0.40       206
weighted avg       0.52      0.51      0.52       206


Fold 1
[[11  4  1  0  0  0]
 [ 9 19 17  1  0  0]
 [ 4 16 36 12  2  1]
 [ 0  1  5 37 11  0]
 [ 0  0  0  8  9  0]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.46      0.69      0.55        16
          A2       0.47      0.41      0.44        46
          B1       0.61      0.51      0.55        71
          B2       0.64      0.69      0.66        54
          C1       0.39      0.53      0.45        17
          C2       0.00      0.00      0.00         1

    accuracy                           0.55       205
   macro avg       0.43      0.47      0.44       205
weighted avg       0.55      0.55      0.55       205


Fold 2
[[ 9  5  3  0  0  0]
 [12 23 10  0  0  0]
 [ 2 27 31 11  0  0]
 [ 0  2  9 35  7  1]
 [ 0  0  1  5 11  0]
 [ 0  0  0  1  0  0]]
              precision    recall  f1-score   support

          A1       0.39      0.53      0.45        17
          A2       0.40      0.51      0.45        45
          B1       0.57      0.44      0.50        71
          B2       0.67      0.65      0.66        54
          C1       0.61      0.65      0.63        17
          C2       0.00      0.00      0.00         1

    accuracy                           0.53       205
   macro avg       0.44      0.46      0.45       205
weighted avg       0.55      0.53      0.53       205


Fold 3
[[ 5 10  2  0  0  0]
 [ 7 19 19  0  0  0]
 [ 4 13 41 12  1  0]
 [ 1  2 11 31  9  0]
 [ 0  0  0  9  8  0]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.29      0.29      0.29        17
          A2       0.43      0.42      0.43        45
          B1       0.56      0.58      0.57        71
          B2       0.60      0.57      0.58        54
          C1       0.42      0.47      0.44        17
          C2       0.00      0.00      0.00         1

    accuracy                           0.51       205
   macro avg       0.38      0.39      0.39       205
weighted avg       0.51      0.51      0.51       205


Fold 4
[[10  6  1  0  0  0]
 [11 24 10  0  0  0]
 [ 4 17 42  9  0  0]
 [ 1  0 12 27 13  0]
 [ 0  0  1  4 12  0]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.38      0.59      0.47        17
          A2       0.51      0.53      0.52        45
          B1       0.64      0.58      0.61        72
          B2       0.68      0.51      0.58        53
          C1       0.46      0.71      0.56        17
          C2       0.00      0.00      0.00         1

    accuracy                           0.56       205
   macro avg       0.44      0.49      0.46       205
weighted avg       0.58      0.56      0.56       205


K-fold scores
[0.515599123759959, 0.545254779253645, 0.534176630689091, 0.5062658532563701, 0.5632872693252847]
SKF f1 score mean 0.5329167312568699

************for dimension:  Sociolinguisticappropriateness  ***************
Printing class statistics
Counter({'B2': 346, 'B1': 299, 'A2': 258, 'C1': 69, 'A1': 54})
RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=300,
                       n_jobs=None, oob_score=False, random_state=1234,
                       verbose=0, warm_start=False)
Fold 0
[[ 0 10  0  1  0]
 [ 0 30 19  3  0]
 [ 0 14 27 18  0]
 [ 0  6  6 58  0]
 [ 0  0  0 14  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        11
          A2       0.50      0.58      0.54        52
          B1       0.52      0.46      0.49        59
          B2       0.62      0.83      0.71        70
          C1       0.00      0.00      0.00        14

    accuracy                           0.56       206
   macro avg       0.33      0.37      0.35       206
weighted avg       0.48      0.56      0.51       206


Fold 1
[[ 0  8  2  0  0]
 [ 1 36 14  1  0]
 [ 0 15 29 16  0]
 [ 0  1 14 54  0]
 [ 0  0  0 14  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        10
          A2       0.60      0.69      0.64        52
          B1       0.49      0.48      0.49        60
          B2       0.64      0.78      0.70        69
          C1       0.00      0.00      0.00        14

    accuracy                           0.58       205
   macro avg       0.35      0.39      0.37       205
weighted avg       0.51      0.58      0.54       205


Fold 2
[[ 0  9  2  0  0]
 [ 0 38 13  1  0]
 [ 0 18 22 20  0]
 [ 1  3 14 51  0]
 [ 0  0  1 12  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        11
          A2       0.56      0.73      0.63        52
          B1       0.42      0.37      0.39        60
          B2       0.61      0.74      0.67        69
          C1       0.00      0.00      0.00        13

    accuracy                           0.54       205
   macro avg       0.32      0.37      0.34       205
weighted avg       0.47      0.54      0.50       205


Fold 3
[[ 0  9  2  0  0]
 [ 0 32 14  5  0]
 [ 0 11 31 18  0]
 [ 0  7  6 56  0]
 [ 0  0  0 14  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        11
          A2       0.54      0.63      0.58        51
          B1       0.58      0.52      0.55        60
          B2       0.60      0.81      0.69        69
          C1       0.00      0.00      0.00        14

    accuracy                           0.58       205
   macro avg       0.35      0.39      0.36       205
weighted avg       0.51      0.58      0.54       205


Fold 4
[[ 0 10  1  0  0]
 [ 0 38 12  1  0]
 [ 0 14 27 19  0]
 [ 0  4 16 49  0]
 [ 0  0  1 13  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        11
          A2       0.58      0.75      0.65        51
          B1       0.47      0.45      0.46        60
          B2       0.60      0.71      0.65        69
          C1       0.00      0.00      0.00        14

    accuracy                           0.56       205
   macro avg       0.33      0.38      0.35       205
weighted avg       0.48      0.56      0.52       205


K-fold scores
[0.5149128188436737, 0.5417652648642606, 0.5000232288037166, 0.5380330973596676, 0.5151315598739279]
SKF f1 score mean 0.5219731939490492

LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
          verbose=0)
Fold 0
[[ 2  8  1  0  0]
 [ 3 26 20  3  0]
 [ 4 11 29 14  1]
 [ 1  2 14 40 13]
 [ 0  0  2  7  5]]
              precision    recall  f1-score   support

          A1       0.20      0.18      0.19        11
          A2       0.55      0.50      0.53        52
          B1       0.44      0.49      0.46        59
          B2       0.62      0.57      0.60        70
          C1       0.26      0.36      0.30        14

    accuracy                           0.50       206
   macro avg       0.42      0.42      0.42       206
weighted avg       0.51      0.50      0.50       206


Fold 1
[[ 3  6  1  0  0]
 [ 7 24 16  5  0]
 [ 3 18 21 17  1]
 [ 0  3 12 45  9]
 [ 0  0  1 10  3]]
              precision    recall  f1-score   support

          A1       0.23      0.30      0.26        10
          A2       0.47      0.46      0.47        52
          B1       0.41      0.35      0.38        60
          B2       0.58      0.65      0.62        69
          C1       0.23      0.21      0.22        14

    accuracy                           0.47       205
   macro avg       0.39      0.40      0.39       205
weighted avg       0.46      0.47      0.46       205


Fold 2
[[ 3  6  2  0  0]
 [ 4 35  8  4  1]
 [ 2 19 19 16  4]
 [ 0  2 21 38  8]
 [ 0  0  2  7  4]]
              precision    recall  f1-score   support

          A1       0.33      0.27      0.30        11
          A2       0.56      0.67      0.61        52
          B1       0.37      0.32      0.34        60
          B2       0.58      0.55      0.57        69
          C1       0.24      0.31      0.27        13

    accuracy                           0.48       205
   macro avg       0.42      0.42      0.42       205
weighted avg       0.48      0.48      0.48       205


Fold 3
[[ 3  6  1  1  0]
 [ 5 28 15  3  0]
 [ 2  8 34 16  0]
 [ 0  3 19 41  6]
 [ 0  1  1 10  2]]
              precision    recall  f1-score   support

          A1       0.30      0.27      0.29        11
          A2       0.61      0.55      0.58        51
          B1       0.49      0.57      0.52        60
          B2       0.58      0.59      0.59        69
          C1       0.25      0.14      0.18        14

    accuracy                           0.53       205
   macro avg       0.44      0.43      0.43       205
weighted avg       0.52      0.53      0.52       205


Fold 4
[[ 3  6  2  0  0]
 [ 3 29 16  3  0]
 [ 2 15 25 17  1]
 [ 2  2 17 39  9]
 [ 0  0  0  9  5]]
              precision    recall  f1-score   support

          A1       0.30      0.27      0.29        11
          A2       0.56      0.57      0.56        51
          B1       0.42      0.42      0.42        60
          B2       0.57      0.57      0.57        69
          C1       0.33      0.36      0.34        14

    accuracy                           0.49       205
   macro avg       0.44      0.44      0.44       205
weighted avg       0.49      0.49      0.49       205


K-fold scores
[0.49911572051899544, 0.46434032073203935, 0.47896567045571703, 0.5216122524696827, 0.4925539584611812]
SKF f1 score mean 0.4913175845275231

LogisticRegression(C=1.0, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='multinomial', n_jobs=None,
                   penalty='l2', random_state=1234, solver='lbfgs', tol=0.0001,
                   verbose=0, warm_start=False)
Fold 0
[[ 2  9  0  0  0]
 [ 3 25 23  1  0]
 [ 5 11 25 16  2]
 [ 1  3 10 38 18]
 [ 0  0  2  6  6]]
              precision    recall  f1-score   support

          A1       0.18      0.18      0.18        11
          A2       0.52      0.48      0.50        52
          B1       0.42      0.42      0.42        59
          B2       0.62      0.54      0.58        70
          C1       0.23      0.43      0.30        14

    accuracy                           0.47       206
   macro avg       0.39      0.41      0.40       206
weighted avg       0.49      0.47      0.47       206


Fold 1
[[ 2  6  2  0  0]
 [ 9 31 10  2  0]
 [ 2 16 27 14  1]
 [ 0  2 11 42 14]
 [ 0  0  0  8  6]]
              precision    recall  f1-score   support

          A1       0.15      0.20      0.17        10
          A2       0.56      0.60      0.58        52
          B1       0.54      0.45      0.49        60
          B2       0.64      0.61      0.62        69
          C1       0.29      0.43      0.34        14

    accuracy                           0.53       205
   macro avg       0.44      0.46      0.44       205
weighted avg       0.54      0.53      0.53       205


Fold 2
[[ 6  4  1  0  0]
 [ 7 33 11  1  0]
 [ 3 14 23 15  5]
 [ 2  2 14 39 12]
 [ 0  0  1  6  6]]
              precision    recall  f1-score   support

          A1       0.33      0.55      0.41        11
          A2       0.62      0.63      0.63        52
          B1       0.46      0.38      0.42        60
          B2       0.64      0.57      0.60        69
          C1       0.26      0.46      0.33        13

    accuracy                           0.52       205
   macro avg       0.46      0.52      0.48       205
weighted avg       0.54      0.52      0.53       205


Fold 3
[[ 4  6  1  0  0]
 [ 8 29 13  1  0]
 [ 2 11 27 20  0]
 [ 0  4 14 41 10]
 [ 0  0  0 10  4]]
              precision    recall  f1-score   support

          A1       0.29      0.36      0.32        11
          A2       0.58      0.57      0.57        51
          B1       0.49      0.45      0.47        60
          B2       0.57      0.59      0.58        69
          C1       0.29      0.29      0.29        14

    accuracy                           0.51       205
   macro avg       0.44      0.45      0.45       205
weighted avg       0.51      0.51      0.51       205


Fold 4
[[ 5  6  0  0  0]
 [ 5 33 13  0  0]
 [ 0 17 27 13  3]
 [ 0  2 20 36 11]
 [ 0  0  0  8  6]]
              precision    recall  f1-score   support

          A1       0.50      0.45      0.48        11
          A2       0.57      0.65      0.61        51
          B1       0.45      0.45      0.45        60
          B2       0.63      0.52      0.57        69
          C1       0.30      0.43      0.35        14

    accuracy                           0.52       205
   macro avg       0.49      0.50      0.49       205
weighted avg       0.53      0.52      0.52       205


K-fold scores
[0.473789334899453, 0.5319895138739353, 0.5271301504775011, 0.5127253723454519, 0.5243345223522392]
SKF f1 score mean 0.5139937787897162

FOr lang:  IT
768
************for dimension:  OverallCEFRrating  ***************
Printing class statistics
Counter({'B1': 392, 'A2': 380, 'A1': 28})
RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=300,
                       n_jobs=None, oob_score=False, random_state=1234,
                       verbose=0, warm_start=False)
Fold 0
[[ 0  5  0]
 [ 0 67  9]
 [ 0 18 61]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         5
          A2       0.74      0.88      0.81        76
          B1       0.87      0.77      0.82        79

    accuracy                           0.80       160
   macro avg       0.54      0.55      0.54       160
weighted avg       0.78      0.80      0.79       160


Fold 1
[[ 0  5  0]
 [ 0 64 12]
 [ 0 16 63]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         5
          A2       0.75      0.84      0.80        76
          B1       0.84      0.80      0.82        79

    accuracy                           0.79       160
   macro avg       0.53      0.55      0.54       160
weighted avg       0.77      0.79      0.78       160


Fold 2
[[ 0  6  0]
 [ 0 67  9]
 [ 0 14 64]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         6
          A2       0.77      0.88      0.82        76
          B1       0.88      0.82      0.85        78

    accuracy                           0.82       160
   macro avg       0.55      0.57      0.56       160
weighted avg       0.79      0.82      0.80       160


Fold 3
[[ 0  6  0]
 [ 0 68  8]
 [ 0 16 62]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         6
          A2       0.76      0.89      0.82        76
          B1       0.89      0.79      0.84        78

    accuracy                           0.81       160
   macro avg       0.55      0.56      0.55       160
weighted avg       0.79      0.81      0.80       160


Fold 4
[[ 0  6  0]
 [ 0 67  9]
 [ 0 19 59]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         6
          A2       0.73      0.88      0.80        76
          B1       0.87      0.76      0.81        78

    accuracy                           0.79       160
   macro avg       0.53      0.55      0.54       160
weighted avg       0.77      0.79      0.77       160


K-fold scores
[0.787712258429692, 0.7816170242800677, 0.8037358306585951, 0.7976025724519701, 0.7728758969341161]
SKF f1 score mean 0.7887087165508883

LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
          verbose=0)
Fold 0
[[ 2  3  0]
 [ 3 64  9]
 [ 0 13 66]]
              precision    recall  f1-score   support

          A1       0.40      0.40      0.40         5
          A2       0.80      0.84      0.82        76
          B1       0.88      0.84      0.86        79

    accuracy                           0.82       160
   macro avg       0.69      0.69      0.69       160
weighted avg       0.83      0.82      0.83       160


Fold 1
[[ 2  2  1]
 [ 1 60 15]
 [ 0 13 66]]
              precision    recall  f1-score   support

          A1       0.67      0.40      0.50         5
          A2       0.80      0.79      0.79        76
          B1       0.80      0.84      0.82        79

    accuracy                           0.80       160
   macro avg       0.76      0.67      0.70       160
weighted avg       0.80      0.80      0.80       160


Fold 2
[[ 2  4  0]
 [ 0 63 13]
 [ 0 12 66]]
              precision    recall  f1-score   support

          A1       1.00      0.33      0.50         6
          A2       0.80      0.83      0.81        76
          B1       0.84      0.85      0.84        78

    accuracy                           0.82       160
   macro avg       0.88      0.67      0.72       160
weighted avg       0.82      0.82      0.81       160


Fold 3
[[ 1  5  0]
 [ 3 59 14]
 [ 1  9 68]]
              precision    recall  f1-score   support

          A1       0.20      0.17      0.18         6
          A2       0.81      0.78      0.79        76
          B1       0.83      0.87      0.85        78

    accuracy                           0.80       160
   macro avg       0.61      0.60      0.61       160
weighted avg       0.80      0.80      0.80       160


Fold 4
[[ 1  5  0]
 [ 4 59 13]
 [ 0 15 63]]
              precision    recall  f1-score   support

          A1       0.20      0.17      0.18         6
          A2       0.75      0.78      0.76        76
          B1       0.83      0.81      0.82        78

    accuracy                           0.77       160
   macro avg       0.59      0.58      0.59       160
weighted avg       0.77      0.77      0.77       160


K-fold scores
[0.8254578754578755, 0.7979221083048825, 0.8147516437230327, 0.7973676784624771, 0.7672947214076247]
SKF f1 score mean 0.8005588054711785

LogisticRegression(C=1.0, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='multinomial', n_jobs=None,
                   penalty='l2', random_state=1234, solver='lbfgs', tol=0.0001,
                   verbose=0, warm_start=False)
Fold 0
[[ 2  3  0]
 [ 5 63  8]
 [ 0 13 66]]
              precision    recall  f1-score   support

          A1       0.29      0.40      0.33         5
          A2       0.80      0.83      0.81        76
          B1       0.89      0.84      0.86        79

    accuracy                           0.82       160
   macro avg       0.66      0.69      0.67       160
weighted avg       0.83      0.82      0.82       160


Fold 1
[[ 3  1  1]
 [ 2 63 11]
 [ 0 13 66]]
              precision    recall  f1-score   support

          A1       0.60      0.60      0.60         5
          A2       0.82      0.83      0.82        76
          B1       0.85      0.84      0.84        79

    accuracy                           0.82       160
   macro avg       0.75      0.75      0.75       160
weighted avg       0.83      0.82      0.83       160


Fold 2
[[ 2  4  0]
 [ 2 65  9]
 [ 0 14 64]]
              precision    recall  f1-score   support

          A1       0.50      0.33      0.40         6
          A2       0.78      0.86      0.82        76
          B1       0.88      0.82      0.85        78

    accuracy                           0.82       160
   macro avg       0.72      0.67      0.69       160
weighted avg       0.82      0.82      0.82       160


Fold 3
[[ 2  4  0]
 [ 5 59 12]
 [ 1 10 67]]
              precision    recall  f1-score   support

          A1       0.25      0.33      0.29         6
          A2       0.81      0.78      0.79        76
          B1       0.85      0.86      0.85        78

    accuracy                           0.80       160
   macro avg       0.64      0.66      0.64       160
weighted avg       0.81      0.80      0.80       160


Fold 4
[[ 2  4  0]
 [ 4 64  8]
 [ 0 16 62]]
              precision    recall  f1-score   support

          A1       0.33      0.33      0.33         6
          A2       0.76      0.84      0.80        76
          B1       0.89      0.79      0.84        78

    accuracy                           0.80       160
   macro avg       0.66      0.66      0.66       160
weighted avg       0.81      0.80      0.80       160


K-fold scores
[0.822526091081594, 0.8250538591232672, 0.8166098129867965, 0.8029715849063518, 0.800945945945946]
SKF f1 score mean 0.813621458808791

************for dimension:  Grammaticalaccuracy  ***************
Printing class statistics
Counter({'B1': 376, 'A2': 242, 'B2': 111, 'A1': 71})
RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=300,
                       n_jobs=None, oob_score=False, random_state=1234,
                       verbose=0, warm_start=False)
Fold 0
[[ 0  9  5  0]
 [ 0 24 24  0]
 [ 0 10 65  1]
 [ 0  0 20  2]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        14
          A2       0.56      0.50      0.53        48
          B1       0.57      0.86      0.68        76
          B2       0.67      0.09      0.16        22

    accuracy                           0.57       160
   macro avg       0.45      0.36      0.34       160
weighted avg       0.53      0.57      0.51       160


Fold 1
[[ 0 13  1  0]
 [ 0 24 24  0]
 [ 0 14 61  0]
 [ 0  2 20  1]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        14
          A2       0.45      0.50      0.48        48
          B1       0.58      0.81      0.67        75
          B2       1.00      0.04      0.08        23

    accuracy                           0.54       160
   macro avg       0.51      0.34      0.31       160
weighted avg       0.55      0.54      0.47       160


Fold 2
[[ 0 12  2  0]
 [ 2 22 25  0]
 [ 0 12 62  1]
 [ 0  1 20  1]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        14
          A2       0.47      0.45      0.46        49
          B1       0.57      0.83      0.67        75
          B2       0.50      0.05      0.08        22

    accuracy                           0.53       160
   macro avg       0.38      0.33      0.30       160
weighted avg       0.48      0.53      0.47       160


Fold 3
[[ 0 10  4  0]
 [ 0 23 26  0]
 [ 0 11 64  0]
 [ 0  2 20  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        14
          A2       0.50      0.47      0.48        49
          B1       0.56      0.85      0.68        75
          B2       0.00      0.00      0.00        22

    accuracy                           0.54       160
   macro avg       0.27      0.33      0.29       160
weighted avg       0.42      0.54      0.47       160


Fold 4
[[ 1 13  1  0]
 [ 0 25 23  0]
 [ 0 12 63  0]
 [ 0  0 20  2]]
              precision    recall  f1-score   support

          A1       1.00      0.07      0.12        15
          A2       0.50      0.52      0.51        48
          B1       0.59      0.84      0.69        75
          B2       1.00      0.09      0.17        22

    accuracy                           0.57       160
   macro avg       0.77      0.38      0.37       160
weighted avg       0.66      0.57      0.51       160


K-fold scores
[0.5052417582417582, 0.47050646276644237, 0.4677196557971014, 0.46574979114452797, 0.5122158719256934]
SKF f1 score mean 0.48428670797510465

LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
          verbose=0)
Fold 0
[[ 2  9  3  0]
 [10 22 14  2]
 [ 2 12 43 19]
 [ 1  1 13  7]]
              precision    recall  f1-score   support

          A1       0.13      0.14      0.14        14
          A2       0.50      0.46      0.48        48
          B1       0.59      0.57      0.58        76
          B2       0.25      0.32      0.28        22

    accuracy                           0.46       160
   macro avg       0.37      0.37      0.37       160
weighted avg       0.48      0.46      0.47       160


Fold 1
[[ 5  8  1  0]
 [ 7 22 16  3]
 [ 3 16 43 13]
 [ 0  3 14  6]]
              precision    recall  f1-score   support

          A1       0.33      0.36      0.34        14
          A2       0.45      0.46      0.45        48
          B1       0.58      0.57      0.58        75
          B2       0.27      0.26      0.27        23

    accuracy                           0.48       160
   macro avg       0.41      0.41      0.41       160
weighted avg       0.48      0.47      0.48       160


Fold 2
[[ 5  8  1  0]
 [ 8 21 16  4]
 [ 2 15 43 15]
 [ 0  1 13  8]]
              precision    recall  f1-score   support

          A1       0.33      0.36      0.34        14
          A2       0.47      0.43      0.45        49
          B1       0.59      0.57      0.58        75
          B2       0.30      0.36      0.33        22

    accuracy                           0.48       160
   macro avg       0.42      0.43      0.42       160
weighted avg       0.49      0.48      0.48       160


Fold 3
[[ 2  8  4  0]
 [ 3 30 14  2]
 [ 3 18 41 13]
 [ 1  1 13  7]]
              precision    recall  f1-score   support

          A1       0.22      0.14      0.17        14
          A2       0.53      0.61      0.57        49
          B1       0.57      0.55      0.56        75
          B2       0.32      0.32      0.32        22

    accuracy                           0.50       160
   macro avg       0.41      0.40      0.40       160
weighted avg       0.49      0.50      0.49       160


Fold 4
[[ 3 11  1  0]
 [ 9 26 11  2]
 [ 6 18 42  9]
 [ 0  0 13  9]]
              precision    recall  f1-score   support

          A1       0.17      0.20      0.18        15
          A2       0.47      0.54      0.50        48
          B1       0.63      0.56      0.59        75
          B2       0.45      0.41      0.43        22

    accuracy                           0.50       160
   macro avg       0.43      0.43      0.43       160
weighted avg       0.51      0.50      0.50       160


K-fold scores
[0.46820830021230997, 0.47514191262840855, 0.4842872361165124, 0.4937960397448561, 0.5047190690480039]
SKF f1 score mean 0.48523051155001823

LogisticRegression(C=1.0, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='multinomial', n_jobs=None,
                   penalty='l2', random_state=1234, solver='lbfgs', tol=0.0001,
                   verbose=0, warm_start=False)
Fold 0
[[ 3 10  1  0]
 [13 23 12  0]
 [ 3 16 36 21]
 [ 1  1  9 11]]
              precision    recall  f1-score   support

          A1       0.15      0.21      0.18        14
          A2       0.46      0.48      0.47        48
          B1       0.62      0.47      0.54        76
          B2       0.34      0.50      0.41        22

    accuracy                           0.46       160
   macro avg       0.39      0.42      0.40       160
weighted avg       0.49      0.46      0.47       160


Fold 1
[[ 7  6  1  0]
 [13 20 13  2]
 [ 2 21 35 17]
 [ 0  3 13  7]]
              precision    recall  f1-score   support

          A1       0.32      0.50      0.39        14
          A2       0.40      0.42      0.41        48
          B1       0.56      0.47      0.51        75
          B2       0.27      0.30      0.29        23

    accuracy                           0.43       160
   macro avg       0.39      0.42      0.40       160
weighted avg       0.45      0.43      0.44       160


Fold 2
[[ 7  6  1  0]
 [13 25  8  3]
 [ 4 16 37 18]
 [ 0  1  9 12]]
              precision    recall  f1-score   support

          A1       0.29      0.50      0.37        14
          A2       0.52      0.51      0.52        49
          B1       0.67      0.49      0.57        75
          B2       0.36      0.55      0.44        22

    accuracy                           0.51       160
   macro avg       0.46      0.51      0.47       160
weighted avg       0.55      0.51      0.52       160


Fold 3
[[ 4  9  1  0]
 [ 9 30 10  0]
 [ 4 20 37 14]
 [ 1  1  8 12]]
              precision    recall  f1-score   support

          A1       0.22      0.29      0.25        14
          A2       0.50      0.61      0.55        49
          B1       0.66      0.49      0.56        75
          B2       0.46      0.55      0.50        22

    accuracy                           0.52       160
   macro avg       0.46      0.48      0.47       160
weighted avg       0.55      0.52      0.52       160


Fold 4
[[ 5  9  1  0]
 [ 9 26 11  2]
 [ 8 15 39 13]
 [ 0  0 12 10]]
              precision    recall  f1-score   support

          A1       0.23      0.33      0.27        15
          A2       0.52      0.54      0.53        48
          B1       0.62      0.52      0.57        75
          B2       0.40      0.45      0.43        22

    accuracy                           0.50       160
   macro avg       0.44      0.46      0.45       160
weighted avg       0.52      0.50      0.51       160


K-fold scores
[0.46749990211673387, 0.43705548521111615, 0.5169245899244543, 0.523993057987254, 0.507977801779011]
SKF f1 score mean 0.49069016740371385

************for dimension:  Orthography  ***************
Printing class statistics
Counter({'C1': 262, 'B1': 220, 'A2': 143, 'B2': 77, 'C2': 76, 'A1': 22})
RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=300,
                       n_jobs=None, oob_score=False, random_state=1234,
                       verbose=0, warm_start=False)
Fold 0
[[ 0  3  1  0  0  0]
 [ 0  9 18  0  2  0]
 [ 1  4 37  0  2  0]
 [ 0  0  5  0 10  0]
 [ 0  1  6  0 46  0]
 [ 0  0  7  0  8  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         4
          A2       0.53      0.31      0.39        29
          B1       0.50      0.84      0.63        44
          B2       0.00      0.00      0.00        15
          C1       0.68      0.87      0.76        53
          C2       0.00      0.00      0.00        15

    accuracy                           0.57       160
   macro avg       0.28      0.34      0.30       160
weighted avg       0.46      0.57      0.50       160


Fold 1
[[ 0  2  2  0  0  0]
 [ 0  6 18  0  4  0]
 [ 0  5 36  0  3  0]
 [ 0  1  4  0 11  0]
 [ 0  1  7  0 45  0]
 [ 0  0  3  0 12  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         4
          A2       0.40      0.21      0.28        28
          B1       0.51      0.82      0.63        44
          B2       0.00      0.00      0.00        16
          C1       0.60      0.85      0.70        53
          C2       0.00      0.00      0.00        15

    accuracy                           0.54       160
   macro avg       0.25      0.31      0.27       160
weighted avg       0.41      0.54      0.46       160


Fold 2
[[ 0  0  4  0  0  0]
 [ 0  7 18  0  3  0]
 [ 0  6 31  0  7  0]
 [ 0  0  3  0 13  0]
 [ 0  1  4  0 47  0]
 [ 0  0  5  0 11  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         4
          A2       0.50      0.25      0.33        28
          B1       0.48      0.70      0.57        44
          B2       0.00      0.00      0.00        16
          C1       0.58      0.90      0.71        52
          C2       0.00      0.00      0.00        16

    accuracy                           0.53       160
   macro avg       0.26      0.31      0.27       160
weighted avg       0.41      0.53      0.44       160


Fold 3
[[ 0  1  3  0  1  0]
 [ 0  6 20  0  3  0]
 [ 0  7 32  0  5  0]
 [ 0  0  4  0 11  0]
 [ 0  1  8  0 43  0]
 [ 0  0  3  0 12  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         5
          A2       0.40      0.21      0.27        29
          B1       0.46      0.73      0.56        44
          B2       0.00      0.00      0.00        15
          C1       0.57      0.83      0.68        52
          C2       0.00      0.00      0.00        15

    accuracy                           0.51       160
   macro avg       0.24      0.29      0.25       160
weighted avg       0.38      0.51      0.42       160


Fold 4
[[ 0  2  2  0  1  0]
 [ 0  5 22  0  2  0]
 [ 0  4 34  0  6  0]
 [ 0  2  2  0 11  0]
 [ 0  0  6  0 46  0]
 [ 0  1  2  0 12  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         5
          A2       0.36      0.17      0.23        29
          B1       0.50      0.77      0.61        44
          B2       0.00      0.00      0.00        15
          C1       0.59      0.88      0.71        52
          C2       0.00      0.00      0.00        15

    accuracy                           0.53       160
   macro avg       0.24      0.30      0.26       160
weighted avg       0.39      0.53      0.44       160


K-fold scores
[0.4952410442943537, 0.45543157607864126, 0.444454599802258, 0.42389652325157917, 0.43911544850498335]
SKF f1 score mean 0.4516278383863631

LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
          verbose=0)
Fold 0
[[ 1  2  1  0  0  0]
 [ 3 13  9  1  2  1]
 [ 0 14 27  2  1  0]
 [ 0  0  2  2  7  4]
 [ 0  1  2  8 33  9]
 [ 0  1  4  1  5  4]]
              precision    recall  f1-score   support

          A1       0.25      0.25      0.25         4
          A2       0.42      0.45      0.43        29
          B1       0.60      0.61      0.61        44
          B2       0.14      0.13      0.14        15
          C1       0.69      0.62      0.65        53
          C2       0.22      0.27      0.24        15

    accuracy                           0.50       160
   macro avg       0.39      0.39      0.39       160
weighted avg       0.51      0.50      0.50       160


Fold 1
[[ 0  2  1  1  0  0]
 [ 2 13  9  1  1  2]
 [ 0 12 26  5  0  1]
 [ 0  2  2  1  8  3]
 [ 0  2  2 11 34  4]
 [ 0  1  1  4  8  1]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         4
          A2       0.41      0.46      0.43        28
          B1       0.63      0.59      0.61        44
          B2       0.04      0.06      0.05        16
          C1       0.67      0.64      0.65        53
          C2       0.09      0.07      0.08        15

    accuracy                           0.47       160
   macro avg       0.31      0.30      0.30       160
weighted avg       0.48      0.47      0.47       160


Fold 2
[[ 1  2  1  0  0  0]
 [ 2 16  8  0  1  1]
 [ 2 10 23  1  5  3]
 [ 0  2  2  1  9  2]
 [ 0  0  1  4 39  8]
 [ 0  0  2  1 11  2]]
              precision    recall  f1-score   support

          A1       0.20      0.25      0.22         4
          A2       0.53      0.57      0.55        28
          B1       0.62      0.52      0.57        44
          B2       0.14      0.06      0.09        16
          C1       0.60      0.75      0.67        52
          C2       0.12      0.12      0.12        16

    accuracy                           0.51       160
   macro avg       0.37      0.38      0.37       160
weighted avg       0.49      0.51      0.50       160


Fold 3
[[ 1  3  0  0  0  1]
 [ 1 13 12  1  1  1]
 [ 3 12 24  1  2  2]
 [ 0  1  3  1 10  0]
 [ 0  6  6  5 29  6]
 [ 0  1  3  2  7  2]]
              precision    recall  f1-score   support

          A1       0.20      0.20      0.20         5
          A2       0.36      0.45      0.40        29
          B1       0.50      0.55      0.52        44
          B2       0.10      0.07      0.08        15
          C1       0.59      0.56      0.57        52
          C2       0.17      0.13      0.15        15

    accuracy                           0.44       160
   macro avg       0.32      0.33      0.32       160
weighted avg       0.43      0.44      0.43       160


Fold 4
[[ 0  2  2  1  0  0]
 [ 2 11 15  1  0  0]
 [ 1 12 16  4  2  9]
 [ 0  2  3  0  8  2]
 [ 0  2  3  6 34  7]
 [ 0  0  3  3  5  4]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         5
          A2       0.38      0.38      0.38        29
          B1       0.38      0.36      0.37        44
          B2       0.00      0.00      0.00        15
          C1       0.69      0.65      0.67        52
          C2       0.18      0.27      0.22        15

    accuracy                           0.41       160
   macro avg       0.27      0.28      0.27       160
weighted avg       0.42      0.41      0.41       160


K-fold scores
[0.5037643025005716, 0.4729949095022625, 0.49614243804023894, 0.4302508131247908, 0.4101577328537379]
SKF f1 score mean 0.4626620392043203

LogisticRegression(C=1.0, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='multinomial', n_jobs=None,
                   penalty='l2', random_state=1234, solver='lbfgs', tol=0.0001,
                   verbose=0, warm_start=False)
Fold 0
[[ 2  1  1  0  0  0]
 [ 5 12 10  0  0  2]
 [ 1 16 22  1  2  2]
 [ 0  1  0  3  6  5]
 [ 0  3  2  9 30  9]
 [ 0  2  3  1  5  4]]
              precision    recall  f1-score   support

          A1       0.25      0.50      0.33         4
          A2       0.34      0.41      0.38        29
          B1       0.58      0.50      0.54        44
          B2       0.21      0.20      0.21        15
          C1       0.70      0.57      0.62        53
          C2       0.18      0.27      0.22        15

    accuracy                           0.46       160
   macro avg       0.38      0.41      0.38       160
weighted avg       0.50      0.46      0.47       160


Fold 1
[[ 0  3  1  0  0  0]
 [ 3 12 10  1  0  2]
 [ 1 16 22  4  0  1]
 [ 0  2  3  1  8  2]
 [ 0  0  3 12 29  9]
 [ 0  1  1  2  9  2]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         4
          A2       0.35      0.43      0.39        28
          B1       0.55      0.50      0.52        44
          B2       0.05      0.06      0.06        16
          C1       0.63      0.55      0.59        53
          C2       0.12      0.13      0.13        15

    accuracy                           0.41       160
   macro avg       0.28      0.28      0.28       160
weighted avg       0.44      0.41      0.42       160


Fold 2
[[ 2  2  0  0  0  0]
 [ 4 15  6  2  1  0]
 [ 6 10 23  2  2  1]
 [ 0  0  1  1  8  6]
 [ 0  1  1  6 30 14]
 [ 0  0  1  2  8  5]]
              precision    recall  f1-score   support

          A1       0.17      0.50      0.25         4
          A2       0.54      0.54      0.54        28
          B1       0.72      0.52      0.61        44
          B2       0.08      0.06      0.07        16
          C1       0.61      0.58      0.59        52
          C2       0.19      0.31      0.24        16

    accuracy                           0.48       160
   macro avg       0.38      0.42      0.38       160
weighted avg       0.52      0.47      0.49       160


Fold 3
[[ 1  3  0  0  0  1]
 [ 4 15  8  0  0  2]
 [ 5 10 22  3  2  2]
 [ 0  0  4  1 10  0]
 [ 0  3  4  4 27 14]
 [ 0  0  2  3  5  5]]
              precision    recall  f1-score   support

          A1       0.10      0.20      0.13         5
          A2       0.48      0.52      0.50        29
          B1       0.55      0.50      0.52        44
          B2       0.09      0.07      0.08        15
          C1       0.61      0.52      0.56        52
          C2       0.21      0.33      0.26        15

    accuracy                           0.44       160
   macro avg       0.34      0.36      0.34       160
weighted avg       0.47      0.44      0.45       160


Fold 4
[[ 0  2  3  0  0  0]
 [ 3 11 13  2  0  0]
 [ 0 17 16  5  0  6]
 [ 0  2  2  2  8  1]
 [ 0  1  4 10 31  6]
 [ 0  2  1  1  7  4]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         5
          A2       0.31      0.38      0.34        29
          B1       0.41      0.36      0.39        44
          B2       0.10      0.13      0.11        15
          C1       0.67      0.60      0.63        52
          C2       0.24      0.27      0.25        15

    accuracy                           0.40       160
   macro avg       0.29      0.29      0.29       160
weighted avg       0.42      0.40      0.41       160


K-fold scores
[0.47056113093749763, 0.4235075408462505, 0.49022275088540745, 0.45290178571428574, 0.40809281449778706]
SKF f1 score mean 0.44905720457624565

************for dimension:  Vocabularyrange  ***************
Printing class statistics
Counter({'B1': 328, 'A2': 243, 'B2': 188, 'A1': 39, 'C1': 2})
RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=300,
                       n_jobs=None, oob_score=False, random_state=1234,
                       verbose=0, warm_start=False)
Fold 0
[[ 0  6  2  0]
 [ 0 30 18  0]
 [ 0  8 52  6]
 [ 0  0 14 24]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         8
          A2       0.68      0.62      0.65        48
          B1       0.60      0.79      0.68        66
          B2       0.80      0.63      0.71        38

    accuracy                           0.66       160
   macro avg       0.52      0.51      0.51       160
weighted avg       0.64      0.66      0.65       160


Fold 1
[[ 0  5  3  0]
 [ 0 26 23  0]
 [ 0 11 45 10]
 [ 0  0 12 25]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         8
          A2       0.62      0.53      0.57        49
          B1       0.54      0.68      0.60        66
          B2       0.71      0.68      0.69        37

    accuracy                           0.60       160
   macro avg       0.47      0.47      0.47       160
weighted avg       0.58      0.60      0.58       160


Fold 2
[[ 0  4  4  0]
 [ 0 37 12  0]
 [ 0 15 45  6]
 [ 0  0  8 29]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         8
          A2       0.66      0.76      0.70        49
          B1       0.65      0.68      0.67        66
          B2       0.83      0.78      0.81        37

    accuracy                           0.69       160
   macro avg       0.54      0.56      0.54       160
weighted avg       0.66      0.69      0.68       160


Fold 3
[[ 0  5  2  0  0]
 [ 0 34 14  1  0]
 [ 0 11 45  9  0]
 [ 0  1 10 27  0]
 [ 0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         7
          A2       0.67      0.69      0.68        49
          B1       0.63      0.69      0.66        65
          B2       0.71      0.71      0.71        38
          C1       0.00      0.00      0.00         1

    accuracy                           0.66       160
   macro avg       0.40      0.42      0.41       160
weighted avg       0.63      0.66      0.65       160


Fold 4
[[ 0  7  1  0  0]
 [ 0 37 11  0  0]
 [ 0 18 42  5  0]
 [ 0  0 11 27  0]
 [ 0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         8
          A2       0.60      0.77      0.67        48
          B1       0.65      0.65      0.65        65
          B2       0.82      0.71      0.76        38
          C1       0.00      0.00      0.00         1

    accuracy                           0.66       160
   macro avg       0.41      0.43      0.42       160
weighted avg       0.64      0.66      0.64       160


K-fold scores
[0.6455360748418361, 0.5847513516032812, 0.6771180555555556, 0.645841911764706, 0.6449519846350833]
SKF f1 score mean 0.6396398756800924

LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
          verbose=0)
Fold 0
[[ 2  5  1  0]
 [ 4 35  9  0]
 [ 1 17 38 10]
 [ 0  0 13 25]]
              precision    recall  f1-score   support

          A1       0.29      0.25      0.27         8
          A2       0.61      0.73      0.67        48
          B1       0.62      0.58      0.60        66
          B2       0.71      0.66      0.68        38

    accuracy                           0.62       160
   macro avg       0.56      0.55      0.55       160
weighted avg       0.63      0.62      0.62       160


Fold 1
[[ 2  5  1  0]
 [ 3 31 15  0]
 [ 0 10 40 16]
 [ 0  2 14 21]]
              precision    recall  f1-score   support

          A1       0.40      0.25      0.31         8
          A2       0.65      0.63      0.64        49
          B1       0.57      0.61      0.59        66
          B2       0.57      0.57      0.57        37

    accuracy                           0.59       160
   macro avg       0.55      0.51      0.53       160
weighted avg       0.58      0.59      0.59       160


Fold 2
[[ 2  2  4  0]
 [ 2 36 10  1]
 [ 1 13 39 13]
 [ 0  1  6 30]]
              precision    recall  f1-score   support

          A1       0.40      0.25      0.31         8
          A2       0.69      0.73      0.71        49
          B1       0.66      0.59      0.62        66
          B2       0.68      0.81      0.74        37

    accuracy                           0.67       160
   macro avg       0.61      0.60      0.60       160
weighted avg       0.66      0.67      0.66       160


Fold 3
[[ 1  4  2  0  0]
 [ 1 35 11  2  0]
 [ 1 15 37 12  0]
 [ 0  1  9 28  0]
 [ 0  0  1  0  0]]
              precision    recall  f1-score   support

          A1       0.33      0.14      0.20         7
          A2       0.64      0.71      0.67        49
          B1       0.62      0.57      0.59        65
          B2       0.67      0.74      0.70        38
          C1       0.00      0.00      0.00         1

    accuracy                           0.63       160
   macro avg       0.45      0.43      0.43       160
weighted avg       0.62      0.63      0.62       160


Fold 4
[[ 1  7  0  0  0]
 [10 25 12  1  0]
 [ 2 16 40  7  0]
 [ 0  0  8 30  0]
 [ 0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.08      0.12      0.10         8
          A2       0.52      0.52      0.52        48
          B1       0.67      0.62      0.64        65
          B2       0.77      0.79      0.78        38
          C1       0.00      0.00      0.00         1

    accuracy                           0.60       160
   macro avg       0.41      0.41      0.41       160
weighted avg       0.61      0.60      0.61       160


K-fold scores
[0.6228549599108331, 0.5850290968885572, 0.66239774336408, 0.6216298076923076, 0.6060768398268399]
SKF f1 score mean 0.6195976895365235

LogisticRegression(C=1.0, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='multinomial', n_jobs=None,
                   penalty='l2', random_state=1234, solver='lbfgs', tol=0.0001,
                   verbose=0, warm_start=False)
Fold 0
[[ 3  3  2  0]
 [ 4 37  7  0]
 [ 2 15 38 11]
 [ 0  0  8 30]]
              precision    recall  f1-score   support

          A1       0.33      0.38      0.35         8
          A2       0.67      0.77      0.72        48
          B1       0.69      0.58      0.63        66
          B2       0.73      0.79      0.76        38

    accuracy                           0.68       160
   macro avg       0.61      0.63      0.61       160
weighted avg       0.68      0.68      0.67       160


Fold 1
[[ 2  6  0  0]
 [ 4 30 15  0]
 [ 3  9 41 13]
 [ 0  1  9 27]]
              precision    recall  f1-score   support

          A1       0.22      0.25      0.24         8
          A2       0.65      0.61      0.63        49
          B1       0.63      0.62      0.63        66
          B2       0.68      0.73      0.70        37

    accuracy                           0.62       160
   macro avg       0.55      0.55      0.55       160
weighted avg       0.63      0.62      0.63       160


Fold 2
[[ 5  1  2  0]
 [ 6 36  7  0]
 [ 2 15 33 16]
 [ 0  0  3 33]]
              precision    recall  f1-score   support

          A1       0.38      0.62      0.48         8
          A2       0.69      0.73      0.71        49
          B1       0.73      0.50      0.59        66
          B2       0.67      0.89      0.77        37
          C1       0.00      0.00      0.00         0

    accuracy                           0.67       160
   macro avg       0.50      0.55      0.51       160
weighted avg       0.69      0.67      0.66       160


Fold 3
[[ 1  4  2  0  0]
 [ 4 36  7  2  0]
 [ 2 15 37 11  0]
 [ 0  1  6 31  0]
 [ 0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.14      0.14      0.14         7
          A2       0.64      0.73      0.69        49
          B1       0.71      0.57      0.63        65
          B2       0.69      0.82      0.75        38
          C1       0.00      0.00      0.00         1

    accuracy                           0.66       160
   macro avg       0.44      0.45      0.44       160
weighted avg       0.66      0.66      0.65       160


Fold 4
[[ 1  7  0  0  0]
 [14 25  9  0  0]
 [ 3 16 37  9  0]
 [ 0  0  6 32  0]
 [ 0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.06      0.12      0.08         8
          A2       0.52      0.52      0.52        48
          B1       0.71      0.57      0.63        65
          B2       0.76      0.84      0.80        38
          C1       0.00      0.00      0.00         1

    accuracy                           0.59       160
   macro avg       0.41      0.41      0.41       160
weighted avg       0.63      0.59      0.61       160


K-fold scores
[0.6726516953324058, 0.6255671900594857, 0.6648675559955205, 0.6506040829986613, 0.6070405982905983]
SKF f1 score mean 0.6441462245353343

************for dimension:  Vocabularycontrol  ***************
Printing class statistics
Counter({'B1': 327, 'A2': 204, 'B2': 196, 'A1': 70, 'C1': 3})
RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=300,
                       n_jobs=None, oob_score=False, random_state=1234,
                       verbose=0, warm_start=False)
Fold 0
[[ 1  6  7  0]
 [ 0 20 21  0]
 [ 1  7 50  8]
 [ 0  0 19 20]]
              precision    recall  f1-score   support

          A1       0.50      0.07      0.12        14
          A2       0.61      0.49      0.54        41
          B1       0.52      0.76      0.61        66
          B2       0.71      0.51      0.60        39

    accuracy                           0.57       160
   macro avg       0.58      0.46      0.47       160
weighted avg       0.59      0.57      0.55       160


Fold 1
[[ 2  9  3  0]
 [ 1 20 20  0]
 [ 0  7 48 11]
 [ 0  0 20 19]]
              precision    recall  f1-score   support

          A1       0.67      0.14      0.24        14
          A2       0.56      0.49      0.52        41
          B1       0.53      0.73      0.61        66
          B2       0.63      0.49      0.55        39

    accuracy                           0.56       160
   macro avg       0.60      0.46      0.48       160
weighted avg       0.57      0.56      0.54       160


Fold 2
[[ 0  8  6  0  0]
 [ 0 19 21  0  0]
 [ 0 12 43 10  0]
 [ 0  0 21 19  0]
 [ 0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        14
          A2       0.49      0.47      0.48        40
          B1       0.47      0.66      0.55        65
          B2       0.63      0.47      0.54        40
          C1       0.00      0.00      0.00         1

    accuracy                           0.51       160
   macro avg       0.32      0.32      0.32       160
weighted avg       0.47      0.51      0.48       160


Fold 3
[[ 1  3 10  0  0]
 [ 0 19 21  1  0]
 [ 1 10 41 13  0]
 [ 0  0 15 24  0]
 [ 0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.50      0.07      0.12        14
          A2       0.59      0.46      0.52        41
          B1       0.47      0.63      0.54        65
          B2       0.62      0.62      0.62        39
          C1       0.00      0.00      0.00         1

    accuracy                           0.53       160
   macro avg       0.44      0.36      0.36       160
weighted avg       0.54      0.53      0.51       160


Fold 4
[[ 1  6  7  0  0]
 [ 1 21 19  0  0]
 [ 1 14 41  9  0]
 [ 0  0 16 23  0]
 [ 0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.33      0.07      0.12        14
          A2       0.51      0.51      0.51        41
          B1       0.49      0.63      0.55        65
          B2       0.70      0.59      0.64        39
          C1       0.00      0.00      0.00         1

    accuracy                           0.54       160
   macro avg       0.41      0.36      0.36       160
weighted avg       0.53      0.54      0.52       160


K-fold scores
[0.5480408862357916, 0.5401735482088407, 0.47992578360458105, 0.5134890951694304, 0.522357743773185]
SKF f1 score mean 0.5207974113983658

LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
          verbose=0)
Fold 0
[[ 3  7  4  0]
 [10 25  6  0]
 [ 2 16 28 20]
 [ 0  1 15 23]]
              precision    recall  f1-score   support

          A1       0.20      0.21      0.21        14
          A2       0.51      0.61      0.56        41
          B1       0.53      0.42      0.47        66
          B2       0.53      0.59      0.56        39

    accuracy                           0.49       160
   macro avg       0.44      0.46      0.45       160
weighted avg       0.50      0.49      0.49       160


Fold 1
[[ 5  7  2  0]
 [ 6 21 13  1]
 [ 4 12 30 20]
 [ 1  1 17 19]]
              precision    recall  f1-score   support

          A1       0.31      0.36      0.33        14
          A2       0.51      0.51      0.51        41
          B1       0.48      0.45      0.47        66
          B2       0.47      0.49      0.48        39
          C1       0.00      0.00      0.00         0

    accuracy                           0.47       160
   macro avg       0.36      0.36      0.36       160
weighted avg       0.47      0.47      0.47       160


Fold 2
[[ 3  8  3  0  0]
 [ 6 21 10  3  0]
 [ 5 16 27 17  0]
 [ 0  3 11 26  0]
 [ 0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.21      0.21      0.21        14
          A2       0.44      0.53      0.48        40
          B1       0.53      0.42      0.47        65
          B2       0.55      0.65      0.60        40
          C1       0.00      0.00      0.00         1

    accuracy                           0.48       160
   macro avg       0.35      0.36      0.35       160
weighted avg       0.48      0.48      0.48       160


Fold 3
[[ 6  3  3  2  0]
 [ 5 27  9  0  0]
 [ 3 13 34 15  0]
 [ 0  0 12 27  0]
 [ 0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.43      0.43      0.43        14
          A2       0.63      0.66      0.64        41
          B1       0.59      0.52      0.55        65
          B2       0.60      0.69      0.64        39
          C1       0.00      0.00      0.00         1

    accuracy                           0.59       160
   macro avg       0.45      0.46      0.45       160
weighted avg       0.58      0.59      0.58       160


Fold 4
[[ 3  6  4  1  0]
 [ 4 24 12  1  0]
 [ 4 15 35 11  0]
 [ 0  0 14 25  0]
 [ 0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.27      0.21      0.24        14
          A2       0.53      0.59      0.56        41
          B1       0.54      0.54      0.54        65
          B2       0.64      0.64      0.64        39
          C1       0.00      0.00      0.00         1

    accuracy                           0.54       160
   macro avg       0.40      0.40      0.40       160
weighted avg       0.54      0.54      0.54       160


K-fold scores
[0.4913200113238455, 0.4710228771097046, 0.47660984848484855, 0.5835220673635308, 0.5390232558139535]
SKF f1 score mean 0.5122996120191766

LogisticRegression(C=1.0, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='multinomial', n_jobs=None,
                   penalty='l2', random_state=1234, solver='lbfgs', tol=0.0001,
                   verbose=0, warm_start=False)
Fold 0
[[ 7  6  1  0]
 [11 25  4  1]
 [ 5 20 22 19]
 [ 0  2  9 28]]
              precision    recall  f1-score   support

          A1       0.30      0.50      0.38        14
          A2       0.47      0.61      0.53        41
          B1       0.61      0.33      0.43        66
          B2       0.58      0.72      0.64        39

    accuracy                           0.51       160
   macro avg       0.49      0.54      0.50       160
weighted avg       0.54      0.51      0.50       160


Fold 1
[[ 9  4  1  0]
 [11 22  8  0]
 [ 6 12 26 22]
 [ 0  0 11 27]]
              precision    recall  f1-score   support

          A1       0.35      0.64      0.45        14
          A2       0.58      0.54      0.56        41
          B1       0.57      0.39      0.46        66
          B2       0.55      0.69      0.61        39
          C1       0.00      0.00      0.00         0

    accuracy                           0.53       160
   macro avg       0.41      0.45      0.42       160
weighted avg       0.55      0.53      0.52       160


Fold 2
[[ 5  8  1  0  0]
 [ 8 23  8  1  0]
 [ 6 18 25 16  0]
 [ 0  1 10 29  0]
 [ 0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.26      0.36      0.30        14
          A2       0.46      0.57      0.51        40
          B1       0.57      0.38      0.46        65
          B2       0.62      0.72      0.67        40
          C1       0.00      0.00      0.00         1

    accuracy                           0.51       160
   macro avg       0.38      0.41      0.39       160
weighted avg       0.52      0.51      0.51       160


Fold 3
[[ 6  4  4  0  0]
 [ 6 30  5  0  0]
 [ 4 12 30 19  0]
 [ 0  0  5 34  0]
 [ 0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.38      0.43      0.40        14
          A2       0.65      0.73      0.69        41
          B1       0.68      0.46      0.55        65
          B2       0.63      0.87      0.73        39
          C1       0.00      0.00      0.00         1

    accuracy                           0.62       160
   macro avg       0.47      0.50      0.47       160
weighted avg       0.63      0.62      0.61       160


Fold 4
[[ 4  7  3  0  0]
 [10 22  9  0  0]
 [ 8 15 27 15  0]
 [ 0  1  9 29  0]
 [ 0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.18      0.29      0.22        14
          A2       0.49      0.54      0.51        41
          B1       0.56      0.42      0.48        65
          B2       0.64      0.74      0.69        39
          C1       0.00      0.00      0.00         1

    accuracy                           0.51       160
   macro avg       0.38      0.40      0.38       160
weighted avg       0.53      0.51      0.51       160


K-fold scores
[0.504249027792196, 0.5231882397665625, 0.5073128069687703, 0.6135737975936565, 0.5129898351773995]
SKF f1 score mean 0.532262741459717

************for dimension:  CoherenceCohesion  ***************
Printing class statistics
Counter({'A2': 334, 'B1': 300, 'A1': 109, 'B2': 57})
RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=300,
                       n_jobs=None, oob_score=False, random_state=1234,
                       verbose=0, warm_start=False)
Fold 0
[[ 0 20  1  0]
 [ 0 62  5  0]
 [ 0 11 49  0]
 [ 0  0 12  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        21
          A2       0.67      0.93      0.78        67
          B1       0.73      0.82      0.77        60
          B2       0.00      0.00      0.00        12

    accuracy                           0.69       160
   macro avg       0.35      0.44      0.39       160
weighted avg       0.55      0.69      0.61       160


Fold 1
[[ 0 21  1  0]
 [ 0 56 11  0]
 [ 0 14 46  0]
 [ 0  1 10  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        22
          A2       0.61      0.84      0.70        67
          B1       0.68      0.77      0.72        60
          B2       0.00      0.00      0.00        11

    accuracy                           0.64       160
   macro avg       0.32      0.40      0.36       160
weighted avg       0.51      0.64      0.56       160


Fold 2
[[ 0 22  0  0]
 [ 1 56 10  0]
 [ 0 11 49  0]
 [ 0  1 10  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        22
          A2       0.62      0.84      0.71        67
          B1       0.71      0.82      0.76        60
          B2       0.00      0.00      0.00        11

    accuracy                           0.66       160
   macro avg       0.33      0.41      0.37       160
weighted avg       0.53      0.66      0.58       160


Fold 3
[[ 0 21  1  0]
 [ 0 57 10  0]
 [ 0 14 46  0]
 [ 0  0 11  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        22
          A2       0.62      0.85      0.72        67
          B1       0.68      0.77      0.72        60
          B2       0.00      0.00      0.00        11

    accuracy                           0.64       160
   macro avg       0.32      0.40      0.36       160
weighted avg       0.51      0.64      0.57       160


Fold 4
[[ 0 22  0  0]
 [ 0 61  5  0]
 [ 0 15 45  0]
 [ 0  1 11  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        22
          A2       0.62      0.92      0.74        66
          B1       0.74      0.75      0.74        60
          B2       0.00      0.00      0.00        12

    accuracy                           0.66       160
   macro avg       0.34      0.42      0.37       160
weighted avg       0.53      0.66      0.58       160


K-fold scores
[0.6139013287401575, 0.5644998034591195, 0.5836098355799141, 0.5697670990566038, 0.5839256198347107]
SKF f1 score mean 0.5831407373341012

LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
          verbose=0)
Fold 0
[[12  9  0  0]
 [18 38 10  1]
 [ 2  9 42  7]
 [ 0  0 10  2]]
              precision    recall  f1-score   support

          A1       0.38      0.57      0.45        21
          A2       0.68      0.57      0.62        67
          B1       0.68      0.70      0.69        60
          B2       0.20      0.17      0.18        12

    accuracy                           0.59       160
   macro avg       0.48      0.50      0.49       160
weighted avg       0.60      0.59      0.59       160


Fold 1
[[10 10  2  0]
 [13 41 12  1]
 [ 2  8 40 10]
 [ 0  1  8  2]]
              precision    recall  f1-score   support

          A1       0.40      0.45      0.43        22
          A2       0.68      0.61      0.65        67
          B1       0.65      0.67      0.66        60
          B2       0.15      0.18      0.17        11

    accuracy                           0.58       160
   macro avg       0.47      0.48      0.47       160
weighted avg       0.59      0.58      0.59       160


Fold 2
[[ 3 18  1  0]
 [ 9 45 12  1]
 [ 0 10 44  6]
 [ 0  0 10  1]]
              precision    recall  f1-score   support

          A1       0.25      0.14      0.18        22
          A2       0.62      0.67      0.64        67
          B1       0.66      0.73      0.69        60
          B2       0.12      0.09      0.11        11

    accuracy                           0.58       160
   macro avg       0.41      0.41      0.40       160
weighted avg       0.55      0.58      0.56       160


Fold 3
[[ 6 16  0  0]
 [11 45  9  2]
 [ 4  9 42  5]
 [ 1  0  5  5]]
              precision    recall  f1-score   support

          A1       0.27      0.27      0.27        22
          A2       0.64      0.67      0.66        67
          B1       0.75      0.70      0.72        60
          B2       0.42      0.45      0.43        11

    accuracy                           0.61       160
   macro avg       0.52      0.52      0.52       160
weighted avg       0.62      0.61      0.61       160


Fold 4
[[ 7 13  2  0]
 [18 40  7  1]
 [ 2  8 48  2]
 [ 0  1  6  5]]
              precision    recall  f1-score   support

          A1       0.26      0.32      0.29        22
          A2       0.65      0.61      0.62        66
          B1       0.76      0.80      0.78        60
          B2       0.62      0.42      0.50        12

    accuracy                           0.62       160
   macro avg       0.57      0.54      0.55       160
weighted avg       0.63      0.62      0.63       160


K-fold scores
[0.590006884610364, 0.5862446267234994, 0.5605404962440841, 0.6140342693616695, 0.6272811411149826]
SKF f1 score mean 0.5956214836109199

LogisticRegression(C=1.0, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='multinomial', n_jobs=None,
                   penalty='l2', random_state=1234, solver='lbfgs', tol=0.0001,
                   verbose=0, warm_start=False)
Fold 0
[[12  9  0  0]
 [20 37  9  1]
 [ 2  7 37 14]
 [ 0  0  9  3]]
              precision    recall  f1-score   support

          A1       0.35      0.57      0.44        21
          A2       0.70      0.55      0.62        67
          B1       0.67      0.62      0.64        60
          B2       0.17      0.25      0.20        12

    accuracy                           0.56       160
   macro avg       0.47      0.50      0.47       160
weighted avg       0.60      0.56      0.57       160


Fold 1
[[10 10  2  0]
 [14 39 14  0]
 [ 3  4 40 13]
 [ 0  1  8  2]]
              precision    recall  f1-score   support

          A1       0.37      0.45      0.41        22
          A2       0.72      0.58      0.64        67
          B1       0.62      0.67      0.65        60
          B2       0.13      0.18      0.15        11

    accuracy                           0.57       160
   macro avg       0.46      0.47      0.46       160
weighted avg       0.60      0.57      0.58       160


Fold 2
[[ 3 19  0  0]
 [14 41 12  0]
 [ 0  9 43  8]
 [ 0  1  8  2]]
              precision    recall  f1-score   support

          A1       0.18      0.14      0.15        22
          A2       0.59      0.61      0.60        67
          B1       0.68      0.72      0.70        60
          B2       0.20      0.18      0.19        11

    accuracy                           0.56       160
   macro avg       0.41      0.41      0.41       160
weighted avg       0.54      0.56      0.55       160


Fold 3
[[ 8 14  0  0]
 [14 42  8  3]
 [ 2  9 39 10]
 [ 0  0  6  5]]
              precision    recall  f1-score   support

          A1       0.33      0.36      0.35        22
          A2       0.65      0.63      0.64        67
          B1       0.74      0.65      0.69        60
          B2       0.28      0.45      0.34        11

    accuracy                           0.59       160
   macro avg       0.50      0.52      0.50       160
weighted avg       0.61      0.59      0.60       160


Fold 4
[[ 9 13  0  0]
 [28 29  8  1]
 [ 4 11 37  8]
 [ 0  1  6  5]]
              precision    recall  f1-score   support

          A1       0.22      0.41      0.29        22
          A2       0.54      0.44      0.48        66
          B1       0.73      0.62      0.67        60
          B2       0.36      0.42      0.38        12

    accuracy                           0.50       160
   macro avg       0.46      0.47      0.46       160
weighted avg       0.55      0.50      0.52       160


K-fold scores
[0.5718062417654808, 0.5785728724564083, 0.5470828923316906, 0.5968598137576425, 0.5175068681318681]
SKF f1 score mean 0.5623657376886181

************for dimension:  Sociolinguisticappropriateness  ***************
Printing class statistics
Counter({'B1': 372, 'A2': 336, 'A1': 56, 'B2': 36})
RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=300,
                       n_jobs=None, oob_score=False, random_state=1234,
                       verbose=0, warm_start=False)
Fold 0
[[ 0 10  1  0]
 [ 0 50 17  0]
 [ 0 10 65  0]
 [ 0  0  7  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        11
          A2       0.71      0.75      0.73        67
          B1       0.72      0.87      0.79        75
          B2       0.00      0.00      0.00         7

    accuracy                           0.72       160
   macro avg       0.36      0.40      0.38       160
weighted avg       0.64      0.72      0.67       160


Fold 1
[[ 0 11  0  0]
 [ 0 54 13  0]
 [ 0 24 51  0]
 [ 0  0  7  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        11
          A2       0.61      0.81      0.69        67
          B1       0.72      0.68      0.70        75
          B2       0.00      0.00      0.00         7

    accuracy                           0.66       160
   macro avg       0.33      0.37      0.35       160
weighted avg       0.59      0.66      0.62       160


Fold 2
[[ 0 11  0  0]
 [ 0 51 16  0]
 [ 0 22 52  0]
 [ 0  2  6  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        11
          A2       0.59      0.76      0.67        67
          B1       0.70      0.70      0.70        74
          B2       0.00      0.00      0.00         8

    accuracy                           0.64       160
   macro avg       0.32      0.37      0.34       160
weighted avg       0.57      0.64      0.60       160


Fold 3
[[ 0 12  0  0]
 [ 0 54 13  0]
 [ 0 16 58  0]
 [ 0  0  7  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        12
          A2       0.66      0.81      0.72        67
          B1       0.74      0.78      0.76        74
          B2       0.00      0.00      0.00         7

    accuracy                           0.70       160
   macro avg       0.35      0.40      0.37       160
weighted avg       0.62      0.70      0.66       160


Fold 4
[[ 0 10  1  0]
 [ 2 54 12  0]
 [ 0 15 59  0]
 [ 0  0  7  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        11
          A2       0.68      0.79      0.73        68
          B1       0.75      0.80      0.77        74
          B2       0.00      0.00      0.00         7

    accuracy                           0.71       160
   macro avg       0.36      0.40      0.38       160
weighted avg       0.64      0.71      0.67       160


K-fold scores
[0.6749751161247511, 0.617386722866175, 0.6041666666666667, 0.6564840162486754, 0.6689442443644124]
SKF f1 score mean 0.6443913532541361

LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
          verbose=0)
Fold 0
[[ 3  7  1  0]
 [ 2 44 20  1]
 [ 1 12 59  3]
 [ 0  0  7  0]]
              precision    recall  f1-score   support

          A1       0.50      0.27      0.35        11
          A2       0.70      0.66      0.68        67
          B1       0.68      0.79      0.73        75
          B2       0.00      0.00      0.00         7

    accuracy                           0.66       160
   macro avg       0.47      0.43      0.44       160
weighted avg       0.64      0.66      0.65       160


Fold 1
[[ 4  7  0  0]
 [ 2 47 17  1]
 [ 1 21 48  5]
 [ 0  0  7  0]]
              precision    recall  f1-score   support

          A1       0.57      0.36      0.44        11
          A2       0.63      0.70      0.66        67
          B1       0.67      0.64      0.65        75
          B2       0.00      0.00      0.00         7

    accuracy                           0.62       160
   macro avg       0.47      0.43      0.44       160
weighted avg       0.61      0.62      0.61       160


Fold 2
[[ 4  4  3  0]
 [ 7 45 13  2]
 [ 2 20 47  5]
 [ 0  1  3  4]]
              precision    recall  f1-score   support

          A1       0.31      0.36      0.33        11
          A2       0.64      0.67      0.66        67
          B1       0.71      0.64      0.67        74
          B2       0.36      0.50      0.42         8

    accuracy                           0.62       160
   macro avg       0.51      0.54      0.52       160
weighted avg       0.64      0.62      0.63       160


Fold 3
[[ 1  9  2  0]
 [ 3 46 18  0]
 [ 0 19 52  3]
 [ 0  0  6  1]]
              precision    recall  f1-score   support

          A1       0.25      0.08      0.12        12
          A2       0.62      0.69      0.65        67
          B1       0.67      0.70      0.68        74
          B2       0.25      0.14      0.18         7

    accuracy                           0.62       160
   macro avg       0.45      0.40      0.41       160
weighted avg       0.60      0.62      0.61       160


Fold 4
[[ 2  8  1  0]
 [ 5 47 16  0]
 [ 1 18 53  2]
 [ 0  0  5  2]]
              precision    recall  f1-score   support

          A1       0.25      0.18      0.21        11
          A2       0.64      0.69      0.67        68
          B1       0.71      0.72      0.71        74
          B2       0.50      0.29      0.36         7

    accuracy                           0.65       160
   macro avg       0.53      0.47      0.49       160
weighted avg       0.64      0.65      0.64       160


K-fold scores
[0.6491614295290765, 0.6138787087604995, 0.6295962534072408, 0.6070038642302079, 0.6427429540905345]
SKF f1 score mean 0.6284766420035119

LogisticRegression(C=1.0, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='multinomial', n_jobs=None,
                   penalty='l2', random_state=1234, solver='lbfgs', tol=0.0001,
                   verbose=0, warm_start=False)
Fold 0
[[ 2  8  1  0]
 [ 6 45 15  1]
 [ 2 11 55  7]
 [ 0  0  5  2]]
              precision    recall  f1-score   support

          A1       0.20      0.18      0.19        11
          A2       0.70      0.67      0.69        67
          B1       0.72      0.73      0.73        75
          B2       0.20      0.29      0.24         7

    accuracy                           0.65       160
   macro avg       0.46      0.47      0.46       160
weighted avg       0.66      0.65      0.65       160


Fold 1
[[ 6  5  0  0]
 [10 43 13  1]
 [ 1 15 49 10]
 [ 0  0  4  3]]
              precision    recall  f1-score   support

          A1       0.35      0.55      0.43        11
          A2       0.68      0.64      0.66        67
          B1       0.74      0.65      0.70        75
          B2       0.21      0.43      0.29         7

    accuracy                           0.63       160
   macro avg       0.50      0.57      0.52       160
weighted avg       0.67      0.63      0.64       160


Fold 2
[[ 5  5  1  0]
 [ 8 46 10  3]
 [ 2 20 39 13]
 [ 0  2  1  5]]
              precision    recall  f1-score   support

          A1       0.33      0.45      0.38        11
          A2       0.63      0.69      0.66        67
          B1       0.76      0.53      0.62        74
          B2       0.24      0.62      0.34         8

    accuracy                           0.59       160
   macro avg       0.49      0.57      0.50       160
weighted avg       0.65      0.59      0.61       160


Fold 3
[[ 5  7  0  0]
 [ 8 43 15  1]
 [ 3 14 51  6]
 [ 0  0  5  2]]
              precision    recall  f1-score   support

          A1       0.31      0.42      0.36        12
          A2       0.67      0.64      0.66        67
          B1       0.72      0.69      0.70        74
          B2       0.22      0.29      0.25         7

    accuracy                           0.63       160
   macro avg       0.48      0.51      0.49       160
weighted avg       0.65      0.63      0.64       160


Fold 4
[[ 5  5  1  0]
 [13 43 12  0]
 [ 1 15 53  5]
 [ 0  0  5  2]]
              precision    recall  f1-score   support

          A1       0.26      0.45      0.33        11
          A2       0.68      0.63      0.66        68
          B1       0.75      0.72      0.73        74
          B2       0.29      0.29      0.29         7

    accuracy                           0.64       160
   macro avg       0.49      0.52      0.50       160
weighted avg       0.67      0.64      0.65       160


K-fold scores
[0.6525537053707283, 0.644781388823942, 0.6074622584312239, 0.6379726220245929, 0.6525277485303149]
SKF f1 score mean 0.6390595446361604

FOr lang:  CZ
768
************for dimension:  OverallCEFRrating  ***************
Printing class statistics
Counter({'A2': 188, 'B1': 165, 'B2': 81})
RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=300,
                       n_jobs=None, oob_score=False, random_state=1234,
                       verbose=0, warm_start=False)
Fold 0
[[32  6  0]
 [ 6 23  4]
 [ 0  7  9]]
              precision    recall  f1-score   support

          A2       0.84      0.84      0.84        38
          B1       0.64      0.70      0.67        33
          B2       0.69      0.56      0.62        16

    accuracy                           0.74        87
   macro avg       0.72      0.70      0.71        87
weighted avg       0.74      0.74      0.73        87


Fold 1
[[31  7  0]
 [ 7 23  3]
 [ 0  7  9]]
              precision    recall  f1-score   support

          A2       0.82      0.82      0.82        38
          B1       0.62      0.70      0.66        33
          B2       0.75      0.56      0.64        16

    accuracy                           0.72        87
   macro avg       0.73      0.69      0.71        87
weighted avg       0.73      0.72      0.72        87


Fold 2
[[33  5  0]
 [11 19  3]
 [ 0 12  4]]
              precision    recall  f1-score   support

          A2       0.75      0.87      0.80        38
          B1       0.53      0.58      0.55        33
          B2       0.57      0.25      0.35        16

    accuracy                           0.64        87
   macro avg       0.62      0.56      0.57        87
weighted avg       0.63      0.64      0.62        87


Fold 3
[[34  3  0]
 [12 18  3]
 [ 1  8  8]]
              precision    recall  f1-score   support

          A2       0.72      0.92      0.81        37
          B1       0.62      0.55      0.58        33
          B2       0.73      0.47      0.57        17

    accuracy                           0.69        87
   macro avg       0.69      0.64      0.65        87
weighted avg       0.69      0.69      0.68        87


Fold 4
[[33  4  0]
 [18 12  3]
 [ 0  7  9]]
              precision    recall  f1-score   support

          A2       0.65      0.89      0.75        37
          B1       0.52      0.36      0.43        33
          B2       0.75      0.56      0.64        16

    accuracy                           0.63        86
   macro avg       0.64      0.61      0.61        86
weighted avg       0.62      0.63      0.61        86


K-fold scores
[0.7348394768133175, 0.7238095238095238, 0.624419497568289, 0.6761834136695094, 0.6067275747508305]
SKF f1 score mean 0.6731958973222939

LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
          verbose=0)
Fold 0
[[30  6  2]
 [12 12  9]
 [ 2  6  8]]
              precision    recall  f1-score   support

          A2       0.68      0.79      0.73        38
          B1       0.50      0.36      0.42        33
          B2       0.42      0.50      0.46        16

    accuracy                           0.57        87
   macro avg       0.53      0.55      0.54        87
weighted avg       0.56      0.57      0.56        87


Fold 1
[[30  7  1]
 [ 5 23  5]
 [ 0  5 11]]
              precision    recall  f1-score   support

          A2       0.86      0.79      0.82        38
          B1       0.66      0.70      0.68        33
          B2       0.65      0.69      0.67        16

    accuracy                           0.74        87
   macro avg       0.72      0.72      0.72        87
weighted avg       0.74      0.74      0.74        87


Fold 2
[[29  9  0]
 [ 8 18  7]
 [ 1  4 11]]
              precision    recall  f1-score   support

          A2       0.76      0.76      0.76        38
          B1       0.58      0.55      0.56        33
          B2       0.61      0.69      0.65        16

    accuracy                           0.67        87
   macro avg       0.65      0.67      0.66        87
weighted avg       0.67      0.67      0.67        87


Fold 3
[[27 10  0]
 [ 6 24  3]
 [ 0 11  6]]
              precision    recall  f1-score   support

          A2       0.82      0.73      0.77        37
          B1       0.53      0.73      0.62        33
          B2       0.67      0.35      0.46        17

    accuracy                           0.66        87
   macro avg       0.67      0.60      0.62        87
weighted avg       0.68      0.66      0.65        87


Fold 4
[[32  5  0]
 [16 12  5]
 [ 0  7  9]]
              precision    recall  f1-score   support

          A2       0.67      0.86      0.75        37
          B1       0.50      0.36      0.42        33
          B2       0.64      0.56      0.60        16

    accuracy                           0.62        86
   macro avg       0.60      0.60      0.59        86
weighted avg       0.60      0.62      0.60        86


K-fold scores
[0.5633781678755342, 0.7381962389742545, 0.6656947261663286, 0.6516862447896931, 0.5971344229246166]
SKF f1 score mean 0.6432179601460855

LogisticRegression(C=1.0, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='multinomial', n_jobs=None,
                   penalty='l2', random_state=1234, solver='lbfgs', tol=0.0001,
                   verbose=0, warm_start=False)
Fold 0
[[31  6  1]
 [ 6 17 10]
 [ 0  6 10]]
              precision    recall  f1-score   support

          A2       0.84      0.82      0.83        38
          B1       0.59      0.52      0.55        33
          B2       0.48      0.62      0.54        16

    accuracy                           0.67        87
   macro avg       0.63      0.65      0.64        87
weighted avg       0.68      0.67      0.67        87


Fold 1
[[30  7  1]
 [ 5 23  5]
 [ 0  5 11]]
              precision    recall  f1-score   support

          A2       0.86      0.79      0.82        38
          B1       0.66      0.70      0.68        33
          B2       0.65      0.69      0.67        16

    accuracy                           0.74        87
   macro avg       0.72      0.72      0.72        87
weighted avg       0.74      0.74      0.74        87


Fold 2
[[29  9  0]
 [ 8 18  7]
 [ 0  4 12]]
              precision    recall  f1-score   support

          A2       0.78      0.76      0.77        38
          B1       0.58      0.55      0.56        33
          B2       0.63      0.75      0.69        16

    accuracy                           0.68        87
   macro avg       0.67      0.69      0.67        87
weighted avg       0.68      0.68      0.68        87


Fold 3
[[31  6  0]
 [ 6 22  5]
 [ 0  6 11]]
              precision    recall  f1-score   support

          A2       0.84      0.84      0.84        37
          B1       0.65      0.67      0.66        33
          B2       0.69      0.65      0.67        17

    accuracy                           0.74        87
   macro avg       0.72      0.72      0.72        87
weighted avg       0.74      0.74      0.74        87


Fold 4
[[31  6  0]
 [13 15  5]
 [ 0  5 11]]
              precision    recall  f1-score   support

          A2       0.70      0.84      0.77        37
          B1       0.58      0.45      0.51        33
          B2       0.69      0.69      0.69        16

    accuracy                           0.66        86
   macro avg       0.66      0.66      0.65        86
weighted avg       0.65      0.66      0.65        86


K-fold scores
[0.6684914502934524, 0.7381962389742545, 0.6772482211275316, 0.7356893692457254, 0.6523331240845366]
SKF f1 score mean 0.6943916807451

************for dimension:  Grammaticalaccuracy  ***************
Printing class statistics
Counter({'A2': 185, 'B1': 156, 'B2': 82, 'A1': 6, 'C1': 5})
RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=300,
                       n_jobs=None, oob_score=False, random_state=1234,
                       verbose=0, warm_start=False)
Fold 0
[[ 0  1  0  0  0]
 [ 0 28  7  2  0]
 [ 0 15 12  5  0]
 [ 0  1  5 10  0]
 [ 0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.62      0.76      0.68        37
          B1       0.50      0.38      0.43        32
          B2       0.56      0.62      0.59        16
          C1       0.00      0.00      0.00         1

    accuracy                           0.57        87
   macro avg       0.34      0.35      0.34        87
weighted avg       0.55      0.57      0.56        87


Fold 1
[[ 0  1  0  0  0]
 [ 0 26  7  4  0]
 [ 0 16 12  3  0]
 [ 0  1  9  7  0]
 [ 0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.59      0.70      0.64        37
          B1       0.43      0.39      0.41        31
          B2       0.47      0.41      0.44        17
          C1       0.00      0.00      0.00         1

    accuracy                           0.52        87
   macro avg       0.30      0.30      0.30        87
weighted avg       0.50      0.52      0.50        87


Fold 2
[[ 0  1  0  0  0]
 [ 0 29  7  1  0]
 [ 0 18 10  3  0]
 [ 0  1  7  9  0]
 [ 0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.59      0.78      0.67        37
          B1       0.42      0.32      0.36        31
          B2       0.64      0.53      0.58        17
          C1       0.00      0.00      0.00         1

    accuracy                           0.55        87
   macro avg       0.33      0.33      0.32        87
weighted avg       0.53      0.55      0.53        87


Fold 3
[[ 0  2  0  0  0]
 [ 0 27  9  1  0]
 [ 0 16 10  5  0]
 [ 0  4  3  9  0]
 [ 0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         2
          A2       0.55      0.73      0.63        37
          B1       0.45      0.32      0.38        31
          B2       0.56      0.56      0.56        16
          C1       0.00      0.00      0.00         1

    accuracy                           0.53        87
   macro avg       0.31      0.32      0.31        87
weighted avg       0.50      0.53      0.50        87


Fold 4
[[ 0  1  0  0  0]
 [ 0 27  7  3  0]
 [ 0 13  9  9  0]
 [ 0  3  4  9  0]
 [ 0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.61      0.73      0.67        37
          B1       0.45      0.29      0.35        31
          B2       0.41      0.56      0.47        16
          C1       0.00      0.00      0.00         1

    accuracy                           0.52        86
   macro avg       0.29      0.32      0.30        86
weighted avg       0.50      0.52      0.50        86


K-fold scores
[0.5562568172769529, 0.5034569644974541, 0.5298526826063882, 0.5049502453687592, 0.502171982624139]
SKF f1 score mean 0.5193377384747386

LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
          verbose=0)
Fold 0
[[ 0  1  0  0  0]
 [ 0 23 12  2  0]
 [ 0 14 14  4  0]
 [ 0  3  6  7  0]
 [ 0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.56      0.62      0.59        37
          B1       0.44      0.44      0.44        32
          B2       0.50      0.44      0.47        16
          C1       0.00      0.00      0.00         1

    accuracy                           0.51        87
   macro avg       0.30      0.30      0.30        87
weighted avg       0.49      0.51      0.50        87


Fold 1
[[ 0  1  0  0  0]
 [ 2 19 14  2  0]
 [ 0  8 19  4  0]
 [ 0  1 12  4  0]
 [ 0  1  0  0  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.63      0.51      0.57        37
          B1       0.42      0.61      0.50        31
          B2       0.40      0.24      0.30        17
          C1       0.00      0.00      0.00         1

    accuracy                           0.48        87
   macro avg       0.29      0.27      0.27        87
weighted avg       0.50      0.48      0.48        87


Fold 2
[[ 0  1  0  0  0]
 [ 0 26  8  3  0]
 [ 0 15 11  5  0]
 [ 0  2  5 10  0]
 [ 0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.59      0.70      0.64        37
          B1       0.46      0.35      0.40        31
          B2       0.53      0.59      0.56        17
          C1       0.00      0.00      0.00         1

    accuracy                           0.54        87
   macro avg       0.32      0.33      0.32        87
weighted avg       0.52      0.54      0.52        87


Fold 3
[[ 0  2  0  0  0]
 [ 0 22 11  4  0]
 [ 1 11 12  7  0]
 [ 0  5  4  7  0]
 [ 0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         2
          A2       0.55      0.59      0.57        37
          B1       0.44      0.39      0.41        31
          B2       0.37      0.44      0.40        16
          C1       0.00      0.00      0.00         1

    accuracy                           0.47        87
   macro avg       0.27      0.28      0.28        87
weighted avg       0.46      0.47      0.46        87


Fold 4
[[ 0  1  0  0  0]
 [ 1 24 10  2  0]
 [ 0 12 10  9  0]
 [ 0  4  5  7  0]
 [ 0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.59      0.65      0.62        37
          B1       0.40      0.32      0.36        31
          B2       0.37      0.44      0.40        16
          C1       0.00      0.00      0.00         1

    accuracy                           0.48        86
   macro avg       0.27      0.28      0.27        86
weighted avg       0.46      0.48      0.47        86


K-fold scores
[0.4975537872089597, 0.4772656513092265, 0.52410955016319, 0.4640280844799275, 0.4679146434960388]
SKF f1 score mean 0.4861743433314684

LogisticRegression(C=1.0, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='multinomial', n_jobs=None,
                   penalty='l2', random_state=1234, solver='lbfgs', tol=0.0001,
                   verbose=0, warm_start=False)
Fold 0
[[ 0  1  0  0  0]
 [ 2 19 14  2  0]
 [ 0  9 12 11  0]
 [ 0  2  4  9  1]
 [ 0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.61      0.51      0.56        37
          B1       0.40      0.38      0.39        32
          B2       0.39      0.56      0.46        16
          C1       0.00      0.00      0.00         1

    accuracy                           0.46        87
   macro avg       0.28      0.29      0.28        87
weighted avg       0.48      0.46      0.46        87


Fold 1
[[ 0  1  0  0  0]
 [ 3 21  8  5  0]
 [ 0  8 17  6  0]
 [ 0  0  7  8  2]
 [ 0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.70      0.57      0.63        37
          B1       0.53      0.55      0.54        31
          B2       0.40      0.47      0.43        17
          C1       0.00      0.00      0.00         1

    accuracy                           0.53        87
   macro avg       0.33      0.32      0.32        87
weighted avg       0.57      0.53      0.54        87


Fold 2
[[ 0  1  0  0  0]
 [ 0 28  6  3  0]
 [ 0 13 13  5  0]
 [ 0  2  4 11  0]
 [ 0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.64      0.76      0.69        37
          B1       0.57      0.42      0.48        31
          B2       0.55      0.65      0.59        17
          C1       0.00      0.00      0.00         1

    accuracy                           0.60        87
   macro avg       0.35      0.36      0.35        87
weighted avg       0.58      0.60      0.58        87


Fold 3
[[ 0  2  0  0  0]
 [ 0 22 11  4  0]
 [ 1  7 13 10  0]
 [ 0  2  5  9  0]
 [ 0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         2
          A2       0.67      0.59      0.63        37
          B1       0.45      0.42      0.43        31
          B2       0.38      0.56      0.45        16
          C1       0.00      0.00      0.00         1

    accuracy                           0.51        87
   macro avg       0.30      0.32      0.30        87
weighted avg       0.51      0.51      0.50        87


Fold 4
[[ 0  1  0  0  0]
 [ 1 22 11  3  0]
 [ 0 11 10 10  0]
 [ 0  2  5  9  0]
 [ 0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.61      0.59      0.60        37
          B1       0.38      0.32      0.35        31
          B2       0.39      0.56      0.46        16
          C1       0.00      0.00      0.00         1

    accuracy                           0.48        86
   macro avg       0.28      0.30      0.28        86
weighted avg       0.47      0.48      0.47        86


K-fold scores
[0.4649216407706233, 0.5433970107155902, 0.5817733442254516, 0.504488232074439, 0.4716648631405259]
SKF f1 score mean 0.513249018185326

************for dimension:  Orthography  ***************
Printing class statistics
Counter({'B1': 269, 'B2': 114, 'A2': 46, 'C1': 5})
RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=300,
                       n_jobs=None, oob_score=False, random_state=1234,
                       verbose=0, warm_start=False)
Fold 0
[[ 0  9  0  0]
 [ 0 51  3  0]
 [ 0 17  6  0]
 [ 0  0  1  0]]
              precision    recall  f1-score   support

          A2       0.00      0.00      0.00         9
          B1       0.66      0.94      0.78        54
          B2       0.60      0.26      0.36        23
          C1       0.00      0.00      0.00         1

    accuracy                           0.66        87
   macro avg       0.32      0.30      0.29        87
weighted avg       0.57      0.66      0.58        87


Fold 1
[[ 0  9  0  0]
 [ 0 50  4  0]
 [ 0 19  4  0]
 [ 0  1  0  0]]
              precision    recall  f1-score   support

          A2       0.00      0.00      0.00         9
          B1       0.63      0.93      0.75        54
          B2       0.50      0.17      0.26        23
          C1       0.00      0.00      0.00         1

    accuracy                           0.62        87
   macro avg       0.28      0.27      0.25        87
weighted avg       0.53      0.62      0.53        87


Fold 2
[[ 1  8  0  0]
 [ 0 51  3  0]
 [ 0 18  5  0]
 [ 0  1  0  0]]
              precision    recall  f1-score   support

          A2       1.00      0.11      0.20         9
          B1       0.65      0.94      0.77        54
          B2       0.62      0.22      0.32        23
          C1       0.00      0.00      0.00         1

    accuracy                           0.66        87
   macro avg       0.57      0.32      0.32        87
weighted avg       0.67      0.66      0.59        87


Fold 3
[[ 0 10  0  0]
 [ 0 48  6  0]
 [ 0 14  8  0]
 [ 0  0  1  0]]
              precision    recall  f1-score   support

          A2       0.00      0.00      0.00        10
          B1       0.67      0.89      0.76        54
          B2       0.53      0.36      0.43        22
          C1       0.00      0.00      0.00         1

    accuracy                           0.64        87
   macro avg       0.30      0.31      0.30        87
weighted avg       0.55      0.64      0.58        87


Fold 4
[[ 0  9  0  0]
 [ 0 52  1  0]
 [ 0 17  6  0]
 [ 0  0  1  0]]
              precision    recall  f1-score   support

          A2       0.00      0.00      0.00         9
          B1       0.67      0.98      0.79        53
          B2       0.75      0.26      0.39        23
          C1       0.00      0.00      0.00         1

    accuracy                           0.67        86
   macro avg       0.35      0.31      0.30        86
weighted avg       0.61      0.67      0.59        86


K-fold scores
[0.5794188263259072, 0.5349079037973131, 0.5855934202986484, 0.582257133981272, 0.5927856009803978]
SKF f1 score mean 0.5749925770767076

LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
          verbose=0)
Fold 0
[[ 3  6  0  0]
 [ 6 31 17  0]
 [ 0 14  9  0]
 [ 0  0  1  0]]
              precision    recall  f1-score   support

          A2       0.33      0.33      0.33         9
          B1       0.61      0.57      0.59        54
          B2       0.33      0.39      0.36        23
          C1       0.00      0.00      0.00         1

    accuracy                           0.49        87
   macro avg       0.32      0.32      0.32        87
weighted avg       0.50      0.49      0.50        87


Fold 1
[[ 1  8  0  0]
 [ 6 30 18  0]
 [ 0 12 11  0]
 [ 0  0  1  0]]
              precision    recall  f1-score   support

          A2       0.14      0.11      0.12         9
          B1       0.60      0.56      0.58        54
          B2       0.37      0.48      0.42        23
          C1       0.00      0.00      0.00         1

    accuracy                           0.48        87
   macro avg       0.28      0.29      0.28        87
weighted avg       0.48      0.48      0.48        87


Fold 2
[[ 3  6  0  0]
 [ 7 40  6  1]
 [ 1  9 13  0]
 [ 0  0  1  0]]
              precision    recall  f1-score   support

          A2       0.27      0.33      0.30         9
          B1       0.73      0.74      0.73        54
          B2       0.65      0.57      0.60        23
          C1       0.00      0.00      0.00         1

    accuracy                           0.64        87
   macro avg       0.41      0.41      0.41        87
weighted avg       0.65      0.64      0.65        87


Fold 3
[[ 3  7  0  0]
 [ 3 37 14  0]
 [ 0 10 12  0]
 [ 0  0  1  0]]
              precision    recall  f1-score   support

          A2       0.50      0.30      0.37        10
          B1       0.69      0.69      0.69        54
          B2       0.44      0.55      0.49        22
          C1       0.00      0.00      0.00         1

    accuracy                           0.60        87
   macro avg       0.41      0.38      0.39        87
weighted avg       0.60      0.60      0.59        87


Fold 4
[[ 3  6  0  0]
 [ 7 38  8  0]
 [ 0 15  8  0]
 [ 0  0  1  0]]
              precision    recall  f1-score   support

          A2       0.30      0.33      0.32         9
          B1       0.64      0.72      0.68        53
          B2       0.47      0.35      0.40        23
          C1       0.00      0.00      0.00         1

    accuracy                           0.57        86
   macro avg       0.35      0.35      0.35        86
weighted avg       0.55      0.57      0.56        86


K-fold scores
[0.4961576354679803, 0.48075880419732087, 0.6464368306565728, 0.5922472437250762, 0.5582138485749256]
SKF f1 score mean 0.5547628725243752

LogisticRegression(C=1.0, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='multinomial', n_jobs=None,
                   penalty='l2', random_state=1234, solver='lbfgs', tol=0.0001,
                   verbose=0, warm_start=False)
Fold 0
[[ 4  4  1  0]
 [ 4 31 19  0]
 [ 0 12 11  0]
 [ 0  0  1  0]]
              precision    recall  f1-score   support

          A2       0.50      0.44      0.47         9
          B1       0.66      0.57      0.61        54
          B2       0.34      0.48      0.40        23
          C1       0.00      0.00      0.00         1

    accuracy                           0.53        87
   macro avg       0.38      0.37      0.37        87
weighted avg       0.55      0.53      0.54        87


Fold 1
[[ 4  5  0  0]
 [10 26 18  0]
 [ 0 11 12  0]
 [ 0  0  1  0]]
              precision    recall  f1-score   support

          A2       0.29      0.44      0.35         9
          B1       0.62      0.48      0.54        54
          B2       0.39      0.52      0.44        23
          C1       0.00      0.00      0.00         1

    accuracy                           0.48        87
   macro avg       0.32      0.36      0.33        87
weighted avg       0.52      0.48      0.49        87


Fold 2
[[ 5  4  0  0]
 [12 32  9  1]
 [ 1  6 16  0]
 [ 0  0  1  0]]
              precision    recall  f1-score   support

          A2       0.28      0.56      0.37         9
          B1       0.76      0.59      0.67        54
          B2       0.62      0.70      0.65        23
          C1       0.00      0.00      0.00         1

    accuracy                           0.61        87
   macro avg       0.41      0.46      0.42        87
weighted avg       0.66      0.61      0.62        87


Fold 3
[[ 7  3  0  0]
 [ 9 32 13  0]
 [ 0  8 14  0]
 [ 0  0  1  0]]
              precision    recall  f1-score   support

          A2       0.44      0.70      0.54        10
          B1       0.74      0.59      0.66        54
          B2       0.50      0.64      0.56        22
          C1       0.00      0.00      0.00         1

    accuracy                           0.61        87
   macro avg       0.42      0.48      0.44        87
weighted avg       0.64      0.61      0.61        87


Fold 4
[[ 4  5  0  0]
 [12 32  9  0]
 [ 0 13 10  0]
 [ 0  0  1  0]]
              precision    recall  f1-score   support

          A2       0.25      0.44      0.32         9
          B1       0.64      0.60      0.62        53
          B2       0.50      0.43      0.47        23
          C1       0.00      0.00      0.00         1

    accuracy                           0.53        86
   macro avg       0.35      0.37      0.35        86
weighted avg       0.55      0.53      0.54        86


K-fold scores
[0.535446080104968, 0.48968571269920586, 0.6247556493861913, 0.613028521425251, 0.5408106192273966]
SKF f1 score mean 0.5607453165686025

************for dimension:  Vocabularyrange  ***************
Printing class statistics
Counter({'B2': 143, 'B1': 141, 'A2': 132, 'C1': 10, 'A1': 8})
RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=300,
                       n_jobs=None, oob_score=False, random_state=1234,
                       verbose=0, warm_start=False)
Fold 0
[[ 0  1  0  0  0]
 [ 0 19  8  0  0]
 [ 0  6 13  9  0]
 [ 0  0  0 29  0]
 [ 0  0  0  2  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.73      0.70      0.72        27
          B1       0.62      0.46      0.53        28
          B2       0.72      1.00      0.84        29
          C1       0.00      0.00      0.00         2

    accuracy                           0.70        87
   macro avg       0.41      0.43      0.42        87
weighted avg       0.67      0.70      0.67        87


Fold 1
[[ 0  2  0  0  0]
 [ 0 16 11  0  0]
 [ 0  2 23  3  0]
 [ 0  1  1 26  0]
 [ 0  0  0  2  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         2
          A2       0.76      0.59      0.67        27
          B1       0.66      0.82      0.73        28
          B2       0.84      0.93      0.88        28
          C1       0.00      0.00      0.00         2

    accuracy                           0.75        87
   macro avg       0.45      0.47      0.46        87
weighted avg       0.72      0.75      0.73        87


Fold 2
[[ 0  1  1  0  0]
 [ 0 13 13  0  0]
 [ 0  4 19  6  0]
 [ 0  1  0 27  0]
 [ 0  0  0  2  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         2
          A2       0.68      0.50      0.58        26
          B1       0.58      0.66      0.61        29
          B2       0.77      0.96      0.86        28
          C1       0.00      0.00      0.00         2

    accuracy                           0.68        87
   macro avg       0.41      0.42      0.41        87
weighted avg       0.64      0.68      0.65        87


Fold 3
[[ 0  2  0  0  0]
 [ 0 20  5  1  0]
 [ 0  2 24  2  0]
 [ 0  0  2 27  0]
 [ 0  0  0  2  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         2
          A2       0.83      0.77      0.80        26
          B1       0.77      0.86      0.81        28
          B2       0.84      0.93      0.89        29
          C1       0.00      0.00      0.00         2

    accuracy                           0.82        87
   macro avg       0.49      0.51      0.50        87
weighted avg       0.78      0.82      0.80        87


Fold 4
[[ 0  1  0  0  0]
 [ 0 15 10  1  0]
 [ 0  3 22  3  0]
 [ 0  0  1 28  0]
 [ 0  0  0  2  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.79      0.58      0.67        26
          B1       0.67      0.79      0.72        28
          B2       0.82      0.97      0.89        29
          C1       0.00      0.00      0.00         2

    accuracy                           0.76        86
   macro avg       0.46      0.47      0.46        86
weighted avg       0.73      0.76      0.74        86


K-fold scores
[0.673476379510155, 0.7255449488061996, 0.6528323651794175, 0.7959976110860936, 0.7361375863091456]
SKF f1 score mean 0.7167977781782022

LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
          verbose=0)
Fold 0
[[ 0  1  0  0  0]
 [ 2 15 10  0  0]
 [ 1  6 13  8  0]
 [ 0  1  0 28  0]
 [ 0  0  0  2  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.65      0.56      0.60        27
          B1       0.57      0.46      0.51        28
          B2       0.74      0.97      0.84        29
          C1       0.00      0.00      0.00         2

    accuracy                           0.64        87
   macro avg       0.39      0.40      0.39        87
weighted avg       0.63      0.64      0.63        87


Fold 1
[[ 0  1  1  0  0]
 [ 1 17  8  1  0]
 [ 1  9 15  3  0]
 [ 0  2  4 22  0]
 [ 0  0  0  2  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         2
          A2       0.59      0.63      0.61        27
          B1       0.54      0.54      0.54        28
          B2       0.79      0.79      0.79        28
          C1       0.00      0.00      0.00         2

    accuracy                           0.62        87
   macro avg       0.38      0.39      0.39        87
weighted avg       0.61      0.62      0.61        87


Fold 2
[[ 0  2  0  0  0]
 [ 1 15 10  0  0]
 [ 0  7 16  6  0]
 [ 0  0  4 24  0]
 [ 0  0  0  2  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         2
          A2       0.62      0.58      0.60        26
          B1       0.53      0.55      0.54        29
          B2       0.75      0.86      0.80        28
          C1       0.00      0.00      0.00         2

    accuracy                           0.63        87
   macro avg       0.38      0.40      0.39        87
weighted avg       0.61      0.63      0.62        87


Fold 3
[[ 0  2  0  0  0]
 [ 0 20  4  2  0]
 [ 0  5 19  4  0]
 [ 0  1  3 25  0]
 [ 0  0  0  2  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         2
          A2       0.71      0.77      0.74        26
          B1       0.73      0.68      0.70        28
          B2       0.76      0.86      0.81        29
          C1       0.00      0.00      0.00         2

    accuracy                           0.74        87
   macro avg       0.44      0.46      0.45        87
weighted avg       0.70      0.74      0.72        87


Fold 4
[[ 0  1  0  0  0]
 [ 0 17  8  1  0]
 [ 0  3 22  3  0]
 [ 0  0  6 23  0]
 [ 0  0  0  2  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.81      0.65      0.72        26
          B1       0.61      0.79      0.69        28
          B2       0.79      0.79      0.79        29
          C1       0.00      0.00      0.00         2

    accuracy                           0.72        86
   macro avg       0.44      0.45      0.44        86
weighted avg       0.71      0.72      0.71        86


K-fold scores
[0.6288886870582853, 0.6137110016420361, 0.6175725696473797, 0.7166673533006496, 0.7099826818406729]
SKF f1 score mean 0.6573644586978047

LogisticRegression(C=1.0, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='multinomial', n_jobs=None,
                   penalty='l2', random_state=1234, solver='lbfgs', tol=0.0001,
                   verbose=0, warm_start=False)
Fold 0
[[ 0  1  0  0  0]
 [ 3 15  9  0  0]
 [ 1  7 13  7  0]
 [ 0  1  0 28  0]
 [ 0  0  0  2  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.62      0.56      0.59        27
          B1       0.59      0.46      0.52        28
          B2       0.76      0.97      0.85        29
          C1       0.00      0.00      0.00         2

    accuracy                           0.64        87
   macro avg       0.39      0.40      0.39        87
weighted avg       0.64      0.64      0.63        87


Fold 1
[[ 0  2  0  0  0]
 [ 1 16 10  0  0]
 [ 0  7 18  3  0]
 [ 0  1  3 24  0]
 [ 0  0  0  2  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         2
          A2       0.62      0.59      0.60        27
          B1       0.58      0.64      0.61        28
          B2       0.83      0.86      0.84        28
          C1       0.00      0.00      0.00         2

    accuracy                           0.67        87
   macro avg       0.40      0.42      0.41        87
weighted avg       0.64      0.67      0.65        87


Fold 2
[[ 0  2  0  0  0]
 [ 1 14 11  0  0]
 [ 0  6 18  5  0]
 [ 0  0  1 27  0]
 [ 0  0  0  2  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         2
          A2       0.64      0.54      0.58        26
          B1       0.60      0.62      0.61        29
          B2       0.79      0.96      0.87        28
          C1       0.00      0.00      0.00         2

    accuracy                           0.68        87
   macro avg       0.41      0.42      0.41        87
weighted avg       0.65      0.68      0.66        87


Fold 3
[[ 0  2  0  0  0]
 [ 0 22  3  1  0]
 [ 0  5 20  3  0]
 [ 0  0  3 24  2]
 [ 0  0  0  2  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         2
          A2       0.76      0.85      0.80        26
          B1       0.77      0.71      0.74        28
          B2       0.80      0.83      0.81        29
          C1       0.00      0.00      0.00         2

    accuracy                           0.76        87
   macro avg       0.47      0.48      0.47        87
weighted avg       0.74      0.76      0.75        87


Fold 4
[[ 0  1  0  0  0]
 [ 2 13  9  1  1]
 [ 0  3 21  4  0]
 [ 0  0  3 26  0]
 [ 0  0  0  2  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.76      0.50      0.60        26
          B1       0.64      0.75      0.69        28
          B2       0.79      0.90      0.84        29
          C1       0.00      0.00      0.00         2

    accuracy                           0.70        86
   macro avg       0.44      0.43      0.43        86
weighted avg       0.70      0.70      0.69        86


K-fold scores
[0.6327403856004261, 0.6547767807308706, 0.658030789598822, 0.74866621930717, 0.6897930163059255]
SKF f1 score mean 0.6768014383086428

************for dimension:  Vocabularycontrol  ***************
Printing class statistics
Counter({'B1': 182, 'A2': 131, 'B2': 100, 'C1': 16, 'A1': 5})
RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=300,
                       n_jobs=None, oob_score=False, random_state=1234,
                       verbose=0, warm_start=False)
Fold 0
[[ 0  0  1  0  0]
 [ 0 13 13  0  0]
 [ 0  7 25  5  0]
 [ 0  1 15  4  0]
 [ 0  0  2  1  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.62      0.50      0.55        26
          B1       0.45      0.68      0.54        37
          B2       0.40      0.20      0.27        20
          C1       0.00      0.00      0.00         3

    accuracy                           0.48        87
   macro avg       0.29      0.28      0.27        87
weighted avg       0.47      0.48      0.46        87


Fold 1
[[ 0  1  0  0  0]
 [ 0 11 15  0  0]
 [ 0 10 25  2  0]
 [ 0  0 15  5  0]
 [ 0  0  1  2  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.50      0.42      0.46        26
          B1       0.45      0.68      0.54        37
          B2       0.56      0.25      0.34        20
          C1       0.00      0.00      0.00         3

    accuracy                           0.47        87
   macro avg       0.30      0.27      0.27        87
weighted avg       0.47      0.47      0.44        87


Fold 2
[[ 0  1  0  0  0]
 [ 0 13 14  0  0]
 [ 0  5 27  4  0]
 [ 0  0 15  5  0]
 [ 0  0  1  2  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.68      0.48      0.57        27
          B1       0.47      0.75      0.58        36
          B2       0.45      0.25      0.32        20
          C1       0.00      0.00      0.00         3

    accuracy                           0.52        87
   macro avg       0.32      0.30      0.29        87
weighted avg       0.51      0.52      0.49        87


Fold 3
[[ 0  1  0  0  0]
 [ 0 12 14  0  0]
 [ 0 10 20  6  0]
 [ 0  1 11  8  0]
 [ 0  0  1  3  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.50      0.46      0.48        26
          B1       0.43      0.56      0.49        36
          B2       0.47      0.40      0.43        20
          C1       0.00      0.00      0.00         4

    accuracy                           0.46        87
   macro avg       0.28      0.28      0.28        87
weighted avg       0.44      0.46      0.44        87


Fold 4
[[ 0  1  0  0  0]
 [ 0 12 14  0  0]
 [ 0  7 21  8  0]
 [ 0  2  7 11  0]
 [ 0  0  0  3  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.55      0.46      0.50        26
          B1       0.50      0.58      0.54        36
          B2       0.50      0.55      0.52        20
          C1       0.00      0.00      0.00         3

    accuracy                           0.51        86
   macro avg       0.31      0.32      0.31        86
weighted avg       0.49      0.51      0.50        86


K-fold scores
[0.4552733928162892, 0.4448930058515422, 0.4898357272976415, 0.44470832480925, 0.4983814634977425]
SKF f1 score mean 0.4666183828544931

LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
          verbose=0)
Fold 0
[[ 0  0  1  0  0]
 [ 0 17  8  1  0]
 [ 0 13 14 10  0]
 [ 0  1 11  8  0]
 [ 0  0  1  2  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.55      0.65      0.60        26
          B1       0.40      0.38      0.39        37
          B2       0.38      0.40      0.39        20
          C1       0.00      0.00      0.00         3

    accuracy                           0.45        87
   macro avg       0.27      0.29      0.28        87
weighted avg       0.42      0.45      0.43        87


Fold 1
[[ 0  1  0  0  0]
 [ 0 15  9  2  0]
 [ 0 15 15  7  0]
 [ 0  2  8  8  2]
 [ 0  0  0  2  1]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.45      0.58      0.51        26
          B1       0.47      0.41      0.43        37
          B2       0.42      0.40      0.41        20
          C1       0.33      0.33      0.33         3

    accuracy                           0.45        87
   macro avg       0.34      0.34      0.34        87
weighted avg       0.44      0.45      0.44        87


Fold 2
[[ 0  1  0  0  0]
 [ 1 14  9  3  0]
 [ 0  8 17 11  0]
 [ 0  0  8 10  2]
 [ 0  0  2  0  1]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.61      0.52      0.56        27
          B1       0.47      0.47      0.47        36
          B2       0.42      0.50      0.45        20
          C1       0.33      0.33      0.33         3

    accuracy                           0.48        87
   macro avg       0.37      0.36      0.36        87
weighted avg       0.49      0.48      0.49        87


Fold 3
[[ 0  1  0  0  0]
 [ 0 13 12  1  0]
 [ 0  8 18 10  0]
 [ 0  1  7 12  0]
 [ 0  0  1  3  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.57      0.50      0.53        26
          B1       0.47      0.50      0.49        36
          B2       0.46      0.60      0.52        20
          C1       0.00      0.00      0.00         4

    accuracy                           0.49        87
   macro avg       0.30      0.32      0.31        87
weighted avg       0.47      0.49      0.48        87


Fold 4
[[ 0  1  0  0  0]
 [ 3 11 11  1  0]
 [ 0 13 15  7  1]
 [ 0  4  4 10  2]
 [ 0  0  1  2  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.38      0.42      0.40        26
          B1       0.48      0.42      0.45        36
          B2       0.50      0.50      0.50        20
          C1       0.00      0.00      0.00         3

    accuracy                           0.42        86
   macro avg       0.27      0.27      0.27        86
weighted avg       0.43      0.42      0.42        86


K-fold scores
[0.4333625157183212, 0.4426715368956113, 0.4851828631138975, 0.47981855735121964, 0.42464422075668173]
SKF f1 score mean 0.4531359387671463

LogisticRegression(C=1.0, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='multinomial', n_jobs=None,
                   penalty='l2', random_state=1234, solver='lbfgs', tol=0.0001,
                   verbose=0, warm_start=False)
Fold 0
[[ 0  1  0  0  0]
 [ 2 19  4  1  0]
 [ 1 14 13  8  1]
 [ 0  1  9 10  0]
 [ 0  0  1  1  1]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.54      0.73      0.62        26
          B1       0.48      0.35      0.41        37
          B2       0.50      0.50      0.50        20
          C1       0.50      0.33      0.40         3

    accuracy                           0.49        87
   macro avg       0.40      0.38      0.39        87
weighted avg       0.50      0.49      0.49        87


Fold 1
[[ 1  0  0  0  0]
 [ 1 17  8  0  0]
 [ 2 16 12  7  0]
 [ 0  1  9  7  3]
 [ 0  0  0  2  1]]
              precision    recall  f1-score   support

          A1       0.25      1.00      0.40         1
          A2       0.50      0.65      0.57        26
          B1       0.41      0.32      0.36        37
          B2       0.44      0.35      0.39        20
          C1       0.25      0.33      0.29         3

    accuracy                           0.44        87
   macro avg       0.37      0.53      0.40        87
weighted avg       0.44      0.44      0.43        87


Fold 2
[[ 1  0  0  0  0]
 [ 4 12  9  2  0]
 [ 0 10 14 12  0]
 [ 0  1  2 13  4]
 [ 0  0  1  0  2]]
              precision    recall  f1-score   support

          A1       0.20      1.00      0.33         1
          A2       0.52      0.44      0.48        27
          B1       0.54      0.39      0.45        36
          B2       0.48      0.65      0.55        20
          C1       0.33      0.67      0.44         3

    accuracy                           0.48        87
   macro avg       0.42      0.63      0.45        87
weighted avg       0.51      0.48      0.48        87


Fold 3
[[ 0  1  0  0  0]
 [ 0 12 11  3  0]
 [ 0 10 16 10  0]
 [ 0  1  6 12  1]
 [ 0  0  0  4  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.50      0.46      0.48        26
          B1       0.48      0.44      0.46        36
          B2       0.41      0.60      0.49        20
          C1       0.00      0.00      0.00         4

    accuracy                           0.46        87
   macro avg       0.28      0.30      0.29        87
weighted avg       0.45      0.46      0.45        87


Fold 4
[[ 0  1  0  0  0]
 [ 4 14  7  1  0]
 [ 1 12 13  8  2]
 [ 0  4  3 11  2]
 [ 0  0  0  3  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.45      0.54      0.49        26
          B1       0.57      0.36      0.44        36
          B2       0.48      0.55      0.51        20
          C1       0.00      0.00      0.00         3

    accuracy                           0.44        86
   macro avg       0.30      0.29      0.29        86
weighted avg       0.48      0.44      0.45        86


K-fold scores
[0.487677831166384, 0.4278482692275796, 0.4821673674716062, 0.4479490866811492, 0.45196389236927104]
SKF f1 score mean 0.45952128938319803

************for dimension:  CoherenceCohesion  ***************
Printing class statistics
Counter({'B1': 171, 'B2': 156, 'A2': 101, 'C1': 5, 'A1': 1})
RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=300,
                       n_jobs=None, oob_score=False, random_state=1234,
                       verbose=0, warm_start=False)
Fold 0
[[11  9  0  0]
 [ 4 26  5  0]
 [ 0  2 29  0]
 [ 0  0  1  0]]
              precision    recall  f1-score   support

          A2       0.73      0.55      0.63        20
          B1       0.70      0.74      0.72        35
          B2       0.83      0.94      0.88        31
          C1       0.00      0.00      0.00         1

    accuracy                           0.76        87
   macro avg       0.57      0.56      0.56        87
weighted avg       0.75      0.76      0.75        87


Fold 1
[[13  7  0  0]
 [ 3 24  7  0]
 [ 0  0 32  0]
 [ 0  0  1  0]]
              precision    recall  f1-score   support

          A2       0.81      0.65      0.72        20
          B1       0.77      0.71      0.74        34
          B2       0.80      1.00      0.89        32
          C1       0.00      0.00      0.00         1

    accuracy                           0.79        87
   macro avg       0.60      0.59      0.59        87
weighted avg       0.78      0.79      0.78        87


Fold 2
[[ 5 15  1  0]
 [ 2 30  2  0]
 [ 0  3 28  0]
 [ 0  0  1  0]]
              precision    recall  f1-score   support

          A2       0.71      0.24      0.36        21
          B1       0.62      0.88      0.73        34
          B2       0.88      0.90      0.89        31
          C1       0.00      0.00      0.00         1

    accuracy                           0.72        87
   macro avg       0.55      0.51      0.49        87
weighted avg       0.73      0.72      0.69        87


Fold 3
[[ 0  0  1  0  0]
 [ 0 13  6  1  0]
 [ 0  6 22  6  0]
 [ 0  0  2 29  0]
 [ 0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.68      0.65      0.67        20
          B1       0.71      0.65      0.68        34
          B2       0.78      0.94      0.85        31
          C1       0.00      0.00      0.00         1

    accuracy                           0.74        87
   macro avg       0.44      0.45      0.44        87
weighted avg       0.71      0.74      0.72        87


Fold 4
[[12  6  2  0]
 [ 3 30  1  0]
 [ 0  3 28  0]
 [ 0  0  1  0]]
              precision    recall  f1-score   support

          A2       0.80      0.60      0.69        20
          B1       0.77      0.88      0.82        34
          B2       0.88      0.90      0.89        31
          C1       0.00      0.00      0.00         1

    accuracy                           0.81        86
   macro avg       0.61      0.60      0.60        86
weighted avg       0.81      0.81      0.80        86


K-fold scores
[0.7481796619727655, 0.7815698988112783, 0.6888920038625673, 0.7217229243598411, 0.8048261249917829]
SKF f1 score mean 0.749038122799647

LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
          verbose=0)
Fold 0
[[15  5  0  0]
 [ 5 24  6  0]
 [ 0  4 27  0]
 [ 0  0  1  0]]
              precision    recall  f1-score   support

          A2       0.75      0.75      0.75        20
          B1       0.73      0.69      0.71        35
          B2       0.79      0.87      0.83        31
          C1       0.00      0.00      0.00         1

    accuracy                           0.76        87
   macro avg       0.57      0.58      0.57        87
weighted avg       0.75      0.76      0.75        87


Fold 1
[[16  4  0  0]
 [ 8 20  6  0]
 [ 0  4 28  0]
 [ 0  0  1  0]]
              precision    recall  f1-score   support

          A2       0.67      0.80      0.73        20
          B1       0.71      0.59      0.65        34
          B2       0.80      0.88      0.84        32
          C1       0.00      0.00      0.00         1

    accuracy                           0.74        87
   macro avg       0.55      0.57      0.55        87
weighted avg       0.73      0.74      0.73        87


Fold 2
[[11  9  1  0]
 [ 6 25  3  0]
 [ 1  4 26  0]
 [ 0  0  1  0]]
              precision    recall  f1-score   support

          A2       0.61      0.52      0.56        21
          B1       0.66      0.74      0.69        34
          B2       0.84      0.84      0.84        31
          C1       0.00      0.00      0.00         1

    accuracy                           0.71        87
   macro avg       0.53      0.52      0.52        87
weighted avg       0.70      0.71      0.71        87


Fold 3
[[ 0  0  1  0  0]
 [ 0 13  6  1  0]
 [ 0  8 23  2  1]
 [ 0  1  4 26  0]
 [ 0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.59      0.65      0.62        20
          B1       0.68      0.68      0.68        34
          B2       0.87      0.84      0.85        31
          C1       0.00      0.00      0.00         1

    accuracy                           0.71        87
   macro avg       0.43      0.43      0.43        87
weighted avg       0.71      0.71      0.71        87


Fold 4
[[14  5  1  0]
 [ 5 26  3  0]
 [ 0  4 27  0]
 [ 0  0  1  0]]
              precision    recall  f1-score   support

          A2       0.74      0.70      0.72        20
          B1       0.74      0.76      0.75        34
          B2       0.84      0.87      0.86        31
          C1       0.00      0.00      0.00         1

    accuracy                           0.78        86
   macro avg       0.58      0.58      0.58        86
weighted avg       0.77      0.78      0.77        86


K-fold scores
[0.7524106724918084, 0.7267495065878011, 0.7064053443363789, 0.7104273780361965, 0.7738789690255817]
SKF f1 score mean 0.7339743740955533

LogisticRegression(C=1.0, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='multinomial', n_jobs=None,
                   penalty='l2', random_state=1234, solver='lbfgs', tol=0.0001,
                   verbose=0, warm_start=False)
Fold 0
[[15  5  0  0]
 [ 6 24  5  0]
 [ 0  3 28  0]
 [ 0  0  1  0]]
              precision    recall  f1-score   support

          A2       0.71      0.75      0.73        20
          B1       0.75      0.69      0.72        35
          B2       0.82      0.90      0.86        31
          C1       0.00      0.00      0.00         1

    accuracy                           0.77        87
   macro avg       0.57      0.58      0.58        87
weighted avg       0.76      0.77      0.76        87


Fold 1
[[16  4  0  0]
 [ 6 22  6  0]
 [ 0  0 31  1]
 [ 0  0  1  0]]
              precision    recall  f1-score   support

          A2       0.73      0.80      0.76        20
          B1       0.85      0.65      0.73        34
          B2       0.82      0.97      0.89        32
          C1       0.00      0.00      0.00         1

    accuracy                           0.79        87
   macro avg       0.60      0.60      0.60        87
weighted avg       0.80      0.79      0.79        87


Fold 2
[[10 10  1  0]
 [ 5 26  3  0]
 [ 0  4 26  1]
 [ 0  0  1  0]]
              precision    recall  f1-score   support

          A2       0.67      0.48      0.56        21
          B1       0.65      0.76      0.70        34
          B2       0.84      0.84      0.84        31
          C1       0.00      0.00      0.00         1

    accuracy                           0.71        87
   macro avg       0.54      0.52      0.52        87
weighted avg       0.71      0.71      0.71        87


Fold 3
[[ 0  0  1  0  0]
 [ 0 15  4  1  0]
 [ 0  7 24  3  0]
 [ 0  0  4 27  0]
 [ 0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.68      0.75      0.71        20
          B1       0.73      0.71      0.72        34
          B2       0.84      0.87      0.86        31
          C1       0.00      0.00      0.00         1

    accuracy                           0.76        87
   macro avg       0.45      0.47      0.46        87
weighted avg       0.74      0.76      0.75        87


Fold 4
[[15  4  1  0]
 [ 5 27  2  0]
 [ 0  2 28  1]
 [ 0  0  1  0]]
              precision    recall  f1-score   support

          A2       0.75      0.75      0.75        20
          B1       0.82      0.79      0.81        34
          B2       0.88      0.90      0.89        31
          C1       0.00      0.00      0.00         1

    accuracy                           0.81        86
   macro avg       0.61      0.61      0.61        86
weighted avg       0.81      0.81      0.81        86


K-fold scores
[0.7634076495957168, 0.78752052545156, 0.7075696386041214, 0.7496017449697328, 0.8134714026765398]
SKF f1 score mean 0.7643141922595342

************for dimension:  Sociolinguisticappropriateness  ***************
Printing class statistics
Counter({'A1': 261, 'A2': 106, 'B1': 63, 'B2': 4})
RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=300,
                       n_jobs=None, oob_score=False, random_state=1234,
                       verbose=0, warm_start=False)
Fold 0
[[48  4  0  0]
 [ 5 12  5  0]
 [ 2  7  3  0]
 [ 1  0  0  0]]
              precision    recall  f1-score   support

          A1       0.86      0.92      0.89        52
          A2       0.52      0.55      0.53        22
          B1       0.38      0.25      0.30        12
          B2       0.00      0.00      0.00         1

    accuracy                           0.72        87
   macro avg       0.44      0.43      0.43        87
weighted avg       0.70      0.72      0.71        87


Fold 1
[[49  4  0  0]
 [ 2 16  3  0]
 [ 0  9  3  0]
 [ 0  1  0  0]]
              precision    recall  f1-score   support

          A1       0.96      0.92      0.94        53
          A2       0.53      0.76      0.63        21
          B1       0.50      0.25      0.33        12
          B2       0.00      0.00      0.00         1

    accuracy                           0.78        87
   macro avg       0.50      0.48      0.48        87
weighted avg       0.78      0.78      0.77        87


Fold 2
[[49  2  1  0]
 [ 6 13  2  0]
 [ 2 11  0  0]
 [ 0  1  0  0]]
              precision    recall  f1-score   support

          A1       0.86      0.94      0.90        52
          A2       0.48      0.62      0.54        21
          B1       0.00      0.00      0.00        13
          B2       0.00      0.00      0.00         1

    accuracy                           0.71        87
   macro avg       0.34      0.39      0.36        87
weighted avg       0.63      0.71      0.67        87


Fold 3
[[47  5  0  0]
 [ 3 18  0  0]
 [ 1  8  4  0]
 [ 0  1  0  0]]
              precision    recall  f1-score   support

          A1       0.92      0.90      0.91        52
          A2       0.56      0.86      0.68        21
          B1       1.00      0.31      0.47        13
          B2       0.00      0.00      0.00         1

    accuracy                           0.79        87
   macro avg       0.62      0.52      0.52        87
weighted avg       0.84      0.79      0.78        87


Fold 4
[[52  0  0]
 [ 5 15  1]
 [ 2  9  2]]
              precision    recall  f1-score   support

          A1       0.88      1.00      0.94        52
          A2       0.62      0.71      0.67        21
          B1       0.67      0.15      0.25        13

    accuracy                           0.80        86
   macro avg       0.72      0.62      0.62        86
weighted avg       0.79      0.80      0.77        86


K-fold scores
[0.7075351213282248, 0.7714802101211837, 0.6681298112411683, 0.7797483756532345, 0.7671014037293107]
SKF f1 score mean 0.7387989844146243

LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
          verbose=0)
Fold 0
[[48  3  1  0]
 [ 1 13  8  0]
 [ 0  7  5  0]
 [ 0  1  0  0]]
              precision    recall  f1-score   support

          A1       0.98      0.92      0.95        52
          A2       0.54      0.59      0.57        22
          B1       0.36      0.42      0.38        12
          B2       0.00      0.00      0.00         1

    accuracy                           0.76        87
   macro avg       0.47      0.48      0.48        87
weighted avg       0.77      0.76      0.76        87


Fold 1
[[49  1  3  0]
 [ 2 11  8  0]
 [ 0  5  7  0]
 [ 1  0  0  0]]
              precision    recall  f1-score   support

          A1       0.94      0.92      0.93        53
          A2       0.65      0.52      0.58        21
          B1       0.39      0.58      0.47        12
          B2       0.00      0.00      0.00         1

    accuracy                           0.77        87
   macro avg       0.49      0.51      0.49        87
weighted avg       0.78      0.77      0.77        87


Fold 2
[[48  4  0  0]
 [ 2 13  6  0]
 [ 1  7  5  0]
 [ 0  1  0  0]]
              precision    recall  f1-score   support

          A1       0.94      0.92      0.93        52
          A2       0.52      0.62      0.57        21
          B1       0.45      0.38      0.42        13
          B2       0.00      0.00      0.00         1

    accuracy                           0.76        87
   macro avg       0.48      0.48      0.48        87
weighted avg       0.76      0.76      0.76        87


Fold 3
[[45  6  1  0]
 [ 0 14  7  0]
 [ 0  6  7  0]
 [ 1  0  0  0]]
              precision    recall  f1-score   support

          A1       0.98      0.87      0.92        52
          A2       0.54      0.67      0.60        21
          B1       0.47      0.54      0.50        13
          B2       0.00      0.00      0.00         1

    accuracy                           0.76        87
   macro avg       0.50      0.52      0.50        87
weighted avg       0.78      0.76      0.77        87


Fold 4
[[52  0  0]
 [ 5 12  4]
 [ 0  6  7]]
              precision    recall  f1-score   support

          A1       0.91      1.00      0.95        52
          A2       0.67      0.57      0.62        21
          B1       0.64      0.54      0.58        13

    accuracy                           0.83        86
   macro avg       0.74      0.70      0.72        86
weighted avg       0.81      0.83      0.82        86


K-fold scores
[0.7640909172222724, 0.7726961080863077, 0.7557730034659046, 0.7674223027435478, 0.8153615018080559]
SKF f1 score mean 0.7750687666652176

LogisticRegression(C=1.0, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='multinomial', n_jobs=None,
                   penalty='l2', random_state=1234, solver='lbfgs', tol=0.0001,
                   verbose=0, warm_start=False)
Fold 0
[[47  3  2  0]
 [ 0 14  8  0]
 [ 0  6  6  0]
 [ 0  1  0  0]]
              precision    recall  f1-score   support

          A1       1.00      0.90      0.95        52
          A2       0.58      0.64      0.61        22
          B1       0.38      0.50      0.43        12
          B2       0.00      0.00      0.00         1

    accuracy                           0.77        87
   macro avg       0.49      0.51      0.50        87
weighted avg       0.80      0.77      0.78        87


Fold 1
[[49  1  3  0]
 [ 0 14  7  0]
 [ 0  3  9  0]
 [ 0  0  1  0]]
              precision    recall  f1-score   support

          A1       1.00      0.92      0.96        53
          A2       0.78      0.67      0.72        21
          B1       0.45      0.75      0.56        12
          B2       0.00      0.00      0.00         1

    accuracy                           0.83        87
   macro avg       0.56      0.59      0.56        87
weighted avg       0.86      0.83      0.84        87


Fold 2
[[48  3  1  0]
 [ 2 13  6  0]
 [ 1  8  4  0]
 [ 0  1  0  0]]
              precision    recall  f1-score   support

          A1       0.94      0.92      0.93        52
          A2       0.52      0.62      0.57        21
          B1       0.36      0.31      0.33        13
          B2       0.00      0.00      0.00         1

    accuracy                           0.75        87
   macro avg       0.46      0.46      0.46        87
weighted avg       0.74      0.75      0.74        87


Fold 3
[[46  4  1  1]
 [ 0 14  7  0]
 [ 0  6  7  0]
 [ 0  0  1  0]]
              precision    recall  f1-score   support

          A1       1.00      0.88      0.94        52
          A2       0.58      0.67      0.62        21
          B1       0.44      0.54      0.48        13
          B2       0.00      0.00      0.00         1

    accuracy                           0.77        87
   macro avg       0.51      0.52      0.51        87
weighted avg       0.80      0.77      0.78        87


Fold 4
[[52  0  0]
 [ 2 14  4]
 [ 0  7  6]]
              precision    recall  f1-score   support

          A1       0.96      1.00      0.98        52
          A2       0.67      0.67      0.67        21
          B1       0.60      0.46      0.52        13
          B2       0.00      0.00      0.00         0

    accuracy                           0.84        86
   macro avg       0.56      0.53      0.54        86
weighted avg       0.84      0.84      0.83        86


K-fold scores
[0.7805505616600069, 0.8361895598203916, 0.743320896186211, 0.7834351180028095, 0.8349008909323312]
SKF f1 score mean 0.7956794053203501

DOING MULTILANG CLASSIFICATION
768
768
768
************for dimension:  OverallCEFRrating  ***************
RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=300,
                       n_jobs=None, oob_score=False, random_state=1234,
                       verbose=0, warm_start=False)
Fold 0
[[  0  16   1   0   0]
 [  0 148  27   0   0]
 [  0  50 118   9   0]
 [  0   3  25  47   0]
 [  0   0   0   8   0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        17
          A2       0.68      0.85      0.76       175
          B1       0.69      0.67      0.68       177
          B2       0.73      0.63      0.68        75
          C1       0.00      0.00      0.00         8

    accuracy                           0.69       452
   macro avg       0.42      0.43      0.42       452
weighted avg       0.66      0.69      0.67       452


Fold 1
[[  0  16   1   0   0]
 [  0 135  40   0   0]
 [  0  41 112  24   0]
 [  0   1  16  58   0]
 [  0   0   1   7   0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        17
          A2       0.70      0.77      0.73       175
          B1       0.66      0.63      0.65       177
          B2       0.65      0.77      0.71        75
          C1       0.00      0.00      0.00         8

    accuracy                           0.67       452
   macro avg       0.40      0.44      0.42       452
weighted avg       0.64      0.67      0.65       452


Fold 2
[[  0  16   1   0   0]
 [  0 148  27   0   0]
 [  0  48 114  15   0]
 [  0   0  18  57   0]
 [  0   0   0   8   0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        17
          A2       0.70      0.85      0.76       175
          B1       0.71      0.64      0.68       177
          B2       0.71      0.76      0.74        75
          C1       0.00      0.00      0.00         8

    accuracy                           0.71       452
   macro avg       0.42      0.45      0.44       452
weighted avg       0.67      0.71      0.68       452


Fold 3
[[  0  15   2   0   0]
 [  0 144  30   0   0]
 [  0  39 127  11   0]
 [  0   1  28  46   0]
 [  0   0   1   8   0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        17
          A2       0.72      0.83      0.77       174
          B1       0.68      0.72      0.70       177
          B2       0.71      0.61      0.66        75
          C1       0.00      0.00      0.00         9

    accuracy                           0.70       452
   macro avg       0.42      0.43      0.43       452
weighted avg       0.66      0.70      0.68       452


Fold 4
[[  0  17   0   0   0]
 [  0 143  32   0   0]
 [  0  49 110  18   0]
 [  0   1  21  52   0]
 [  0   0   0   9   0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        17
          A2       0.68      0.82      0.74       175
          B1       0.67      0.62      0.65       177
          B2       0.66      0.70      0.68        74
          C1       0.00      0.00      0.00         9

    accuracy                           0.67       452
   macro avg       0.40      0.43      0.41       452
weighted avg       0.64      0.67      0.65       452


K-fold scores
[0.6701255848714812, 0.6542143487001681, 0.6831021269055523, 0.6787762002093124, 0.6522789056625601]
SKF f1 score mean 0.6676994332698147

LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
          verbose=0)
Fold 0
[[  4  11   2   0   0]
 [  9 137  25   4   0]
 [  2  38 120  16   1]
 [  0   2  22  49   2]
 [  0   0   0   4   4]]
              precision    recall  f1-score   support

          A1       0.27      0.24      0.25        17
          A2       0.73      0.78      0.75       175
          B1       0.71      0.68      0.69       177
          B2       0.67      0.65      0.66        75
          C1       0.57      0.50      0.53         8

    accuracy                           0.69       452
   macro avg       0.59      0.57      0.58       452
weighted avg       0.69      0.69      0.69       452


Fold 1
[[  7   9   0   0   1]
 [ 15 112  45   3   0]
 [  1  37 110  29   0]
 [  0   1  20  50   4]
 [  0   0   0   6   2]]
              precision    recall  f1-score   support

          A1       0.30      0.41      0.35        17
          A2       0.70      0.64      0.67       175
          B1       0.63      0.62      0.62       177
          B2       0.57      0.67      0.61        75
          C1       0.29      0.25      0.27         8

    accuracy                           0.62       452
   macro avg       0.50      0.52      0.51       452
weighted avg       0.63      0.62      0.62       452


Fold 2
[[  6  11   0   0   0]
 [  6 134  34   1   0]
 [  1  37 113  23   3]
 [  0   0  14  58   3]
 [  0   0   0   4   4]]
              precision    recall  f1-score   support

          A1       0.46      0.35      0.40        17
          A2       0.74      0.77      0.75       175
          B1       0.70      0.64      0.67       177
          B2       0.67      0.77      0.72        75
          C1       0.40      0.50      0.44         8

    accuracy                           0.70       452
   macro avg       0.59      0.61      0.60       452
weighted avg       0.70      0.70      0.69       452


Fold 3
[[  5  11   1   0   0]
 [ 14 124  35   1   0]
 [  1  41 120  15   0]
 [  0   3  14  57   1]
 [  0   0   0   8   1]]
              precision    recall  f1-score   support

          A1       0.25      0.29      0.27        17
          A2       0.69      0.71      0.70       174
          B1       0.71      0.68      0.69       177
          B2       0.70      0.76      0.73        75
          C1       0.50      0.11      0.18         9

    accuracy                           0.68       452
   macro avg       0.57      0.51      0.52       452
weighted avg       0.68      0.68      0.68       452


Fold 4
[[  6  11   0   0   0]
 [  4 141  30   0   0]
 [  0  41 114  22   0]
 [  1   2  12  55   4]
 [  0   0   0   8   1]]
              precision    recall  f1-score   support

          A1       0.55      0.35      0.43        17
          A2       0.72      0.81      0.76       175
          B1       0.73      0.64      0.68       177
          B2       0.65      0.74      0.69        74
          C1       0.20      0.11      0.14         9

    accuracy                           0.70       452
   macro avg       0.57      0.53      0.54       452
weighted avg       0.70      0.70      0.70       452


K-fold scores
[0.692581989412971, 0.6240837892324369, 0.6949435488538589, 0.6763341280542309, 0.6954291254257859]
SKF f1 score mean 0.6766745161958567

LogisticRegression(C=1.0, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='multinomial', n_jobs=None,
                   penalty='l2', random_state=1234, solver='lbfgs', tol=0.0001,
                   verbose=0, warm_start=False)
Fold 0
[[  9   6   2   0   0]
 [ 19 132  23   1   0]
 [  0  37 126  13   1]
 [  0   2  15  53   5]
 [  0   0   0   3   5]]
              precision    recall  f1-score   support

          A1       0.32      0.53      0.40        17
          A2       0.75      0.75      0.75       175
          B1       0.76      0.71      0.73       177
          B2       0.76      0.71      0.73        75
          C1       0.45      0.62      0.53         8

    accuracy                           0.72       452
   macro avg       0.61      0.67      0.63       452
weighted avg       0.73      0.72      0.72       452


Fold 1
[[  8   9   0   0   0]
 [ 18 113  41   3   0]
 [  4  24 111  38   0]
 [  0   1   8  60   6]
 [  0   0   0   5   3]]
              precision    recall  f1-score   support

          A1       0.27      0.47      0.34        17
          A2       0.77      0.65      0.70       175
          B1       0.69      0.63      0.66       177
          B2       0.57      0.80      0.66        75
          C1       0.33      0.38      0.35         8

    accuracy                           0.65       452
   macro avg       0.53      0.58      0.54       452
weighted avg       0.68      0.65      0.66       452


Fold 2
[[  8   9   0   0   0]
 [ 15 133  27   0   0]
 [  3  35 115  21   3]
 [  0   0   9  59   7]
 [  0   0   0   5   3]]
              precision    recall  f1-score   support

          A1       0.31      0.47      0.37        17
          A2       0.75      0.76      0.76       175
          B1       0.76      0.65      0.70       177
          B2       0.69      0.79      0.74        75
          C1       0.23      0.38      0.29         8

    accuracy                           0.70       452
   macro avg       0.55      0.61      0.57       452
weighted avg       0.72      0.70      0.71       452


Fold 3
[[  9   8   0   0   0]
 [ 18 123  32   1   0]
 [  0  44 117  16   0]
 [  0   0   9  63   3]
 [  0   0   0   4   5]]
              precision    recall  f1-score   support

          A1       0.33      0.53      0.41        17
          A2       0.70      0.71      0.70       174
          B1       0.74      0.66      0.70       177
          B2       0.75      0.84      0.79        75
          C1       0.62      0.56      0.59         9

    accuracy                           0.70       452
   macro avg       0.63      0.66      0.64       452
weighted avg       0.71      0.70      0.70       452


Fold 4
[[  9   8   0   0   0]
 [ 13 138  24   0   0]
 [  1  40 111  25   0]
 [  0   1  10  56   7]
 [  0   0   0   4   5]]
              precision    recall  f1-score   support

          A1       0.39      0.53      0.45        17
          A2       0.74      0.79      0.76       175
          B1       0.77      0.63      0.69       177
          B2       0.66      0.76      0.70        74
          C1       0.42      0.56      0.48         9

    accuracy                           0.71       452
   macro avg       0.59      0.65      0.62       452
weighted avg       0.72      0.71      0.71       452


K-fold scores
[0.7237365682504795, 0.65876109257767, 0.7085928484987123, 0.7034646255114861, 0.7068981652975626]
SKF f1 score mean 0.7002906600271821

************for dimension:  Grammaticalaccuracy  ***************
RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=300,
                       n_jobs=None, oob_score=False, random_state=1234,
                       verbose=0, warm_start=False)
Fold 0
[[  1  27   5   0   0]
 [  1  87  53   1   0]
 [  1  46 111  18   0]
 [  0   4  40  46   0]
 [  0   0   2   9   0]]
              precision    recall  f1-score   support

          A1       0.33      0.03      0.06        33
          A2       0.53      0.61      0.57       142
          B1       0.53      0.63      0.57       176
          B2       0.62      0.51      0.56        90
          C1       0.00      0.00      0.00        11

    accuracy                           0.54       452
   macro avg       0.40      0.36      0.35       452
weighted avg       0.52      0.54      0.52       452


Fold 1
[[  0  25   8   0   0]
 [  1  78  61   2   0]
 [  0  38 124  14   0]
 [  0   6  34  50   0]
 [  0   0   0  11   0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        33
          A2       0.53      0.55      0.54       142
          B1       0.55      0.70      0.62       176
          B2       0.65      0.56      0.60        90
          C1       0.00      0.00      0.00        11

    accuracy                           0.56       452
   macro avg       0.35      0.36      0.35       452
weighted avg       0.51      0.56      0.53       452


Fold 2
[[  1  26   6   0   0]
 [  0  93  48   1   0]
 [  0  37 114  25   0]
 [  0   1  41  49   0]
 [  0   0   2   8   0]]
              precision    recall  f1-score   support

          A1       1.00      0.03      0.06        33
          A2       0.59      0.65      0.62       142
          B1       0.54      0.65      0.59       176
          B2       0.59      0.54      0.56        91
          C1       0.00      0.00      0.00        10

    accuracy                           0.57       452
   macro avg       0.54      0.37      0.37       452
weighted avg       0.59      0.57      0.54       452


Fold 3
[[  0  28   5   0   0]
 [  1  76  62   4   0]
 [  0  43 113  20   0]
 [  0   3  47  40   0]
 [  0   0   5   5   0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        33
          A2       0.51      0.53      0.52       143
          B1       0.49      0.64      0.55       176
          B2       0.58      0.44      0.50        90
          C1       0.00      0.00      0.00        10

    accuracy                           0.51       452
   macro avg       0.31      0.32      0.32       452
weighted avg       0.47      0.51      0.48       452


Fold 4
[[  0  26   7   0   0]
 [  0  77  64   1   0]
 [  0  58 110   9   0]
 [  0   6  42  42   0]
 [  0   0   2   8   0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        33
          A2       0.46      0.54      0.50       142
          B1       0.49      0.62      0.55       177
          B2       0.70      0.47      0.56        90
          C1       0.00      0.00      0.00        10

    accuracy                           0.51       452
   macro avg       0.33      0.33      0.32       452
weighted avg       0.48      0.51      0.48       452


K-fold scores
[0.5177599038952994, 0.5284301480258772, 0.5425186298118626, 0.4799945028487894, 0.4823803057057697]
SKF f1 score mean 0.5102166980575196

LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
          verbose=0)
Fold 0
[[12 18  3  0  0]
 [24 75 37  5  1]
 [10 54 75 36  1]
 [ 0 12 22 50  6]
 [ 1  0  0  9  1]]
              precision    recall  f1-score   support

          A1       0.26      0.36      0.30        33
          A2       0.47      0.53      0.50       142
          B1       0.55      0.43      0.48       176
          B2       0.50      0.56      0.53        90
          C1       0.11      0.09      0.10        11

    accuracy                           0.47       452
   macro avg       0.38      0.39      0.38       452
weighted avg       0.48      0.47      0.47       452


Fold 1
[[12 18  3  0  0]
 [20 70 45  6  1]
 [ 7 42 96 31  0]
 [ 0  5 28 56  1]
 [ 0  0  1  7  3]]
              precision    recall  f1-score   support

          A1       0.31      0.36      0.33        33
          A2       0.52      0.49      0.51       142
          B1       0.55      0.55      0.55       176
          B2       0.56      0.62      0.59        90
          C1       0.60      0.27      0.37        11

    accuracy                           0.52       452
   macro avg       0.51      0.46      0.47       452
weighted avg       0.53      0.52      0.52       452


Fold 2
[[ 9 21  2  1  0]
 [23 80 31  8  0]
 [ 7 51 77 41  0]
 [ 1  1 33 52  4]
 [ 0  0  2  8  0]]
              precision    recall  f1-score   support

          A1       0.23      0.27      0.25        33
          A2       0.52      0.56      0.54       142
          B1       0.53      0.44      0.48       176
          B2       0.47      0.57      0.52        91
          C1       0.00      0.00      0.00        10

    accuracy                           0.48       452
   macro avg       0.35      0.37      0.36       452
weighted avg       0.48      0.48      0.48       452


Fold 3
[[11 17  5  0  0]
 [16 75 44  8  0]
 [ 5 38 87 46  0]
 [ 0  3 25 58  4]
 [ 0  0  1  8  1]]
              precision    recall  f1-score   support

          A1       0.34      0.33      0.34        33
          A2       0.56      0.52      0.54       143
          B1       0.54      0.49      0.51       176
          B2       0.48      0.64      0.55        90
          C1       0.20      0.10      0.13        10

    accuracy                           0.51       452
   macro avg       0.43      0.42      0.42       452
weighted avg       0.51      0.51      0.51       452


Fold 4
[[13 16  4  0  0]
 [14 76 43  8  1]
 [12 47 91 26  1]
 [ 1  8 39 40  2]
 [ 0  0  1  6  3]]
              precision    recall  f1-score   support

          A1       0.33      0.39      0.36        33
          A2       0.52      0.54      0.53       142
          B1       0.51      0.51      0.51       177
          B2       0.50      0.44      0.47        90
          C1       0.43      0.30      0.35        10

    accuracy                           0.49       452
   macro avg       0.46      0.44      0.44       452
weighted avg       0.50      0.49      0.49       452


K-fold scores
[0.47229554994974154, 0.5238314149275507, 0.4793686938937858, 0.5100393615421586, 0.49350566521638967]
SKF f1 score mean 0.49580813710592525

LogisticRegression(C=1.0, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='multinomial', n_jobs=None,
                   penalty='l2', random_state=1234, solver='lbfgs', tol=0.0001,
                   verbose=0, warm_start=False)
Fold 0
[[18 14  1  0  0]
 [27 78 31  6  0]
 [ 8 56 71 41  0]
 [ 0  8 18 57  7]
 [ 0  0  0  8  3]]
              precision    recall  f1-score   support

          A1       0.34      0.55      0.42        33
          A2       0.50      0.55      0.52       142
          B1       0.59      0.40      0.48       176
          B2       0.51      0.63      0.56        90
          C1       0.30      0.27      0.29        11

    accuracy                           0.50       452
   macro avg       0.45      0.48      0.45       452
weighted avg       0.52      0.50      0.50       452


Fold 1
[[16 15  2  0  0]
 [33 71 34  4  0]
 [ 7 43 84 40  2]
 [ 0  4 26 53  7]
 [ 0  0  1  6  4]]
              precision    recall  f1-score   support

          A1       0.29      0.48      0.36        33
          A2       0.53      0.50      0.52       142
          B1       0.57      0.48      0.52       176
          B2       0.51      0.59      0.55        90
          C1       0.31      0.36      0.33        11

    accuracy                           0.50       452
   macro avg       0.44      0.48      0.46       452
weighted avg       0.52      0.50      0.51       452


Fold 2
[[15 14  4  0  0]
 [28 87 24  3  0]
 [12 45 74 43  2]
 [ 0  2 26 55  8]
 [ 0  0  1  7  2]]
              precision    recall  f1-score   support

          A1       0.27      0.45      0.34        33
          A2       0.59      0.61      0.60       142
          B1       0.57      0.42      0.49       176
          B2       0.51      0.60      0.55        91
          C1       0.17      0.20      0.18        10

    accuracy                           0.52       452
   macro avg       0.42      0.46      0.43       452
weighted avg       0.53      0.52      0.52       452


Fold 3
[[14 18  1  0  0]
 [24 80 32  7  0]
 [10 40 81 43  2]
 [ 0  3 21 60  6]
 [ 0  0  1  6  3]]
              precision    recall  f1-score   support

          A1       0.29      0.42      0.35        33
          A2       0.57      0.56      0.56       143
          B1       0.60      0.46      0.52       176
          B2       0.52      0.67      0.58        90
          C1       0.27      0.30      0.29        10

    accuracy                           0.53       452
   macro avg       0.45      0.48      0.46       452
weighted avg       0.54      0.53      0.53       452


Fold 4
[[15 16  2  0  0]
 [25 80 33  4  0]
 [16 55 80 25  1]
 [ 0  7 31 48  4]
 [ 0  0  0  7  3]]
              precision    recall  f1-score   support

          A1       0.27      0.45      0.34        33
          A2       0.51      0.56      0.53       142
          B1       0.55      0.45      0.50       177
          B2       0.57      0.53      0.55        90
          C1       0.38      0.30      0.33        10

    accuracy                           0.50       452
   macro avg       0.45      0.46      0.45       452
weighted avg       0.52      0.50      0.50       452


K-fold scores
[0.5005146204803027, 0.5084675200193254, 0.517639309832732, 0.5279640053028212, 0.5033704715971884]
SKF f1 score mean 0.5115911854464739

************for dimension:  Orthography  ***************
RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=300,
                       n_jobs=None, oob_score=False, random_state=1234,
                       verbose=0, warm_start=False)
Fold 0
[[  0   0   8   0   0   0]
 [  0   7  57   2   2   0]
 [  0   3 135  20   4   0]
 [  0   0  41  56   9   0]
 [  0   1  12  26  47   0]
 [  0   0   1   8  13   0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         8
          A2       0.64      0.10      0.18        68
          B1       0.53      0.83      0.65       162
          B2       0.50      0.53      0.51       106
          C1       0.63      0.55      0.58        86
          C2       0.00      0.00      0.00        22

    accuracy                           0.54       452
   macro avg       0.38      0.34      0.32       452
weighted avg       0.52      0.54      0.49       452


Fold 1
[[  0   3   5   0   0   0]
 [  0   6  60   1   0   0]
 [  0   6 149   7   0   0]
 [  0   0  43  46  17   0]
 [  0   0  18  21  47   0]
 [  0   0   8   5  10   0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         8
          A2       0.40      0.09      0.15        67
          B1       0.53      0.92      0.67       162
          B2       0.57      0.43      0.49       106
          C1       0.64      0.55      0.59        86
          C2       0.00      0.00      0.00        23

    accuracy                           0.55       452
   macro avg       0.36      0.33      0.32       452
weighted avg       0.50      0.55      0.49       452


Fold 2
[[  0   0   8   0   0   0]
 [  0   6  61   0   1   0]
 [  0   6 137  15   4   0]
 [  0   0  44  50  11   0]
 [  0   2  14  25  45   0]
 [  0   0   5   5  13   0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         8
          A2       0.43      0.09      0.15        68
          B1       0.51      0.85      0.64       162
          B2       0.53      0.48      0.50       105
          C1       0.61      0.52      0.56        86
          C2       0.00      0.00      0.00        23

    accuracy                           0.53       452
   macro avg       0.35      0.32      0.31       452
weighted avg       0.48      0.53      0.47       452


Fold 3
[[  0   2   6   0   0   0]
 [  0   4  64   0   0   0]
 [  0   4 141  16   1   0]
 [  0   0  36  45  25   0]
 [  0   0  20  25  40   0]
 [  0   1   5   8   9   0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         8
          A2       0.36      0.06      0.10        68
          B1       0.52      0.87      0.65       162
          B2       0.48      0.42      0.45       106
          C1       0.53      0.47      0.50        85
          C2       0.00      0.00      0.00        23

    accuracy                           0.51       452
   macro avg       0.32      0.30      0.28       452
weighted avg       0.45      0.51      0.45       452


Fold 4
[[  0   1   7   0   0   0]
 [  0   7  58   0   3   0]
 [  0   3 135  21   3   0]
 [  0   3  51  44   8   0]
 [  0   0  14  33  38   0]
 [  0   0  11   7   5   0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         8
          A2       0.50      0.10      0.17        68
          B1       0.49      0.83      0.62       162
          B2       0.42      0.42      0.42       106
          C1       0.67      0.45      0.54        85
          C2       0.00      0.00      0.00        23

    accuracy                           0.50       452
   macro avg       0.35      0.30      0.29       452
weighted avg       0.47      0.50      0.45       452


K-fold scores
[0.4908512376132236, 0.48948092662409115, 0.4730411915577895, 0.44767422292129866, 0.4450757928061]
SKF f1 score mean 0.4692246743045006

LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
          verbose=0)
Fold 0
[[ 1  5  1  1  0  0]
 [ 5 25 22  8  5  3]
 [ 3 34 79 28  8 10]
 [ 1  6 34 41 18  6]
 [ 0  2  3 17 49 15]
 [ 0  0  1  6 13  2]]
              precision    recall  f1-score   support

          A1       0.10      0.12      0.11         8
          A2       0.35      0.37      0.36        68
          B1       0.56      0.49      0.52       162
          B2       0.41      0.39      0.40       106
          C1       0.53      0.57      0.55        86
          C2       0.06      0.09      0.07        22

    accuracy                           0.44       452
   macro avg       0.33      0.34      0.33       452
weighted avg       0.45      0.44      0.44       452


Fold 1
[[ 1  5  2  0  0  0]
 [ 3 28 29  7  0  0]
 [ 1 35 86 31  7  2]
 [ 1  3 35 31 19 17]
 [ 0  3  5 19 45 14]
 [ 0  2  4  1 13  3]]
              precision    recall  f1-score   support

          A1       0.17      0.12      0.14         8
          A2       0.37      0.42      0.39        67
          B1       0.53      0.53      0.53       162
          B2       0.35      0.29      0.32       106
          C1       0.54      0.52      0.53        86
          C2       0.08      0.13      0.10        23

    accuracy                           0.43       452
   macro avg       0.34      0.34      0.34       452
weighted avg       0.44      0.43      0.43       452


Fold 2
[[ 1  2  4  1  0  0]
 [ 3 32 27  2  3  1]
 [ 2 36 85 30  5  4]
 [ 0  4 25 44 24  8]
 [ 0  3  6 21 47  9]
 [ 0  0  2  3 13  5]]
              precision    recall  f1-score   support

          A1       0.17      0.12      0.14         8
          A2       0.42      0.47      0.44        68
          B1       0.57      0.52      0.55       162
          B2       0.44      0.42      0.43       105
          C1       0.51      0.55      0.53        86
          C2       0.19      0.22      0.20        23

    accuracy                           0.47       452
   macro avg       0.38      0.38      0.38       452
weighted avg       0.48      0.47      0.47       452


Fold 3
[[ 1  5  1  0  0  1]
 [ 4 26 30  4  4  0]
 [ 1 39 85 28  6  3]
 [ 0 12 21 39 26  8]
 [ 0  2  2 16 50 15]
 [ 0  2  1  5 13  2]]
              precision    recall  f1-score   support

          A1       0.17      0.12      0.14         8
          A2       0.30      0.38      0.34        68
          B1       0.61      0.52      0.56       162
          B2       0.42      0.37      0.39       106
          C1       0.51      0.59      0.54        85
          C2       0.07      0.09      0.08        23

    accuracy                           0.45       452
   macro avg       0.35      0.35      0.34       452
weighted avg       0.46      0.45      0.45       452


Fold 4
[[ 2  5  1  0  0  0]
 [ 2 25 36  3  1  1]
 [ 1 33 84 34  9  1]
 [ 2 10 31 47 11  5]
 [ 0  3  6 27 39 10]
 [ 0  0  5  6  9  3]]
              precision    recall  f1-score   support

          A1       0.29      0.25      0.27         8
          A2       0.33      0.37      0.35        68
          B1       0.52      0.52      0.52       162
          B2       0.40      0.44      0.42       106
          C1       0.57      0.46      0.51        85
          C2       0.15      0.13      0.14        23

    accuracy                           0.44       452
   macro avg       0.37      0.36      0.37       452
weighted avg       0.45      0.44      0.44       452


K-fold scores
[0.44363041700943256, 0.43189785878032266, 0.47473408003938566, 0.45358054819634536, 0.4434266540559473]
SKF f1 score mean 0.4494539116162867

LogisticRegression(C=1.0, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='multinomial', n_jobs=None,
                   penalty='l2', random_state=1234, solver='lbfgs', tol=0.0001,
                   verbose=0, warm_start=False)
Fold 0
[[ 1  4  3  0  0  0]
 [ 9 36 14  3  2  4]
 [ 3 41 74 30  7  7]
 [ 0  4 24 50 21  7]
 [ 0  1  3 13 47 22]
 [ 0  0  1  4 12  5]]
              precision    recall  f1-score   support

          A1       0.08      0.12      0.10         8
          A2       0.42      0.53      0.47        68
          B1       0.62      0.46      0.53       162
          B2       0.50      0.47      0.49       106
          C1       0.53      0.55      0.54        86
          C2       0.11      0.23      0.15        22

    accuracy                           0.47       452
   macro avg       0.38      0.39      0.38       452
weighted avg       0.51      0.47      0.48       452


Fold 1
[[ 1  6  1  0  0  0]
 [ 3 32 26  5  0  1]
 [ 5 40 81 32  3  1]
 [ 2  5 24 46 17 12]
 [ 0  6  3 15 45 17]
 [ 0  2  2  2 11  6]]
              precision    recall  f1-score   support

          A1       0.09      0.12      0.11         8
          A2       0.35      0.48      0.41        67
          B1       0.59      0.50      0.54       162
          B2       0.46      0.43      0.45       106
          C1       0.59      0.52      0.56        86
          C2       0.16      0.26      0.20        23

    accuracy                           0.47       452
   macro avg       0.37      0.39      0.38       452
weighted avg       0.49      0.47      0.48       452


Fold 2
[[ 1  4  2  1  0  0]
 [ 4 41 20  1  2  0]
 [ 4 44 75 29  5  5]
 [ 0  3 25 48 21  8]
 [ 0  3  2 17 48 16]
 [ 0  1  1  3 14  4]]
              precision    recall  f1-score   support

          A1       0.11      0.12      0.12         8
          A2       0.43      0.60      0.50        68
          B1       0.60      0.46      0.52       162
          B2       0.48      0.46      0.47       105
          C1       0.53      0.56      0.55        86
          C2       0.12      0.17      0.14        23

    accuracy                           0.48       452
   macro avg       0.38      0.40      0.38       452
weighted avg       0.50      0.48      0.48       452


Fold 3
[[ 0  7  0  0  0  1]
 [ 4 35 23  3  1  2]
 [ 1 41 74 35  4  7]
 [ 0  9 15 39 25 18]
 [ 0  2  1 11 51 20]
 [ 0  2  2  4 11  4]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         8
          A2       0.36      0.51      0.43        68
          B1       0.64      0.46      0.53       162
          B2       0.42      0.37      0.39       106
          C1       0.55      0.60      0.58        85
          C2       0.08      0.17      0.11        23

    accuracy                           0.45       452
   macro avg       0.34      0.35      0.34       452
weighted avg       0.49      0.45      0.46       452


Fold 4
[[ 3  5  0  0  0  0]
 [ 8 34 20  3  1  2]
 [ 1 44 75 32  4  6]
 [ 1 10 26 52 10  7]
 [ 0  5  3 24 42 11]
 [ 0  3  1  4 10  5]]
              precision    recall  f1-score   support

          A1       0.23      0.38      0.29         8
          A2       0.34      0.50      0.40        68
          B1       0.60      0.46      0.52       162
          B2       0.45      0.49      0.47       106
          C1       0.63      0.49      0.55        85
          C2       0.16      0.22      0.19        23

    accuracy                           0.47       452
   macro avg       0.40      0.42      0.40       452
weighted avg       0.50      0.47      0.48       452


K-fold scores
[0.4840976425971952, 0.47670686863571593, 0.48499277858034096, 0.4618900594269238, 0.47661713935680716]
SKF f1 score mean 0.4768608977193966

************for dimension:  Vocabularyrange  ***************
RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=300,
                       n_jobs=None, oob_score=False, random_state=1234,
                       verbose=0, warm_start=False)
Fold 0
[[  0  10   9   0   0   0]
 [  0  65  50   3   0   0]
 [  0  13 130  20   0   0]
 [  0   0  24  91   6   0]
 [  0   1   3  12  14   0]
 [  0   0   0   0   1   0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        19
          A2       0.73      0.55      0.63       118
          B1       0.60      0.80      0.69       163
          B2       0.72      0.75      0.74       121
          C1       0.67      0.47      0.55        30
          C2       0.00      0.00      0.00         1

    accuracy                           0.66       452
   macro avg       0.45      0.43      0.43       452
weighted avg       0.65      0.66      0.65       452


Fold 1
[[  0   9  10   0   0   0]
 [  0  50  64   4   0   0]
 [  0  19 125  19   0   0]
 [  0   1  27  80  13   0]
 [  0   0   1  16  13   0]
 [  0   0   0   0   1   0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        19
          A2       0.63      0.42      0.51       118
          B1       0.55      0.77      0.64       163
          B2       0.67      0.66      0.67       121
          C1       0.48      0.43      0.46        30
          C2       0.00      0.00      0.00         1

    accuracy                           0.59       452
   macro avg       0.39      0.38      0.38       452
weighted avg       0.58      0.59      0.57       452


Fold 2
[[  0  11   8   0   0   0]
 [  0  66  50   2   0   0]
 [  0  31 114  19   0   0]
 [  0   1  20  93   6   0]
 [  0   0   1  15  14   0]
 [  0   0   0   0   1   0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        19
          A2       0.61      0.56      0.58       118
          B1       0.59      0.70      0.64       164
          B2       0.72      0.78      0.75       120
          C1       0.67      0.47      0.55        30
          C2       0.00      0.00      0.00         1

    accuracy                           0.63       452
   macro avg       0.43      0.42      0.42       452
weighted avg       0.61      0.63      0.62       452


Fold 3
[[  0  12   8   0   0   0]
 [  0  65  51   1   0   0]
 [  0  24 123  17   0   0]
 [  0   0  21  90   9   0]
 [  0   0   1  13  16   0]
 [  0   0   0   0   1   0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        20
          A2       0.64      0.56      0.60       117
          B1       0.60      0.75      0.67       164
          B2       0.74      0.75      0.75       120
          C1       0.62      0.53      0.57        30
          C2       0.00      0.00      0.00         1

    accuracy                           0.65       452
   macro avg       0.43      0.43      0.43       452
weighted avg       0.62      0.65      0.63       452


Fold 4
[[  0  11   9   0   0   0]
 [  0  56  60   1   0   0]
 [  0  27 119  18   0   0]
 [  0   1  18  99   2   0]
 [  0   0   1  18  11   0]
 [  0   0   0   1   0   0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        20
          A2       0.59      0.48      0.53       117
          B1       0.57      0.73      0.64       164
          B2       0.72      0.82      0.77       120
          C1       0.85      0.37      0.51        30
          C2       0.00      0.00      0.00         1

    accuracy                           0.63       452
   macro avg       0.46      0.40      0.41       452
weighted avg       0.61      0.63      0.61       452


K-fold scores
[0.6450339461068739, 0.5724259598175273, 0.6182862352623599, 0.6331205534157041, 0.6080067854016259]
SKF f1 score mean 0.6153746960008182

LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
          verbose=0)
Fold 0
[[  5  10   3   1   0   0]
 [ 13  69  35   0   1   0]
 [  4  31 100  26   2   0]
 [  0   1  23  88   7   2]
 [  0   0   3  12  15   0]
 [  0   0   0   0   1   0]]
              precision    recall  f1-score   support

          A1       0.23      0.26      0.24        19
          A2       0.62      0.58      0.60       118
          B1       0.61      0.61      0.61       163
          B2       0.69      0.73      0.71       121
          C1       0.58      0.50      0.54        30
          C2       0.00      0.00      0.00         1

    accuracy                           0.61       452
   macro avg       0.45      0.45      0.45       452
weighted avg       0.62      0.61      0.61       452


Fold 1
[[  5   9   5   0   0   0]
 [ 11  65  37   4   1   0]
 [  5  31 103  24   0   0]
 [  0   2  18  84  17   0]
 [  0   0   0  12  18   0]
 [  0   0   0   0   1   0]]
              precision    recall  f1-score   support

          A1       0.24      0.26      0.25        19
          A2       0.61      0.55      0.58       118
          B1       0.63      0.63      0.63       163
          B2       0.68      0.69      0.69       121
          C1       0.49      0.60      0.54        30
          C2       0.00      0.00      0.00         1

    accuracy                           0.61       452
   macro avg       0.44      0.46      0.45       452
weighted avg       0.61      0.61      0.61       452


Fold 2
[[ 4 11  4  0  0  0]
 [ 5 72 38  3  0  0]
 [ 9 35 96 24  0  0]
 [ 0  2 26 79 12  1]
 [ 0  0  0 15 15  0]
 [ 0  0  0  1  0  0]]
              precision    recall  f1-score   support

          A1       0.22      0.21      0.22        19
          A2       0.60      0.61      0.61       118
          B1       0.59      0.59      0.59       164
          B2       0.65      0.66      0.65       120
          C1       0.56      0.50      0.53        30
          C2       0.00      0.00      0.00         1

    accuracy                           0.59       452
   macro avg       0.44      0.43      0.43       452
weighted avg       0.59      0.59      0.59       452


Fold 3
[[ 4 11  5  0  0  0]
 [ 6 79 29  2  1  0]
 [ 3 44 93 22  2  0]
 [ 0  2 18 82 17  1]
 [ 0  0  0 13 17  0]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.31      0.20      0.24        20
          A2       0.58      0.68      0.62       117
          B1       0.64      0.57      0.60       164
          B2       0.69      0.68      0.69       120
          C1       0.45      0.57      0.50        30
          C2       0.00      0.00      0.00         1

    accuracy                           0.61       452
   macro avg       0.44      0.45      0.44       452
weighted avg       0.61      0.61      0.61       452


Fold 4
[[  6   9   4   0   1   0]
 [ 11  68  36   2   0   0]
 [  2  40 101  21   0   0]
 [  0   0  27  87   6   0]
 [  0   0   0  17  13   0]
 [  0   0   0   0   1   0]]
              precision    recall  f1-score   support

          A1       0.32      0.30      0.31        20
          A2       0.58      0.58      0.58       117
          B1       0.60      0.62      0.61       164
          B2       0.69      0.72      0.70       120
          C1       0.62      0.43      0.51        30
          C2       0.00      0.00      0.00         1

    accuracy                           0.61       452
   macro avg       0.47      0.44      0.45       452
weighted avg       0.61      0.61      0.61       452


K-fold scores
[0.6136723508029885, 0.6084482507395595, 0.5876983345432045, 0.6061442950456317, 0.6056759055010864]
SKF f1 score mean 0.6043278273264941

LogisticRegression(C=1.0, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='multinomial', n_jobs=None,
                   penalty='l2', random_state=1234, solver='lbfgs', tol=0.0001,
                   verbose=0, warm_start=False)
Fold 0
[[  9   8   2   0   0   0]
 [ 19  71  27   1   0   0]
 [ 10  29 101  23   0   0]
 [  1   0  15  89  16   0]
 [  0   0   1  10  19   0]
 [  0   0   0   0   1   0]]
              precision    recall  f1-score   support

          A1       0.23      0.47      0.31        19
          A2       0.66      0.60      0.63       118
          B1       0.69      0.62      0.65       163
          B2       0.72      0.74      0.73       121
          C1       0.53      0.63      0.58        30
          C2       0.00      0.00      0.00         1

    accuracy                           0.64       452
   macro avg       0.47      0.51      0.48       452
weighted avg       0.66      0.64      0.65       452


Fold 1
[[  9   8   2   0   0   0]
 [ 19  67  27   5   0   0]
 [  9  30 100  24   0   0]
 [  0   0  12  90  19   0]
 [  0   0   0   8  22   0]
 [  0   0   0   0   1   0]]
              precision    recall  f1-score   support

          A1       0.24      0.47      0.32        19
          A2       0.64      0.57      0.60       118
          B1       0.71      0.61      0.66       163
          B2       0.71      0.74      0.73       121
          C1       0.52      0.73      0.61        30
          C2       0.00      0.00      0.00         1

    accuracy                           0.64       452
   macro avg       0.47      0.52      0.49       452
weighted avg       0.66      0.64      0.64       452


Fold 2
[[10  5  4  0  0  0]
 [13 72 33  0  0  0]
 [13 41 87 23  0  0]
 [ 0  1 19 83 16  1]
 [ 0  0  0  5 25  0]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.28      0.53      0.36        19
          A2       0.61      0.61      0.61       118
          B1       0.61      0.53      0.57       164
          B2       0.75      0.69      0.72       120
          C1       0.60      0.83      0.69        30
          C2       0.00      0.00      0.00         1

    accuracy                           0.61       452
   macro avg       0.47      0.53      0.49       452
weighted avg       0.63      0.61      0.62       452


Fold 3
[[ 5 14  1  0  0  0]
 [12 84 21  0  0  0]
 [ 3 45 96 20  0  0]
 [ 0  0 14 87 18  1]
 [ 0  0  0 10 20  0]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.25      0.25      0.25        20
          A2       0.59      0.72      0.65       117
          B1       0.73      0.59      0.65       164
          B2       0.74      0.72      0.73       120
          C1       0.51      0.67      0.58        30
          C2       0.00      0.00      0.00         1

    accuracy                           0.65       452
   macro avg       0.47      0.49      0.48       452
weighted avg       0.66      0.65      0.65       452


Fold 4
[[11  8  1  0  0  0]
 [15 76 26  0  0  0]
 [ 4 44 94 21  1  0]
 [ 0  1 19 90 10  0]
 [ 0  0  0  9 21  0]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.37      0.55      0.44        20
          A2       0.59      0.65      0.62       117
          B1       0.67      0.57      0.62       164
          B2       0.75      0.75      0.75       120
          C1       0.64      0.70      0.67        30
          C2       0.00      0.00      0.00         1

    accuracy                           0.65       452
   macro avg       0.50      0.54      0.52       452
weighted avg       0.65      0.65      0.65       452


K-fold scores
[0.6463230044794358, 0.6424905498613123, 0.6164237457366871, 0.6470596206836046, 0.6471542822088677]
SKF f1 score mean 0.6398902405939816

************for dimension:  Vocabularycontrol  ***************
RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=300,
                       n_jobs=None, oob_score=False, random_state=1234,
                       verbose=0, warm_start=False)
Fold 0
[[  1  18  11   0   0   0]
 [  1  63  54   1   0   0]
 [  0  28 109  29   0   0]
 [  0   1  42  70   1   0]
 [  0   0   0  20   1   0]
 [  0   0   0   2   0   0]]
              precision    recall  f1-score   support

          A1       0.50      0.03      0.06        30
          A2       0.57      0.53      0.55       119
          B1       0.50      0.66      0.57       166
          B2       0.57      0.61      0.59       114
          C1       0.50      0.05      0.09        21
          C2       0.00      0.00      0.00         2

    accuracy                           0.54       452
   macro avg       0.44      0.31      0.31       452
weighted avg       0.54      0.54      0.51       452


Fold 1
[[  1  20   9   0   0   0]
 [  0  66  53   0   0   0]
 [  0  38 108  20   0   0]
 [  0   4  39  71   1   0]
 [  0   1   4  14   1   0]
 [  0   0   0   2   0   0]]
              precision    recall  f1-score   support

          A1       1.00      0.03      0.06        30
          A2       0.51      0.55      0.53       119
          B1       0.51      0.65      0.57       166
          B2       0.66      0.62      0.64       115
          C1       0.50      0.05      0.09        20
          C2       0.00      0.00      0.00         2

    accuracy                           0.55       452
   macro avg       0.53      0.32      0.32       452
weighted avg       0.58      0.55      0.52       452


Fold 2
[[  0  19  11   0   0   0]
 [  0  57  61   1   0   0]
 [  0  32 105  28   1   0]
 [  0   1  36  76   2   0]
 [  0   0   3  17   0   0]
 [  0   0   0   2   0   0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        30
          A2       0.52      0.48      0.50       119
          B1       0.49      0.63      0.55       166
          B2       0.61      0.66      0.64       115
          C1       0.00      0.00      0.00        20
          C2       0.00      0.00      0.00         2

    accuracy                           0.53       452
   macro avg       0.27      0.30      0.28       452
weighted avg       0.47      0.53      0.50       452


Fold 3
[[  1  13  17   0   0   0]
 [  1  64  53   1   0   0]
 [  0  29 105  31   0   0]
 [  0   2  44  69   0   0]
 [  0   0   0  20   0   0]
 [  0   0   0   2   0   0]]
              precision    recall  f1-score   support

          A1       0.50      0.03      0.06        31
          A2       0.59      0.54      0.56       119
          B1       0.48      0.64      0.55       165
          B2       0.56      0.60      0.58       115
          C1       0.00      0.00      0.00        20
          C2       0.00      0.00      0.00         2

    accuracy                           0.53       452
   macro avg       0.36      0.30      0.29       452
weighted avg       0.51      0.53      0.50       452


Fold 4
[[  0  14  17   0   0   0]
 [  0  54  63   1   0   0]
 [  0  28 106  31   0   0]
 [  0   4  36  73   2   0]
 [  0   0   2  18   0   0]
 [  0   0   0   3   0   0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        31
          A2       0.54      0.46      0.50       118
          B1       0.47      0.64      0.54       165
          B2       0.58      0.63      0.61       115
          C1       0.00      0.00      0.00        20
          C2       0.00      0.00      0.00         3

    accuracy                           0.52       452
   macro avg       0.27      0.29      0.27       452
weighted avg       0.46      0.52      0.48       452


K-fold scores
[0.5122503814746334, 0.5204818453173424, 0.4953420792398791, 0.4997680458707932, 0.4824107180669011]
SKF f1 score mean 0.5020506139939098

LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
          verbose=0)
Fold 0
[[13 12  5  0  0  0]
 [18 63 35  3  0  0]
 [ 8 30 78 46  4  0]
 [ 0  2 29 79  4  0]
 [ 0  0  2 16  3  0]
 [ 0  0  0  2  0  0]]
              precision    recall  f1-score   support

          A1       0.33      0.43      0.38        30
          A2       0.59      0.53      0.56       119
          B1       0.52      0.47      0.50       166
          B2       0.54      0.69      0.61       114
          C1       0.27      0.14      0.19        21
          C2       0.00      0.00      0.00         2

    accuracy                           0.52       452
   macro avg       0.38      0.38      0.37       452
weighted avg       0.52      0.52      0.52       452


Fold 1
[[10 18  1  1  0  0]
 [17 60 37  5  0  0]
 [ 4 44 85 31  2  0]
 [ 0  6 28 68 12  1]
 [ 0  1  2  9  8  0]
 [ 0  0  0  1  1  0]]
              precision    recall  f1-score   support

          A1       0.32      0.33      0.33        30
          A2       0.47      0.50      0.48       119
          B1       0.56      0.51      0.53       166
          B2       0.59      0.59      0.59       115
          C1       0.35      0.40      0.37        20
          C2       0.00      0.00      0.00         2

    accuracy                           0.51       452
   macro avg       0.38      0.39      0.38       452
weighted avg       0.51      0.51      0.51       452


Fold 2
[[ 9 14  7  0  0  0]
 [20 63 31  5  0  0]
 [14 38 69 41  4  0]
 [ 0  3 24 73 14  1]
 [ 0  0  2 11  7  0]
 [ 0  0  0  2  0  0]]
              precision    recall  f1-score   support

          A1       0.21      0.30      0.25        30
          A2       0.53      0.53      0.53       119
          B1       0.52      0.42      0.46       166
          B2       0.55      0.63      0.59       115
          C1       0.28      0.35      0.31        20
          C2       0.00      0.00      0.00         2

    accuracy                           0.49       452
   macro avg       0.35      0.37      0.36       452
weighted avg       0.50      0.49      0.49       452


Fold 3
[[11 12  7  1  0  0]
 [18 61 36  3  1  0]
 [ 9 43 76 32  5  0]
 [ 0  8 39 60  8  0]
 [ 0  0  1 15  4  0]
 [ 0  0  0  1  1  0]]
              precision    recall  f1-score   support

          A1       0.29      0.35      0.32        31
          A2       0.49      0.51      0.50       119
          B1       0.48      0.46      0.47       165
          B2       0.54      0.52      0.53       115
          C1       0.21      0.20      0.21        20
          C2       0.00      0.00      0.00         2

    accuracy                           0.47       452
   macro avg       0.33      0.34      0.34       452
weighted avg       0.47      0.47      0.47       452


Fold 4
[[11 12  6  2  0  0]
 [16 55 39  7  1  0]
 [ 7 43 83 29  3  0]
 [ 0  6 28 64 17  0]
 [ 0  1  1  8 10  0]
 [ 0  0  0  2  1  0]]
              precision    recall  f1-score   support

          A1       0.32      0.35      0.34        31
          A2       0.47      0.47      0.47       118
          B1       0.53      0.50      0.52       165
          B2       0.57      0.56      0.56       115
          C1       0.31      0.50      0.38        20
          C2       0.00      0.00      0.00         3

    accuracy                           0.49       452
   macro avg       0.37      0.40      0.38       452
weighted avg       0.50      0.49      0.49       452


K-fold scores
[0.515649175787382, 0.5117754890341534, 0.48999203185489787, 0.468875745552908, 0.49408536441819173]
SKF f1 score mean 0.4960755613295066

LogisticRegression(C=1.0, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='multinomial', n_jobs=None,
                   penalty='l2', random_state=1234, solver='lbfgs', tol=0.0001,
                   verbose=0, warm_start=False)
Fold 0
[[20  9  1  0  0  0]
 [25 70 21  3  0  0]
 [14 32 72 43  3  2]
 [ 0  2 27 69 14  2]
 [ 0  0  2  9  9  1]
 [ 0  0  0  1  1  0]]
              precision    recall  f1-score   support

          A1       0.34      0.67      0.45        30
          A2       0.62      0.59      0.60       119
          B1       0.59      0.43      0.50       166
          B2       0.55      0.61      0.58       114
          C1       0.33      0.43      0.38        21
          C2       0.00      0.00      0.00         2

    accuracy                           0.53       452
   macro avg       0.40      0.45      0.42       452
weighted avg       0.56      0.53      0.53       452


Fold 1
[[10 18  2  0  0  0]
 [23 71 23  2  0  0]
 [ 8 50 74 32  2  0]
 [ 2  3 21 71 15  3]
 [ 0  1  0 11  8  0]
 [ 0  0  0  0  2  0]]
              precision    recall  f1-score   support

          A1       0.23      0.33      0.27        30
          A2       0.50      0.60      0.54       119
          B1       0.62      0.45      0.52       166
          B2       0.61      0.62      0.61       115
          C1       0.30      0.40      0.34        20
          C2       0.00      0.00      0.00         2

    accuracy                           0.52       452
   macro avg       0.38      0.40      0.38       452
weighted avg       0.54      0.52      0.52       452


Fold 2
[[13 13  4  0  0  0]
 [22 58 32  7  0  0]
 [12 42 69 37  4  2]
 [ 0  3 19 69 22  2]
 [ 0  0  0  8 12  0]
 [ 0  0  0  1  1  0]]
              precision    recall  f1-score   support

          A1       0.28      0.43      0.34        30
          A2       0.50      0.49      0.49       119
          B1       0.56      0.42      0.48       166
          B2       0.57      0.60      0.58       115
          C1       0.31      0.60      0.41        20
          C2       0.00      0.00      0.00         2

    accuracy                           0.49       452
   macro avg       0.37      0.42      0.38       452
weighted avg       0.51      0.49      0.49       452


Fold 3
[[19  7  5  0  0  0]
 [23 70 26  0  0  0]
 [14 37 71 37  4  2]
 [ 1  5 30 62 16  1]
 [ 0  0  0 10  9  1]
 [ 0  0  0  1  1  0]]
              precision    recall  f1-score   support

          A1       0.33      0.61      0.43        31
          A2       0.59      0.59      0.59       119
          B1       0.54      0.43      0.48       165
          B2       0.56      0.54      0.55       115
          C1       0.30      0.45      0.36        20
          C2       0.00      0.00      0.00         2

    accuracy                           0.51       452
   macro avg       0.39      0.44      0.40       452
weighted avg       0.53      0.51      0.52       452


Fold 4
[[ 8 17  6  0  0  0]
 [21 65 29  3  0  0]
 [ 6 43 81 28  6  1]
 [ 0  7 19 61 26  2]
 [ 0  0  1  5 13  1]
 [ 0  0  0  2  1  0]]
              precision    recall  f1-score   support

          A1       0.23      0.26      0.24        31
          A2       0.49      0.55      0.52       118
          B1       0.60      0.49      0.54       165
          B2       0.62      0.53      0.57       115
          C1       0.28      0.65      0.39        20
          C2       0.00      0.00      0.00         3

    accuracy                           0.50       452
   macro avg       0.37      0.41      0.38       452
weighted avg       0.53      0.50      0.51       452


K-fold scores
[0.5347468173575106, 0.5223863064631308, 0.4932765877142822, 0.5151615714668812, 0.5113244994877306]
SKF f1 score mean 0.5153791564979071

************for dimension:  CoherenceCohesion  ***************
RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=300,
                       n_jobs=None, oob_score=False, random_state=1234,
                       verbose=0, warm_start=False)
Fold 0
[[  1  31   6   0   0   0]
 [  0  94  36   3   0   0]
 [  0  27 127  11   0   0]
 [  0   1  28  67   1   0]
 [  0   0   1  16   1   0]
 [  0   0   0   1   0   0]]
              precision    recall  f1-score   support

          A1       1.00      0.03      0.05        38
          A2       0.61      0.71      0.66       133
          B1       0.64      0.77      0.70       165
          B2       0.68      0.69      0.69        97
          C1       0.50      0.06      0.10        18
          C2       0.00      0.00      0.00         1

    accuracy                           0.64       452
   macro avg       0.57      0.37      0.37       452
weighted avg       0.67      0.64      0.60       452


Fold 1
[[  1  25  12   1   0   0]
 [  3  94  34   1   0   0]
 [  0  26 122  17   0   0]
 [  1   1  20  75   0   0]
 [  0   0   2  16   0   0]
 [  0   0   0   1   0   0]]
              precision    recall  f1-score   support

          A1       0.20      0.03      0.05        39
          A2       0.64      0.71      0.68       132
          B1       0.64      0.74      0.69       165
          B2       0.68      0.77      0.72        97
          C1       0.00      0.00      0.00        18
          C2       0.00      0.00      0.00         1

    accuracy                           0.65       452
   macro avg       0.36      0.38      0.36       452
weighted avg       0.58      0.65      0.61       452


Fold 2
[[  0  32   7   0   0   0]
 [  0  81  50   1   0   0]
 [  0  33 108  25   0   0]
 [  0   3  20  72   1   0]
 [  0   0   0  18   0   0]
 [  0   0   0   1   0   0]]
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        39
          A2       0.54      0.61      0.58       132
          B1       0.58      0.65      0.62       166
          B2       0.62      0.75      0.68        96
          C1       0.00      0.00      0.00        18
          C2       0.00      0.00      0.00         1

    accuracy                           0.58       452
   macro avg       0.29      0.34      0.31       452
weighted avg       0.50      0.58      0.54       452


Fold 3
[[  1  28  10   0   0   0]
 [  0  72  60   0   0   0]
 [  0  21 131  13   1   0]
 [  0   0  31  65   0   0]
 [  0   0   1  17   0   0]
 [  0   0   0   1   0   0]]
              precision    recall  f1-score   support

          A1       1.00      0.03      0.05        39
          A2       0.60      0.55      0.57       132
          B1       0.56      0.79      0.66       166
          B2       0.68      0.68      0.68        96
          C1       0.00      0.00      0.00        18
          C2       0.00      0.00      0.00         1

    accuracy                           0.60       452
   macro avg       0.47      0.34      0.33       452
weighted avg       0.61      0.60      0.56       452


Fold 4
[[  1  33   5   0   0   0]
 [  1  99  33   0   0   0]
 [  0  30 125  10   0   0]
 [  0   1  35  59   1   0]
 [  0   0   2  16   0   0]
 [  0   0   0   1   0   0]]
              precision    recall  f1-score   support

          A1       0.50      0.03      0.05        39
          A2       0.61      0.74      0.67       133
          B1       0.62      0.76      0.68       165
          B2       0.69      0.61      0.65        96
          C1       0.00      0.00      0.00        18
          C2       0.00      0.00      0.00         1

    accuracy                           0.63       452
   macro avg       0.40      0.36      0.34       452
weighted avg       0.60      0.63      0.59       452


K-fold scores
[0.6046155908987768, 0.6070780710270695, 0.5379533157802306, 0.5554932324076833, 0.588770159540933]
SKF f1 score mean 0.5787820739309386

LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
          verbose=0)
Fold 0
[[ 17  20   1   0   0   0]
 [ 23  80  28   2   0   0]
 [  7  29 106  23   0   0]
 [  0   2  20  66   9   0]
 [  0   0   0  13   5   0]
 [  0   0   0   0   1   0]]
              precision    recall  f1-score   support

          A1       0.36      0.45      0.40        38
          A2       0.61      0.60      0.61       133
          B1       0.68      0.64      0.66       165
          B2       0.63      0.68      0.66        97
          C1       0.33      0.28      0.30        18
          C2       0.00      0.00      0.00         1

    accuracy                           0.61       452
   macro avg       0.44      0.44      0.44       452
weighted avg       0.61      0.61      0.61       452


Fold 1
[[13 22  4  0  0  0]
 [24 77 26  3  2  0]
 [ 4 30 98 33  0  0]
 [ 0  2 22 66  5  2]
 [ 0  0  1  5 12  0]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.32      0.33      0.32        39
          A2       0.59      0.58      0.59       132
          B1       0.65      0.59      0.62       165
          B2       0.62      0.68      0.65        97
          C1       0.60      0.67      0.63        18
          C2       0.00      0.00      0.00         1

    accuracy                           0.59       452
   macro avg       0.46      0.48      0.47       452
weighted avg       0.59      0.59      0.59       452


Fold 2
[[ 9 26  3  1  0  0]
 [26 69 35  2  0  0]
 [ 6 33 99 27  1  0]
 [ 2  3 18 66  7  0]
 [ 0  0  2 10  6  0]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.21      0.23      0.22        39
          A2       0.53      0.52      0.52       132
          B1       0.63      0.60      0.61       166
          B2       0.62      0.69      0.65        96
          C1       0.40      0.33      0.36        18
          C2       0.00      0.00      0.00         1

    accuracy                           0.55       452
   macro avg       0.40      0.40      0.40       452
weighted avg       0.55      0.55      0.55       452


Fold 3
[[ 16  18   4   1   0   0]
 [ 16  68  44   4   0   0]
 [  6  33 105  21   1   0]
 [  1   1  27  60   7   0]
 [  0   0   0  12   6   0]
 [  0   0   0   0   1   0]]
              precision    recall  f1-score   support

          A1       0.41      0.41      0.41        39
          A2       0.57      0.52      0.54       132
          B1       0.58      0.63      0.61       166
          B2       0.61      0.62      0.62        96
          C1       0.40      0.33      0.36        18
          C2       0.00      0.00      0.00         1

    accuracy                           0.56       452
   macro avg       0.43      0.42      0.42       452
weighted avg       0.56      0.56      0.56       452


Fold 4
[[19 16  4  0  0  0]
 [24 78 27  4  0  0]
 [ 8 38 96 22  1  0]
 [ 0  1 28 59  8  0]
 [ 0  0  0 12  6  0]
 [ 0  0  0  1  0  0]]
              precision    recall  f1-score   support

          A1       0.37      0.49      0.42        39
          A2       0.59      0.59      0.59       133
          B1       0.62      0.58      0.60       165
          B2       0.60      0.61      0.61        96
          C1       0.40      0.33      0.36        18
          C2       0.00      0.00      0.00         1

    accuracy                           0.57       452
   macro avg       0.43      0.43      0.43       452
weighted avg       0.57      0.57      0.57       452


K-fold scores
[0.6068022092874324, 0.5894749441422179, 0.5505751654178641, 0.5617620313478409, 0.5716899862598248]
SKF f1 score mean 0.576060867291036

LogisticRegression(C=1.0, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='multinomial', n_jobs=None,
                   penalty='l2', random_state=1234, solver='lbfgs', tol=0.0001,
                   verbose=0, warm_start=False)
Fold 0
[[ 24  12   2   0   0   0]
 [ 33  72  26   2   0   0]
 [  6  27 113  19   0   0]
 [  0   2  17  64  14   0]
 [  0   0   0  11   7   0]
 [  0   0   0   0   1   0]]
              precision    recall  f1-score   support

          A1       0.38      0.63      0.48        38
          A2       0.64      0.54      0.59       133
          B1       0.72      0.68      0.70       165
          B2       0.67      0.66      0.66        97
          C1       0.32      0.39      0.35        18
          C2       0.00      0.00      0.00         1

    accuracy                           0.62       452
   macro avg       0.45      0.48      0.46       452
weighted avg       0.64      0.62      0.62       452


Fold 1
[[17 21  1  0  0  0]
 [33 80 18  1  0  0]
 [ 3 34 96 29  3  0]
 [ 0  2 14 66 12  3]
 [ 0  0  1  4 13  0]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.32      0.44      0.37        39
          A2       0.58      0.61      0.59       132
          B1       0.74      0.58      0.65       165
          B2       0.66      0.68      0.67        97
          C1       0.45      0.72      0.55        18
          C2       0.00      0.00      0.00         1

    accuracy                           0.60       452
   macro avg       0.46      0.50      0.47       452
weighted avg       0.63      0.60      0.61       452


Fold 2
[[20 15  4  0  0  0]
 [30 68 31  3  0  0]
 [ 8 34 95 28  1  0]
 [ 2  3 16 65 10  0]
 [ 0  0  0 10  8  0]
 [ 0  0  0  0  1  0]]
              precision    recall  f1-score   support

          A1       0.33      0.51      0.40        39
          A2       0.57      0.52      0.54       132
          B1       0.65      0.57      0.61       166
          B2       0.61      0.68      0.64        96
          C1       0.40      0.44      0.42        18
          C2       0.00      0.00      0.00         1

    accuracy                           0.57       452
   macro avg       0.43      0.45      0.44       452
weighted avg       0.58      0.57      0.57       452


Fold 3
[[ 18  18   3   0   0   0]
 [ 22  72  34   4   0   0]
 [  8  26 111  20   1   0]
 [  0   0  20  63  13   0]
 [  0   0   0  10   7   1]
 [  0   0   0   0   1   0]]
              precision    recall  f1-score   support

          A1       0.38      0.46      0.41        39
          A2       0.62      0.55      0.58       132
          B1       0.66      0.67      0.66       166
          B2       0.65      0.66      0.65        96
          C1       0.32      0.39      0.35        18
          C2       0.00      0.00      0.00         1

    accuracy                           0.60       452
   macro avg       0.44      0.45      0.44       452
weighted avg       0.61      0.60      0.60       452


Fold 4
[[ 24  14   1   0   0   0]
 [ 37  75  17   4   0   0]
 [ 10  35 102  17   1   0]
 [  0   2  23  55  16   0]
 [  0   0   0  10   8   0]
 [  0   0   0   0   1   0]]
              precision    recall  f1-score   support

          A1       0.34      0.62      0.44        39
          A2       0.60      0.56      0.58       133
          B1       0.71      0.62      0.66       165
          B2       0.64      0.57      0.60        96
          C1       0.31      0.44      0.36        18
          C2       0.00      0.00      0.00         1

    accuracy                           0.58       452
   macro avg       0.43      0.47      0.44       452
weighted avg       0.61      0.58      0.59       452


K-fold scores
[0.6238796174855414, 0.609000565941439, 0.5695719915302155, 0.6019734442381779, 0.5926954772087516]
SKF f1 score mean 0.5994242192808251

************for dimension:  Sociolinguisticappropriateness  ***************
RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_impurity_split=None,
                       min_samples_leaf=1, min_samples_split=2,
                       min_weight_fraction_leaf=0.0, n_estimators=300,
                       n_jobs=None, oob_score=False, random_state=1234,
                       verbose=0, warm_start=False)
Fold 0
[[52 20  2  0  0]
 [ 4 97 38  1  0]
 [ 2 34 93 17  0]
 [ 0  7 20 51  0]
 [ 0  0  1 13  0]]
              precision    recall  f1-score   support

          A1       0.90      0.70      0.79        74
          A2       0.61      0.69      0.65       140
          B1       0.60      0.64      0.62       146
          B2       0.62      0.65      0.64        78
          C1       0.00      0.00      0.00        14

    accuracy                           0.65       452
   macro avg       0.55      0.54      0.54       452
weighted avg       0.64      0.65      0.64       452


Fold 1
[[48 22  4  0  0]
 [ 2 99 38  1  0]
 [ 1 58 76 12  0]
 [ 0  5 19 53  0]
 [ 0  0  2 12  0]]
              precision    recall  f1-score   support

          A1       0.94      0.65      0.77        74
          A2       0.54      0.71      0.61       140
          B1       0.55      0.52      0.53       147
          B2       0.68      0.69      0.68        77
          C1       0.00      0.00      0.00        14

    accuracy                           0.61       452
   macro avg       0.54      0.51      0.52       452
weighted avg       0.61      0.61      0.60       452


Fold 2
[[48 21  4  1  0]
 [ 3 93 42  2  0]
 [ 1 46 81 19  0]
 [ 0  5 15 57  0]
 [ 0  0  1 13  0]]
              precision    recall  f1-score   support

          A1       0.92      0.65      0.76        74
          A2       0.56      0.66      0.61       140
          B1       0.57      0.55      0.56       147
          B2       0.62      0.74      0.67        77
          C1       0.00      0.00      0.00        14

    accuracy                           0.62       452
   macro avg       0.53      0.52      0.52       452
weighted avg       0.62      0.62      0.61       452


Fold 3
[[ 54  19   1   0   0]
 [  0 114  25   1   0]
 [  2  41  90  14   0]
 [  0   6  29  42   0]
 [  0   0   0  14   0]]
              precision    recall  f1-score   support

          A1       0.96      0.73      0.83        74
          A2       0.63      0.81      0.71       140
          B1       0.62      0.61      0.62       147
          B2       0.59      0.55      0.57        77
          C1       0.00      0.00      0.00        14

    accuracy                           0.66       452
   macro avg       0.56      0.54      0.55       452
weighted avg       0.66      0.66      0.65       452


Fold 4
[[ 47  23   5   0   0]
 [  3 106  30   1   0]
 [  0  41  89  17   0]
 [  1   4  18  54   0]
 [  0   0   0  12   1]]
              precision    recall  f1-score   support

          A1       0.92      0.63      0.75        75
          A2       0.61      0.76      0.68       140
          B1       0.63      0.61      0.62       147
          B2       0.64      0.70      0.67        77
          C1       1.00      0.08      0.14        13

    accuracy                           0.66       452
   macro avg       0.76      0.55      0.57       452
weighted avg       0.68      0.66      0.65       452


K-fold scores
[0.6409048006644819, 0.6043617128264572, 0.6102125472189325, 0.6538629737517482, 0.6516012900525247]
SKF f1 score mean 0.6321886649028289

LinearSVC(C=1.0, class_weight='balanced', dual=True, fit_intercept=True,
          intercept_scaling=1, loss='squared_hinge', max_iter=1000,
          multi_class='ovr', penalty='l2', random_state=1234, tol=0.0001,
          verbose=0)
Fold 0
[[56 15  3  0  0]
 [14 91 29  6  0]
 [ 5 31 85 23  2]
 [ 1  4 20 45  8]
 [ 0  0  1 10  3]]
              precision    recall  f1-score   support

          A1       0.74      0.76      0.75        74
          A2       0.65      0.65      0.65       140
          B1       0.62      0.58      0.60       146
          B2       0.54      0.58      0.56        78
          C1       0.23      0.21      0.22        14

    accuracy                           0.62       452
   macro avg       0.55      0.56      0.55       452
weighted avg       0.62      0.62      0.62       452


Fold 1
[[52 19  2  0  1]
 [15 92 32  1  0]
 [ 9 35 82 20  1]
 [ 0  2 21 45  9]
 [ 0  0  2 11  1]]
              precision    recall  f1-score   support

          A1       0.68      0.70      0.69        74
          A2       0.62      0.66      0.64       140
          B1       0.59      0.56      0.57       147
          B2       0.58      0.58      0.58        77
          C1       0.08      0.07      0.08        14

    accuracy                           0.60       452
   macro avg       0.51      0.51      0.51       452
weighted avg       0.60      0.60      0.60       452


Fold 2
[[49 22  3  0  0]
 [11 77 46  4  2]
 [ 4 46 70 27  0]
 [ 1  4 14 46 12]
 [ 0  0  1 10  3]]
              precision    recall  f1-score   support

          A1       0.75      0.66      0.71        74
          A2       0.52      0.55      0.53       140
          B1       0.52      0.48      0.50       147
          B2       0.53      0.60      0.56        77
          C1       0.18      0.21      0.19        14

    accuracy                           0.54       452
   macro avg       0.50      0.50      0.50       452
weighted avg       0.55      0.54      0.54       452


Fold 3
[[52 16  5  1  0]
 [12 82 42  4  0]
 [ 1 37 86 20  3]
 [ 0  5 26 44  2]
 [ 0  1  1 11  1]]
              precision    recall  f1-score   support

          A1       0.80      0.70      0.75        74
          A2       0.58      0.59      0.58       140
          B1       0.54      0.59      0.56       147
          B2       0.55      0.57      0.56        77
          C1       0.17      0.07      0.10        14

    accuracy                           0.59       452
   macro avg       0.53      0.50      0.51       452
weighted avg       0.58      0.59      0.58       452


Fold 4
[[52 17  4  2  0]
 [12 92 33  3  0]
 [ 4 42 70 28  3]
 [ 1  6 13 48  9]
 [ 0  0  0 10  3]]
              precision    recall  f1-score   support

          A1       0.75      0.69      0.72        75
          A2       0.59      0.66      0.62       140
          B1       0.58      0.48      0.52       147
          B2       0.53      0.62      0.57        77
          C1       0.20      0.23      0.21        13

    accuracy                           0.59       452
   macro avg       0.53      0.54      0.53       452
weighted avg       0.59      0.59      0.59       452


K-fold scores
[0.6189564171650238, 0.5998268594728773, 0.5440663086932445, 0.5840544986414066, 0.5857633614419931]
SKF f1 score mean 0.5865334890829091

LogisticRegression(C=1.0, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=100, multi_class='multinomial', n_jobs=None,
                   penalty='l2', random_state=1234, solver='lbfgs', tol=0.0001,
                   verbose=0, warm_start=False)
Fold 0
[[58 15  1  0  0]
 [16 87 33  4  0]
 [ 5 26 89 24  2]
 [ 1  4 19 39 15]
 [ 0  0  1  6  7]]
              precision    recall  f1-score   support

          A1       0.72      0.78      0.75        74
          A2       0.66      0.62      0.64       140
          B1       0.62      0.61      0.62       146
          B2       0.53      0.50      0.52        78
          C1       0.29      0.50      0.37        14

    accuracy                           0.62       452
   macro avg       0.57      0.60      0.58       452
weighted avg       0.63      0.62      0.62       452


Fold 1
[[55 19  0  0  0]
 [16 90 31  3  0]
 [ 7 34 87 17  2]
 [ 0  1 13 46 17]
 [ 0  0  1 10  3]]
              precision    recall  f1-score   support

          A1       0.71      0.74      0.72        74
          A2       0.62      0.64      0.63       140
          B1       0.66      0.59      0.62       147
          B2       0.61      0.60      0.60        77
          C1       0.14      0.21      0.17        14

    accuracy                           0.62       452
   macro avg       0.55      0.56      0.55       452
weighted avg       0.63      0.62      0.63       452


Fold 2
[[51 21  2  0  0]
 [10 81 41  7  1]
 [ 2 41 75 27  2]
 [ 1  5 12 46 13]
 [ 0  0  2  6  6]]
              precision    recall  f1-score   support

          A1       0.80      0.69      0.74        74
          A2       0.55      0.58      0.56       140
          B1       0.57      0.51      0.54       147
          B2       0.53      0.60      0.56        77
          C1       0.27      0.43      0.33        14

    accuracy                           0.57       452
   macro avg       0.54      0.56      0.55       452
weighted avg       0.58      0.57      0.58       452


Fold 3
[[54 18  2  0  0]
 [12 89 36  3  0]
 [ 4 33 87 23  0]
 [ 0  5 23 45  4]
 [ 0  0  1 10  3]]
              precision    recall  f1-score   support

          A1       0.77      0.73      0.75        74
          A2       0.61      0.64      0.62       140
          B1       0.58      0.59      0.59       147
          B2       0.56      0.58      0.57        77
          C1       0.43      0.21      0.29        14

    accuracy                           0.62       452
   macro avg       0.59      0.55      0.56       452
weighted avg       0.61      0.62      0.61       452


Fold 4
[[52 18  4  1  0]
 [ 9 98 31  2  0]
 [ 4 40 71 27  5]
 [ 1  7 11 45 13]
 [ 0  0  0  9  4]]
              precision    recall  f1-score   support

          A1       0.79      0.69      0.74        75
          A2       0.60      0.70      0.65       140
          B1       0.61      0.48      0.54       147
          B2       0.54      0.58      0.56        77
          C1       0.18      0.31      0.23        13

    accuracy                           0.60       452
   macro avg       0.54      0.55      0.54       452
weighted avg       0.61      0.60      0.60       452


K-fold scores
[0.6209562924060096, 0.6252133456373624, 0.5765590699214213, 0.6132998189094273, 0.5994763134784531]
SKF f1 score mean 0.6071009680705347

DOING CROSS LANG CLASSIFICATION
768
768
768
************for dimension:  OverallCEFRrating  ***************
DE Train, IT Test
CROSS LANG EVAL
0.6125
[[  0  23   4   1]
 [  0 189 187   4]
 [  0  32 301  59]
 [  0   0   0   0]]
0.6214281674208145
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        28
          A2       0.77      0.50      0.61       380
          B1       0.61      0.77      0.68       392
          B2       0.00      0.00      0.00         0

    accuracy                           0.61       800
   macro avg       0.35      0.32      0.32       800
weighted avg       0.67      0.61      0.62       800


0.3925
[[  8  16   2   2   0]
 [ 49 179  84  66   2]
 [ 15  31 127 216   3]
 [  0   0   0   0   0]
 [  0   0   0   0   0]]
0.49192956932056847
              precision    recall  f1-score   support

          A1       0.11      0.29      0.16        28
          A2       0.79      0.47      0.59       380
          B1       0.60      0.32      0.42       392
          B2       0.00      0.00      0.00         0
          C1       0.00      0.00      0.00         0

    accuracy                           0.39       800
   macro avg       0.30      0.22      0.23       800
weighted avg       0.67      0.39      0.49       800


0.475
[[ 18   9   1   0   0]
 [ 54 104 210  12   0]
 [ 11   6 258 116   1]
 [  0   0   0   0   0]
 [  0   0   0   0   0]]
0.5030058799206852
              precision    recall  f1-score   support

          A1       0.22      0.64      0.32        28
          A2       0.87      0.27      0.42       380
          B1       0.55      0.66      0.60       392
          B2       0.00      0.00      0.00         0
          C1       0.00      0.00      0.00         0

    accuracy                           0.48       800
   macro avg       0.33      0.31      0.27       800
weighted avg       0.69      0.47      0.50       800


DE Train, CZ Test
CROSS LANG EVAL
0.4792626728110599
[[ 56 118  14]
 [ 12  79  74]
 [  2   6  73]]
0.4638768732722681
              precision    recall  f1-score   support

          A2       0.80      0.30      0.43       188
          B1       0.39      0.48      0.43       165
          B2       0.45      0.90      0.60        81

    accuracy                           0.48       434
   macro avg       0.55      0.56      0.49       434
weighted avg       0.58      0.48      0.46       434


0.3433179723502304
[[  0   0   0   0   0]
 [  2   5 167  14   0]
 [  0   0 120  40   5]
 [  0   1  46  24  10]
 [  0   0   0   0   0]]
0.2618931431505078
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         0
          A2       0.83      0.03      0.05       188
          B1       0.36      0.73      0.48       165
          B2       0.31      0.30      0.30        81
          C1       0.00      0.00      0.00         0

    accuracy                           0.34       434
   macro avg       0.30      0.21      0.17       434
weighted avg       0.56      0.34      0.26       434


0.3640552995391705
[[  0   0   0   0   0]
 [  6   2 170  10   0]
 [  0   1 119  38   7]
 [  0   0  28  37  16]
 [  0   0   0   0   0]]
0.2799968561185531
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         0
          A2       0.67      0.01      0.02       188
          B1       0.38      0.72      0.49       165
          B2       0.44      0.46      0.45        81
          C1       0.00      0.00      0.00         0

    accuracy                           0.36       434
   macro avg       0.30      0.24      0.19       434
weighted avg       0.51      0.36      0.28       434


************for dimension:  Grammaticalaccuracy  ***************
DE Train, IT Test
CROSS LANG EVAL
0.50375
[[  0  30  40   1]
 [  0  73 167   2]
 [  0  46 325   5]
 [  0   4 102   5]]
0.42547489023606316
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        71
          A2       0.48      0.30      0.37       242
          B1       0.51      0.86      0.64       376
          B2       0.38      0.05      0.08       111

    accuracy                           0.50       800
   macro avg       0.34      0.30      0.27       800
weighted avg       0.44      0.50      0.43       800


0.42125
[[ 12  21  38   0   0]
 [ 30  64 144   3   1]
 [ 18  74 235  42   7]
 [  2  19  61  26   3]
 [  0   0   0   0   0]]
0.4065134763137352
              precision    recall  f1-score   support

          A1       0.19      0.17      0.18        71
          A2       0.36      0.26      0.30       242
          B1       0.49      0.62      0.55       376
          B2       0.37      0.23      0.29       111
          C1       0.00      0.00      0.00         0

    accuracy                           0.42       800
   macro avg       0.28      0.26      0.26       800
weighted avg       0.41      0.42      0.41       800


0.48625
[[ 19  13  39   0   0]
 [ 42  44 154   2   0]
 [ 18  23 300  35   0]
 [  3   2  79  26   1]
 [  0   0   0   0   0]]
0.4431368491590503
              precision    recall  f1-score   support

          A1       0.23      0.27      0.25        71
          A2       0.54      0.18      0.27       242
          B1       0.52      0.80      0.63       376
          B2       0.41      0.23      0.30       111
          C1       0.00      0.00      0.00         0

    accuracy                           0.49       800
   macro avg       0.34      0.30      0.29       800
weighted avg       0.49      0.49      0.44       800


DE Train, CZ Test
CROSS LANG EVAL
0.41013824884792627
[[  0   1   5   0   0]
 [  0   5 162  18   0]
 [  0   5 112  39   0]
 [  0   4  17  61   0]
 [  0   0   0   5   0]]
0.3118887892010929
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         6
          A2       0.33      0.03      0.05       185
          B1       0.38      0.72      0.50       156
          B2       0.50      0.74      0.60        82
          C1       0.00      0.00      0.00         5

    accuracy                           0.41       434
   macro avg       0.24      0.30      0.23       434
weighted avg       0.37      0.41      0.31       434


0.29723502304147464
[[ 2  0  2  1  1]
 [11 17 95 56  6]
 [ 3  3 73 71  6]
 [ 3  2 32 34 11]
 [ 0  0  1  1  3]]
0.2730093411045028
              precision    recall  f1-score   support

          A1       0.11      0.33      0.16         6
          A2       0.77      0.09      0.16       185
          B1       0.36      0.47      0.41       156
          B2       0.21      0.41      0.28        82
          C1       0.11      0.60      0.19         5

    accuracy                           0.30       434
   macro avg       0.31      0.38      0.24       434
weighted avg       0.50      0.30      0.27       434


0.37557603686635943
[[  2   0   4   0   0]
 [  8   8 157   8   4]
 [  3   5 125  16   7]
 [  1   0  42  23  16]
 [  0   0   0   0   5]]
0.293363292108433
              precision    recall  f1-score   support

          A1       0.14      0.33      0.20         6
          A2       0.62      0.04      0.08       185
          B1       0.38      0.80      0.52       156
          B2       0.49      0.28      0.36        82
          C1       0.16      1.00      0.27         5

    accuracy                           0.38       434
   macro avg       0.36      0.49      0.28       434
weighted avg       0.50      0.38      0.29       434


************for dimension:  Orthography  ***************
DE Train, IT Test
CROSS LANG EVAL
0.31125
[[  0   1  20   1   0   0]
 [  0   2 128  13   0   0]
 [  0   0 194  26   0   0]
 [  0   0  24  53   0   0]
 [  0   0  66 196   0   0]
 [  0   0  29  47   0   0]]
0.18628200105895978
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        22
          A2       0.67      0.01      0.03       143
          B1       0.42      0.88      0.57       220
          B2       0.16      0.69      0.26        77
          C1       0.00      0.00      0.00       262
          C2       0.00      0.00      0.00        76

    accuracy                           0.31       800
   macro avg       0.21      0.26      0.14       800
weighted avg       0.25      0.31      0.19       800


0.37125
[[  0  12   5   0   5   0]
 [  3  72  31   1  34   2]
 [  3 110  31   4  71   1]
 [  0  15  18   2  42   0]
 [  2  20  40   9 191   0]
 [  0   9   8   3  55   1]]
0.31179778537392616
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        22
          A2       0.30      0.50      0.38       143
          B1       0.23      0.14      0.18       220
          B2       0.11      0.03      0.04        77
          C1       0.48      0.73      0.58       262
          C2       0.25      0.01      0.03        76

    accuracy                           0.37       800
   macro avg       0.23      0.24      0.20       800
weighted avg       0.31      0.37      0.31       800


0.36625
[[  0  16   5   1   0   0]
 [  4  64  59   1  13   2]
 [  5 103  73   8  31   0]
 [  0   6  23  17  31   0]
 [  1  12  49  61 139   0]
 [  0   7  17  15  37   0]]
0.3508637957936696
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        22
          A2       0.31      0.45      0.36       143
          B1       0.32      0.33      0.33       220
          B2       0.17      0.22      0.19        77
          C1       0.55      0.53      0.54       262
          C2       0.00      0.00      0.00        76

    accuracy                           0.37       800
   macro avg       0.22      0.26      0.24       800
weighted avg       0.34      0.37      0.35       800


DE Train, CZ Test
CROSS LANG EVAL
0.5
[[  1  25  20   0]
 [  0 128 141   0]
 [  0  26  88   0]
 [  0   0   5   0]]
0.48431675496136206
              precision    recall  f1-score   support

          A2       1.00      0.02      0.04        46
          B1       0.72      0.48      0.57       269
          B2       0.35      0.77      0.48       114
          C1       0.00      0.00      0.00         5

    accuracy                           0.50       434
   macro avg       0.52      0.32      0.27       434
weighted avg       0.64      0.50      0.48       434


0.14516129032258066
[[  0   0   0   0   0   0]
 [  1   1   5  36   3   0]
 [  0   2   9 192  61   5]
 [  0   0   6  50  56   2]
 [  0   0   0   2   3   0]
 [  0   0   0   0   0   0]]
0.1101388512262857
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         0
          A2       0.33      0.02      0.04        46
          B1       0.45      0.03      0.06       269
          B2       0.18      0.44      0.25       114
          C1       0.02      0.60      0.05         5
          C2       0.00      0.00      0.00         0

    accuracy                           0.15       434
   macro avg       0.16      0.18      0.07       434
weighted avg       0.36      0.15      0.11       434


0.2119815668202765
[[  0   0   0   0   0   0]
 [  2   1   6  34   3   0]
 [  0   4  40 176  34  15]
 [  0   1  12  50  31  20]
 [  0   0   0   0   1   4]
 [  0   0   0   0   0   0]]
0.22625817253535166
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         0
          A2       0.17      0.02      0.04        46
          B1       0.69      0.15      0.24       269
          B2       0.19      0.44      0.27       114
          C1       0.01      0.20      0.03         5
          C2       0.00      0.00      0.00         0

    accuracy                           0.21       434
   macro avg       0.18      0.13      0.10       434
weighted avg       0.50      0.21      0.23       434


************for dimension:  Vocabularyrange  ***************
DE Train, IT Test
CROSS LANG EVAL
0.505
[[  0   4  35   0   0]
 [  0  18 224   1   0]
 [  0  11 284  33   0]
 [  0   0  86 102   0]
 [  0   0   0   2   0]]
0.4300185625954452
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        39
          A2       0.55      0.07      0.13       243
          B1       0.45      0.87      0.59       328
          B2       0.74      0.54      0.63       188
          C1       0.00      0.00      0.00         2

    accuracy                           0.51       800
   macro avg       0.35      0.30      0.27       800
weighted avg       0.52      0.51      0.43       800


0.45125
[[  0  18  14   6   1]
 [  2  84 140  16   1]
 [  4  37 189  78  20]
 [  1   8  44  87  48]
 [  0   0   0   1   1]]
0.45641989175208353
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        39
          A2       0.57      0.35      0.43       243
          B1       0.49      0.58      0.53       328
          B2       0.46      0.46      0.46       188
          C1       0.01      0.50      0.03         2

    accuracy                           0.45       800
   macro avg       0.31      0.38      0.29       800
weighted avg       0.48      0.45      0.46       800


0.56
[[  4  23   9   2   1]
 [  6 126 101  10   0]
 [  5  48 191  80   4]
 [  1   5  42 126  14]
 [  0   0   0   1   1]]
0.5582459199684289
              precision    recall  f1-score   support

          A1       0.25      0.10      0.15        39
          A2       0.62      0.52      0.57       243
          B1       0.56      0.58      0.57       328
          B2       0.58      0.67      0.62       188
          C1       0.05      0.50      0.09         2

    accuracy                           0.56       800
   macro avg       0.41      0.47      0.40       800
weighted avg       0.57      0.56      0.56       800


DE Train, CZ Test
CROSS LANG EVAL
0.5529953917050692
[[  0   0   7   1   0]
 [  0   2 112  18   0]
 [  0   0 115  26   0]
 [  0   7  11 123   2]
 [  0   0   0  10   0]]
0.45472122105816487
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         8
          A2       0.22      0.02      0.03       132
          B1       0.47      0.82      0.60       141
          B2       0.69      0.86      0.77       143
          C1       0.00      0.00      0.00        10

    accuracy                           0.55       434
   macro avg       0.28      0.34      0.28       434
weighted avg       0.45      0.55      0.45       434


0.32027649769585254
[[  0   0   1   7   0]
 [  1   0  43  87   1]
 [  1   0  31 106   3]
 [  0   0   1 104  38]
 [  0   0   0   6   4]]
0.24740629001012926
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         8
          A2       0.00      0.00      0.00       132
          B1       0.41      0.22      0.29       141
          B2       0.34      0.73      0.46       143
          C1       0.09      0.40      0.14        10

    accuracy                           0.32       434
   macro avg       0.17      0.27      0.18       434
weighted avg       0.25      0.32      0.25       434


0.44930875576036866
[[ 2  1  3  2  0]
 [ 3  3 91 35  0]
 [ 1  0 87 50  3]
 [ 0  0  6 98 39]
 [ 0  0  0  5  5]]
0.3890105491206551
              precision    recall  f1-score   support

          A1       0.33      0.25      0.29         8
          A2       0.75      0.02      0.04       132
          B1       0.47      0.62      0.53       141
          B2       0.52      0.69      0.59       143
          C1       0.11      0.50      0.18        10

    accuracy                           0.45       434
   macro avg       0.43      0.42      0.32       434
weighted avg       0.56      0.45      0.39       434


************for dimension:  Vocabularycontrol  ***************
DE Train, IT Test
CROSS LANG EVAL
0.4725
[[  0  34  36   0   0]
 [  0  73 127   4   0]
 [  0  66 236  25   0]
 [  0   8 119  69   0]
 [  0   0   1   2   0]]
0.43897391706434263
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        70
          A2       0.40      0.36      0.38       204
          B1       0.45      0.72      0.56       327
          B2       0.69      0.35      0.47       196
          C1       0.00      0.00      0.00         3

    accuracy                           0.47       800
   macro avg       0.31      0.29      0.28       800
weighted avg       0.46      0.47      0.44       800


0.395
[[  0  57   7   6   0]
 [  1 149  15  36   3]
 [  1 121  37 145  23]
 [  0  22   5 130  39]
 [  0   0   0   3   0]]
0.33822305232392325
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        70
          A2       0.43      0.73      0.54       204
          B1       0.58      0.11      0.19       327
          B2       0.41      0.66      0.50       196
          C1       0.00      0.00      0.00         3

    accuracy                           0.40       800
   macro avg       0.28      0.30      0.25       800
weighted avg       0.44      0.40      0.34       800


0.50125
[[  2  45  23   0   0]
 [  5 121  73   4   1]
 [  6  74 181  57   9]
 [  2   4  66  97  27]
 [  0   0   1   2   0]]
0.49589230248375415
              precision    recall  f1-score   support

          A1       0.13      0.03      0.05        70
          A2       0.50      0.59      0.54       204
          B1       0.53      0.55      0.54       327
          B2       0.61      0.49      0.54       196
          C1       0.00      0.00      0.00         3

    accuracy                           0.50       800
   macro avg       0.35      0.33      0.33       800
weighted avg       0.50      0.50      0.50       800


DE Train, CZ Test
CROSS LANG EVAL
0.43317972350230416
[[  0   2   3   0   0]
 [  0  14 106  11   0]
 [  0  10 104  68   0]
 [  0   5  25  70   0]
 [  0   0   1  15   0]]
0.3815472770597538
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         5
          A2       0.45      0.11      0.17       131
          B1       0.44      0.57      0.49       182
          B2       0.43      0.70      0.53       100
          C1       0.00      0.00      0.00        16

    accuracy                           0.43       434
   macro avg       0.26      0.28      0.24       434
weighted avg       0.42      0.43      0.38       434


0.30414746543778803
[[ 0  3  2  0  0]
 [ 3 16 57 53  2]
 [ 1 15 62 82 22]
 [ 0  4 23 46 27]
 [ 0  0  2  6  8]]
0.29741634617245233
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         5
          A2       0.42      0.12      0.19       131
          B1       0.42      0.34      0.38       182
          B2       0.25      0.46      0.32       100
          C1       0.14      0.50      0.21        16

    accuracy                           0.30       434
   macro avg       0.25      0.28      0.22       434
weighted avg       0.37      0.30      0.30       434


0.4078341013824885
[[  0   2   3   0   0   0]
 [  1   8 115   7   0   0]
 [  1   9 123  38  11   0]
 [  0   1  45  38  15   1]
 [  0   0   7   1   8   0]
 [  0   0   0   0   0   0]]
0.35613360514593745
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         5
          A2       0.40      0.06      0.11       131
          B1       0.42      0.68      0.52       182
          B2       0.45      0.38      0.41       100
          C1       0.24      0.50      0.32        16
          C2       0.00      0.00      0.00         0

    accuracy                           0.41       434
   macro avg       0.25      0.27      0.23       434
weighted avg       0.41      0.41      0.36       434


************for dimension:  CoherenceCohesion  ***************
DE Train, IT Test
CROSS LANG EVAL
0.38875
[[  0  12  96   1]
 [  0  35 295   4]
 [  0   2 252  46]
 [  0   0  33  24]]
0.29586211492141806
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00       109
          A2       0.71      0.10      0.18       334
          B1       0.37      0.84      0.52       300
          B2       0.32      0.42      0.36        57

    accuracy                           0.39       800
   macro avg       0.35      0.34      0.27       800
weighted avg       0.46      0.39      0.30       800


0.35375
[[ 37  19  45   4   4]
 [ 59  58 193  13  11]
 [  4  13 173  72  38]
 [  0   0  22  15  20]
 [  0   0   0   0   0]]
0.3527520007313158
              precision    recall  f1-score   support

          A1       0.37      0.34      0.35       109
          A2       0.64      0.17      0.27       334
          B1       0.40      0.58      0.47       300
          B2       0.14      0.26      0.19        57
          C1       0.00      0.00      0.00         0

    accuracy                           0.35       800
   macro avg       0.31      0.27      0.26       800
weighted avg       0.48      0.35      0.35       800


0.3975
[[ 27  42  38   1   1]
 [ 48 108 166   2  10]
 [  5  17 171  51  56]
 [  1   0  20  12  24]
 [  0   0   0   0   0]]
0.41715849733563604
              precision    recall  f1-score   support

          A1       0.33      0.25      0.28       109
          A2       0.65      0.32      0.43       334
          B1       0.43      0.57      0.49       300
          B2       0.18      0.21      0.20        57
          C1       0.00      0.00      0.00         0

    accuracy                           0.40       800
   macro avg       0.32      0.27      0.28       800
weighted avg       0.49      0.40      0.42       800


DE Train, CZ Test
CROSS LANG EVAL
0.6497695852534562
[[  0   0   1   0   0]
 [  0   3  90   8   0]
 [  0   0 141  30   0]
 [  0   0  18 138   0]
 [  0   0   0   5   0]]
0.5717306498821416
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       1.00      0.03      0.06       101
          B1       0.56      0.82      0.67       171
          B2       0.76      0.88      0.82       156
          C1       0.00      0.00      0.00         5

    accuracy                           0.65       434
   macro avg       0.47      0.35      0.31       434
weighted avg       0.73      0.65      0.57       434


0.24193548387096775
[[  0   0   1   0   0   0]
 [  4   8  47  33   9   0]
 [  1   8  81  38  43   0]
 [  0   2  29  11 112   2]
 [  0   0   0   0   5   0]
 [  0   0   0   0   0   0]]
0.25918885766031025
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.44      0.08      0.13       101
          B1       0.51      0.47      0.49       171
          B2       0.13      0.07      0.09       156
          C1       0.03      1.00      0.06         5
          C2       0.00      0.00      0.00         0

    accuracy                           0.24       434
   macro avg       0.19      0.27      0.13       434
weighted avg       0.35      0.24      0.26       434


0.3824884792626728
[[  0   1   0   0   0]
 [  3  10  84   1   3]
 [  1   9 133   6  22]
 [  0   1  23  18 114]
 [  0   0   0   0   5]]
0.3654195960255451
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00         1
          A2       0.48      0.10      0.16       101
          B1       0.55      0.78      0.65       171
          B2       0.72      0.12      0.20       156
          C1       0.03      1.00      0.07         5

    accuracy                           0.38       434
   macro avg       0.36      0.40      0.22       434
weighted avg       0.59      0.38      0.37       434


************for dimension:  Sociolinguisticappropriateness  ***************
DE Train, IT Test
CROSS LANG EVAL
0.38125
[[  0  32  23   1]
 [  0 144 159  33]
 [  0  50 133 189]
 [  0   0   8  28]]
0.4019830275524394
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00        56
          A2       0.64      0.43      0.51       336
          B1       0.41      0.36      0.38       372
          B2       0.11      0.78      0.20        36

    accuracy                           0.38       800
   macro avg       0.29      0.39      0.27       800
weighted avg       0.46      0.38      0.40       800


0.42875
[[  2  37  17   0   0]
 [  1 162 146  20   7]
 [  1  81 172  71  47]
 [  0   3  15   7  11]
 [  0   0   0   0   0]]
0.45075785485284636
              precision    recall  f1-score   support

          A1       0.50      0.04      0.07        56
          A2       0.57      0.48      0.52       336
          B1       0.49      0.46      0.48       372
          B2       0.07      0.19      0.10        36
          C1       0.00      0.00      0.00         0

    accuracy                           0.43       800
   macro avg       0.33      0.23      0.23       800
weighted avg       0.51      0.43      0.45       800


0.49
[[  2  36  18   0   0]
 [  9 168 147   6   6]
 [  1  69 219  47  36]
 [  0   2  21   3  10]
 [  0   0   0   0   0]]
0.5001416119056376
              precision    recall  f1-score   support

          A1       0.17      0.04      0.06        56
          A2       0.61      0.50      0.55       336
          B1       0.54      0.59      0.56       372
          B2       0.05      0.08      0.07        36
          C1       0.00      0.00      0.00         0

    accuracy                           0.49       800
   macro avg       0.27      0.24      0.25       800
weighted avg       0.52      0.49      0.50       800


DE Train, CZ Test
CROSS LANG EVAL
0.1359447004608295
[[  0  20  42 199]
 [  0  14  76  16]
 [  0  11  45   7]
 [  0   0   4   0]]
0.10209171210165052
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00       261
          A2       0.31      0.13      0.19       106
          B1       0.27      0.71      0.39        63
          B2       0.00      0.00      0.00         4

    accuracy                           0.14       434
   macro avg       0.15      0.21      0.14       434
weighted avg       0.12      0.14      0.10       434


0.10829493087557604
[[  0   1 184  38  38]
 [  1   1  83  21   0]
 [  0   0  45  17   1]
 [  0   0   3   1   0]
 [  0   0   0   0   0]]
0.03931273823746942
              precision    recall  f1-score   support

          A1       0.00      0.00      0.00       261
          A2       0.50      0.01      0.02       106
          B1       0.14      0.71      0.24        63
          B2       0.01      0.25      0.02         4
          C1       0.00      0.00      0.00         0

    accuracy                           0.11       434
   macro avg       0.13      0.19      0.06       434
weighted avg       0.14      0.11      0.04       434


0.12442396313364056
[[  1   2 106  67  85]
 [  3   2  88  12   1]
 [  0   1  50  11   1]
 [  0   0   3   1   0]
 [  0   0   0   0   0]]
0.060360420073851645
              precision    recall  f1-score   support

          A1       0.25      0.00      0.01       261
          A2       0.40      0.02      0.04       106
          B1       0.20      0.79      0.32        63
          B2       0.01      0.25      0.02         4
          C1       0.00      0.00      0.00         0

    accuracy                           0.12       434
   macro avg       0.17      0.21      0.08       434
weighted avg       0.28      0.12      0.06       434


0:20:28.255692
2020-10-05 00:50:18.696956
2020-10-05 01:10:46.952648
