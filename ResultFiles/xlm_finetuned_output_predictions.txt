There are 1 GPU(s) available.
We will use the GPU: Tesla V100-SXM2-16GB
MULTILINGUAL EXPERIMENTS
LANGUAGE: DE
130.68810916179336 82.83744971317162
LANGUAGE: CZ
144.90552995391704 65.35717405024758
LANGUAGE: IT
148.5775 138.9822884174455
LABEL SET ['A1', 'A2', 'B1', 'B2', 'C1']
1 Fold, Dimension = OverallCEFRrating

======== Epoch 1 / 4 ========
Training...
Elapsed time 9
Elapsed time 19
Elapsed time 28
Elapsed time 37
Elapsed time 47

  Average training loss: 0.92
  Training epoch took: 53
Running Validation...
  Average evaluation loss: 0.61
              precision    recall  f1-score   support

         0.0       0.00      0.00      0.00        17
         1.0       0.71      0.91      0.80       174
         2.0       0.82      0.63      0.72       177
         3.0       0.73      0.89      0.80        75
         4.0       0.00      0.00      0.00         9

    accuracy                           0.75       452
   macro avg       0.45      0.49      0.46       452
weighted avg       0.72      0.75      0.72       452

[[  0  16   1   0   0]
 [  0 159  15   0   0]
 [  0  49 112  16   0]
 [  0   0   8  67   0]
 [  0   0   0   9   0]]
0.7209639222660961



======== Epoch 2 / 4 ========
Training...
Elapsed time 9
Elapsed time 18
Elapsed time 28
Elapsed time 37
Elapsed time 46

  Average training loss: 0.58
  Training epoch took: 52
Running Validation...
  Average evaluation loss: 0.69
              precision    recall  f1-score   support

         0.0       1.00      0.06      0.11        17
         1.0       0.80      0.76      0.78       174
         2.0       0.75      0.77      0.76       177
         3.0       0.70      0.96      0.81        75
         4.0       0.00      0.00      0.00         9

    accuracy                           0.75       452
   macro avg       0.65      0.51      0.49       452
weighted avg       0.75      0.75      0.73       452

[[  1  15   1   0   0]
 [  0 132  42   0   0]
 [  0  19 136  22   0]
 [  0   0   3  72   0]
 [  0   0   0   9   0]]
0.7340149958570212



======== Epoch 3 / 4 ========
Training...
Elapsed time 9
Elapsed time 19
Elapsed time 28
Elapsed time 37
Elapsed time 46

  Average training loss: 0.48
  Training epoch took: 52
Running Validation...
  Average evaluation loss: 0.73
              precision    recall  f1-score   support

         0.0       1.00      0.06      0.11        17
         1.0       0.82      0.70      0.75       174
         2.0       0.70      0.87      0.78       177
         3.0       0.76      0.85      0.81        75
         4.0       0.00      0.00      0.00         9

    accuracy                           0.75       452
   macro avg       0.66      0.50      0.49       452
weighted avg       0.75      0.75      0.73       452

[[  1  15   1   0   0]
 [  0 121  53   0   0]
 [  0  12 154  11   0]
 [  0   0  11  64   0]
 [  0   0   0   9   0]]
0.7316440273927552



======== Epoch 4 / 4 ========
Training...
Elapsed time 9
Elapsed time 19
Elapsed time 28
Elapsed time 37
Elapsed time 46

  Average training loss: 0.37
  Training epoch took: 53
Running Validation...
  Average evaluation loss: 0.88
              precision    recall  f1-score   support

         0.0       0.43      0.18      0.25        17
         1.0       0.82      0.68      0.74       174
         2.0       0.71      0.76      0.73       177
         3.0       0.65      0.96      0.78        75
         4.0       0.00      0.00      0.00         9

    accuracy                           0.73       452
   macro avg       0.52      0.52      0.50       452
weighted avg       0.72      0.73      0.71       452

[[  3  13   1   0   0]
 [  4 118  52   0   0]
 [  0  13 135  29   0]
 [  0   0   3  72   0]
 [  0   0   0   9   0]]
0.7115588147895113
Filename	True Label	Prediction
1023_0001418	3.0	3.0
1023_0001419	3.0	3.0
1023_0001423	2.0	2.0
1023_0001575	3.0	3.0
1023_0101675	3.0	3.0
1023_0101684	2.0	3.0
1023_0101688	3.0	3.0
1023_0101694	3.0	3.0
1023_0101843	3.0	3.0
1023_0101844	2.0	3.0
1023_0101845	3.0	3.0
1023_0101856	2.0	2.0
1023_0101897	2.0	3.0
1023_0102118	3.0	3.0
1023_0103822	2.0	3.0
1023_0103826	3.0	3.0
1023_0103829	2.0	3.0
1023_0103833	4.0	3.0
1023_0103834	3.0	3.0
1023_0103836	3.0	3.0
1023_0103844	4.0	3.0
1023_0103883	3.0	3.0
1023_0107244	3.0	3.0
1023_0107726	3.0	3.0
1023_0108306	3.0	3.0
1023_0108648	3.0	3.0
1023_0108766	2.0	3.0
1023_0108886	3.0	3.0
1023_0108888	3.0	3.0
1023_0108993	3.0	3.0
1023_0109022	3.0	3.0
1023_0109395	2.0	3.0
1023_0109396	2.0	3.0
1023_0109402	2.0	3.0
1023_0109505	3.0	3.0
1023_0109518	2.0	3.0
1023_0109524	3.0	3.0
1023_0109528	3.0	3.0
1023_0109590	2.0	3.0
1023_0109606	3.0	3.0
1023_0109880	3.0	3.0
1023_0109945	3.0	3.0
1031_0001951	2.0	3.0
1031_0001997	3.0	3.0
1031_0002006	4.0	3.0
1031_0002036	4.0	3.0
1031_0002061	3.0	3.0
1031_0002086	3.0	3.0
1031_0002187	3.0	3.0
1031_0002196	3.0	3.0
1031_0002198	3.0	3.0
1031_0003053	3.0	3.0
1031_0003085	3.0	3.0
1031_0003095	3.0	3.0
1031_0003121	3.0	3.0
1031_0003132	3.0	3.0
1031_0003133	4.0	3.0
1031_0003140	3.0	3.0
1031_0003141	3.0	3.0
1031_0003146	4.0	3.0
1031_0003160	3.0	3.0
1031_0003166	2.0	2.0
1031_0003180	4.0	3.0
1031_0003191	3.0	3.0
1031_0003216	3.0	3.0
1031_0003217	4.0	3.0
1031_0003220	3.0	3.0
1031_0003224	3.0	3.0
1031_0003234	3.0	3.0
1031_0003236	3.0	3.0
1031_0003239	4.0	3.0
1031_0003240	2.0	3.0
1031_0003242	3.0	3.0
1031_0003249	3.0	3.0
1031_0003261	3.0	3.0
1031_0003331	3.0	3.0
1031_0003336	3.0	3.0
1031_0003355	3.0	3.0
1031_0003365	3.0	3.0
1031_0003368	3.0	3.0
1031_0003386	2.0	3.0
1031_0003389	3.0	3.0
1031_0003407	3.0	3.0
1061_0120282	0.0	1.0
1061_0120286	1.0	1.0
1061_0120295	0.0	2.0
1061_0120297	2.0	2.0
1061_0120298	2.0	2.0
1061_0120302	1.0	2.0
1061_0120311	3.0	2.0
1061_0120314	2.0	2.0
1061_0120318	2.0	2.0
1061_0120324	2.0	2.0
1061_0120328	1.0	1.0
1061_0120329	2.0	2.0
1061_0120371	3.0	3.0
1061_0120373	2.0	2.0
1061_0120375	2.0	1.0
1061_0120391	1.0	1.0
1061_0120403	3.0	2.0
1061_0120404	1.0	1.0
1061_0120430	2.0	2.0
1061_0120439	1.0	1.0
1061_0120460	2.0	2.0
1061_0120481	3.0	3.0
1061_0120482	2.0	2.0
1061_0120484	2.0	3.0
1061_0120491	2.0	2.0
1061_0120853	2.0	2.0
1061_0120855	1.0	2.0
1061_0120857	2.0	2.0
1061_0120881	2.0	3.0
1061_0120885	2.0	3.0
1061_1029119	1.0	2.0
1061_1202910	2.0	2.0
1061_1202911	1.0	2.0
1061_1202913	2.0	2.0
1071_0024680	2.0	2.0
1071_0024682	2.0	2.0
1071_0024686	2.0	2.0
1071_0024688	1.0	1.0
1071_0024690	1.0	2.0
1071_0024693	1.0	1.0
1071_0024694	1.0	2.0
1071_0024704	1.0	1.0
1071_0024705	1.0	2.0
1071_0024712	1.0	1.0
1071_0024714	2.0	1.0
1071_0024756	1.0	1.0
1071_0024765	0.0	1.0
1071_0024770	1.0	1.0
1071_0024779	1.0	1.0
1071_0024801	1.0	1.0
1071_0024813	0.0	1.0
1071_0024815	0.0	1.0
1071_0024825	1.0	1.0
1071_0024831	0.0	1.0
1071_0024840	1.0	1.0
1071_0024855	1.0	1.0
1071_0024856	1.0	1.0
1071_0024859	1.0	1.0
1071_0024874	1.0	1.0
1071_0024876	1.0	1.0
1071_0242022	0.0	1.0
1071_0242073	1.0	1.0
1071_0243581	1.0	1.0
1071_0248310	1.0	1.0
1071_0248317	0.0	0.0
1071_0248327	0.0	1.0
1071_0248329	1.0	1.0
1071_0248338	1.0	1.0
1071_0248347	1.0	0.0
1071_0248350	1.0	0.0
1091_0000001	1.0	1.0
1091_0000002	2.0	2.0
1091_0000009	0.0	1.0
1091_0000015	1.0	2.0
1091_0000016	0.0	1.0
1091_0000017	2.0	2.0
1091_0000019	1.0	2.0
1091_0000020	1.0	2.0
1091_0000021	2.0	3.0
1091_0000023	1.0	1.0
1091_0000027	2.0	1.0
1091_0000030	1.0	1.0
1091_0000035	1.0	1.0
1091_0000042	0.0	0.0
1091_0000043	1.0	2.0
1091_0000050	1.0	1.0
1091_0000054	1.0	1.0
1091_0000071	2.0	2.0
1091_0000116	2.0	2.0
1091_0000146	1.0	0.0
1091_0000151	1.0	1.0
1091_0000153	2.0	2.0
1091_0000155	2.0	3.0
1091_0000158	2.0	2.0
1091_0000159	2.0	2.0
1091_0000164	1.0	1.0
1091_0000165	1.0	2.0
1091_0000168	2.0	3.0
1091_0000172	2.0	1.0
1091_0000190	1.0	2.0
1091_0000195	1.0	1.0
1091_0000197	2.0	2.0
1091_0000204	1.0	2.0
1091_0000206	1.0	1.0
1091_0000207	2.0	2.0
1091_0000211	2.0	2.0
1091_0000213	1.0	2.0
1091_0000214	1.0	1.0
1091_0000215	2.0	2.0
1091_0000217	1.0	1.0
1091_0000218	1.0	1.0
1091_0000224	1.0	1.0
1091_0000233	1.0	2.0
1091_0000237	2.0	2.0
1091_0000248	1.0	1.0
1091_0000251	2.0	2.0
1091_0000252	2.0	2.0
1091_0000258	2.0	2.0
1091_0000262	1.0	2.0
1091_0000263	2.0	2.0
1091_0000264	1.0	1.0
1091_0000269	2.0	2.0
1091_0000272	1.0	2.0
1091_0000275	1.0	2.0
0611	2.0	1.0
0613	1.0	1.0
0623	1.0	1.0
0625	1.0	1.0
0633	2.0	2.0
0642	1.0	2.0
0644	1.0	2.0
0714	2.0	2.0
0715	2.0	2.0
0716	2.0	2.0
0719	2.0	1.0
0723	1.0	2.0
0802	1.0	2.0
0812	1.0	1.0
0813	1.0	1.0
0816	2.0	2.0
0825	1.0	2.0
0827	1.0	1.0
0924	1.0	1.0
0930	1.0	2.0
1003	1.0	1.0
1005	1.0	1.0
1014	2.0	2.0
1022	2.0	1.0
1023	1.0	2.0
BER0609003	2.0	2.0
LIB0611004A	1.0	1.0
MOS0509004	2.0	1.0
MOS0611015	2.0	3.0
PAR1011008A	1.0	1.0
PAR1011009A	1.0	2.0
PAR1011013	2.0	3.0
PAR1011014	2.0	3.0
PAR1011015	2.0	2.0
PAR1011016	3.0	3.0
PHA0111001A	1.0	1.0
PHA0111014	1.0	2.0
PHA0112003A	1.0	1.0
PHA0112003B	1.0	1.0
PHA0112006A	2.0	2.0
PHA0112006B	2.0	2.0
PHA0112009A	2.0	2.0
PHA0209013	1.0	1.0
PHA0209026	3.0	3.0
PHA0209034	2.0	3.0
PHA0209038	3.0	3.0
PHA0411008A	1.0	2.0
PHA0411011B	1.0	2.0
PHA0411012A	1.0	1.0
PHA0411030	3.0	3.0
PHA0411033	2.0	2.0
PHA0411036	3.0	2.0
PHA0411042	2.0	3.0
PHA0411045	2.0	2.0
PHA0411056	3.0	3.0
PHA0509017	2.0	3.0
PHA0509018	3.0	3.0
PHA0509019	2.0	3.0
PHA0509020	3.0	3.0
PHA0509022	3.0	3.0
PHA0509031	2.0	3.0
PHA0509044	2.0	2.0
PHA0510002A	1.0	1.0
PHA0510003A	1.0	1.0
PHA0510013B	1.0	1.0
PHA0510035	3.0	3.0
PHA0610005B	1.0	1.0
PHA0610006A	1.0	1.0
PHA0610017	3.0	3.0
PHA0710019	3.0	3.0
PHA0809010	2.0	2.0
PHA0810006	2.0	2.0
PHA0810008	2.0	3.0
PHA0811010	2.0	2.0
PHA0811014	2.0	2.0
PHA1109002	3.0	3.0
PHA1109007	2.0	2.0
PHA1110001A	1.0	1.0
PHA1110004A	1.0	1.0
PHA1111002A	1.0	1.0
PHA1111003A	1.0	1.0
PHA1111004B	1.0	1.0
PHA1111008B	1.0	1.0
VAR0909005	2.0	2.0
VAR0909008	2.0	2.0
VAR0909009	3.0	3.0
1325_1001014	2.0	2.0
1325_1001018	2.0	2.0
1325_1001024	2.0	2.0
1325_1001025	2.0	2.0
1325_1001035	2.0	2.0
1325_1001036	2.0	2.0
1325_1001040	2.0	2.0
1325_1001051	2.0	2.0
1325_1001057	2.0	2.0
1325_1001063	2.0	2.0
1325_1001075	1.0	2.0
1325_1001084	2.0	2.0
1325_1001085	2.0	2.0
1325_1001091	2.0	2.0
1325_1001093	2.0	2.0
1325_1001096	2.0	2.0
1325_1001123	2.0	2.0
1325_1001125	2.0	2.0
1325_1001127	2.0	2.0
1325_1001129	1.0	2.0
1325_1001134	2.0	2.0
1325_1001141	1.0	2.0
1325_1001159	2.0	2.0
1325_1001160	2.0	2.0
1325_1001162	2.0	2.0
1325_1001167	2.0	2.0
1325_1001170	2.0	2.0
1325_9000088	2.0	2.0
1325_9000089	2.0	2.0
1325_9000095	2.0	2.0
1325_9000105	2.0	2.0
1325_9000106	2.0	2.0
1325_9000137	2.0	2.0
1325_9000140	2.0	2.0
1325_9000211	2.0	2.0
1325_9000213	2.0	2.0
1325_9000214	2.0	2.0
1325_9000240	2.0	2.0
1325_9000296	2.0	2.0
1325_9000315	1.0	2.0
1325_9000316	2.0	2.0
1325_9000323	2.0	2.0
1325_9000505	2.0	2.0
1325_9000554	2.0	2.0
1325_9000675	2.0	2.0
1365_0100003	1.0	1.0
1365_0100004	1.0	2.0
1365_0100008	1.0	2.0
1365_0100009	1.0	1.0
1365_0100011	2.0	2.0
1365_0100014	2.0	2.0
1365_0100016	2.0	2.0
1365_0100017	2.0	2.0
1365_0100021	2.0	2.0
1365_0100024	1.0	2.0
1365_0100061	2.0	2.0
1365_0100065	1.0	2.0
1365_0100071	2.0	2.0
1365_0100079	2.0	2.0
1365_0100095	2.0	2.0
1365_0100096	2.0	2.0
1365_0100104	1.0	2.0
1365_0100106	1.0	2.0
1365_0100133	2.0	2.0
1365_0100139	2.0	2.0
1365_0100145	2.0	2.0
1365_0100169	2.0	2.0
1365_0100170	1.0	2.0
1365_0100191	1.0	2.0
1365_0100195	1.0	1.0
1365_0100196	1.0	2.0
1365_0100201	2.0	2.0
1365_0100202	1.0	2.0
1365_0100217	2.0	2.0
1365_0100226	2.0	2.0
1365_0100251	2.0	2.0
1365_0100255	1.0	2.0
1365_0100265	2.0	2.0
1365_0100270	2.0	2.0
1365_0100275	2.0	2.0
1365_0100277	2.0	2.0
1365_0100286	1.0	2.0
1365_0100447	2.0	2.0
1365_0100457	2.0	2.0
1365_0100458	2.0	2.0
1365_0100461	2.0	2.0
1365_0100477	1.0	2.0
1365_0100481	2.0	2.0
1385_0000021	1.0	1.0
1385_0000033	1.0	1.0
1385_0000039	1.0	1.0
1385_0000051	1.0	1.0
1385_0000057	1.0	1.0
1385_0000098	1.0	1.0
1385_0000101	1.0	1.0
1385_0000120	0.0	0.0
1385_0000127	1.0	1.0
1385_0000130	1.0	1.0
1385_0001111	1.0	1.0
1385_0001126	0.0	1.0
1385_0001130	1.0	0.0
1385_0001132	1.0	1.0
1385_0001149	1.0	1.0
1385_0001153	2.0	2.0
1385_0001158	1.0	1.0
1385_0001160	1.0	2.0
1385_0001161	1.0	1.0
1385_0001164	1.0	1.0
1385_0001178	0.0	1.0
1385_0001190	1.0	1.0
1385_0001522	1.0	1.0
1385_0001526	0.0	1.0
1385_0001712	1.0	2.0
1385_0001715	1.0	1.0
1385_0001730	2.0	1.0
1385_0001737	1.0	1.0
1385_0001742	0.0	1.0
1385_0001759	1.0	1.0
1385_0001766	1.0	2.0
1385_0001787	1.0	1.0
1385_0001789	1.0	1.0
1385_0001792	1.0	1.0
1395_0000353	1.0	1.0
1395_0000365	2.0	2.0
1395_0000366	2.0	1.0
1395_0000387	2.0	2.0
1395_0000388	2.0	2.0
1395_0000390	1.0	1.0
1395_0000403	1.0	1.0
1395_0000413	1.0	2.0
1395_0000449	2.0	2.0
1395_0000451	1.0	1.0
1395_0000452	1.0	1.0
1395_0000462	2.0	1.0
1395_0000512	1.0	1.0
1395_0000528	2.0	1.0
1395_0000552	1.0	2.0
1395_0000555	1.0	1.0
1395_0000564	1.0	1.0
1395_0000572	1.0	1.0
1395_0000597	1.0	1.0
1395_0000606	1.0	1.0
1395_0000607	1.0	1.0
1395_0000610	1.0	1.0
1395_0000636	1.0	1.0
1395_0000642	1.0	1.0
1395_0001010	2.0	1.0
1395_0001015	1.0	1.0
1395_0001023	1.0	1.0
1395_0001058	1.0	1.0
1395_0001070	2.0	2.0
1395_0001078	1.0	1.0
1395_0001080	1.0	1.0
1395_0001101	1.0	1.0
1395_0001103	1.0	1.0
1395_0001119	2.0	2.0
1395_0001141	1.0	1.0
1395_0001145	2.0	2.0
1395_0001171	1.0	1.0
2 Fold, Dimension = OverallCEFRrating

======== Epoch 1 / 4 ========
Training...
Elapsed time 9
Elapsed time 19
Elapsed time 28
Elapsed time 37
Elapsed time 47

  Average training loss: 0.97
  Training epoch took: 53
Running Validation...
  Average evaluation loss: 0.69
              precision    recall  f1-score   support

         0.0       0.00      0.00      0.00        17
         1.0       0.81      0.76      0.78       175
         2.0       0.72      0.81      0.76       177
         3.0       0.69      0.81      0.74        75
         4.0       0.00      0.00      0.00         8

    accuracy                           0.75       452
   macro avg       0.44      0.48      0.46       452
weighted avg       0.71      0.75      0.73       452

[[  0  17   0   0   0]
 [  0 133  42   0   0]
 [  0  14 143  20   0]
 [  0   0  14  61   0]
 [  0   0   0   8   0]]
0.7250913625409793



======== Epoch 2 / 4 ========
Training...
Elapsed time 9
Elapsed time 19
Elapsed time 28
Elapsed time 37
Elapsed time 47

  Average training loss: 0.62
  Training epoch took: 53
Running Validation...
  Average evaluation loss: 0.64
              precision    recall  f1-score   support

         0.0       0.00      0.00      0.00        17
         1.0       0.81      0.80      0.81       175
         2.0       0.76      0.74      0.75       177
         3.0       0.64      0.92      0.75        75
         4.0       0.00      0.00      0.00         8

    accuracy                           0.75       452
   macro avg       0.44      0.49      0.46       452
weighted avg       0.72      0.75      0.73       452

[[  0  17   0   0   0]
 [  0 140  35   0   0]
 [  0  15 131  31   0]
 [  0   0   6  69   0]
 [  0   0   0   8   0]]
0.7315144746015384



======== Epoch 3 / 4 ========
Training...
Elapsed time 9
Elapsed time 19
Elapsed time 28
Elapsed time 38
Elapsed time 47

  Average training loss: 0.50
  Training epoch took: 53
Running Validation...
  Average evaluation loss: 0.62
              precision    recall  f1-score   support

         0.0       1.00      0.18      0.30        17
         1.0       0.88      0.78      0.83       175
         2.0       0.76      0.80      0.78       177
         3.0       0.65      0.92      0.76        75
         4.0       0.00      0.00      0.00         8

    accuracy                           0.78       452
   macro avg       0.66      0.54      0.53       452
weighted avg       0.78      0.78      0.76       452

[[  3  12   2   0   0]
 [  0 137  38   0   0]
 [  0   6 142  29   0]
 [  0   0   6  69   0]
 [  0   0   0   8   0]]
0.7639511032969573



======== Epoch 4 / 4 ========
Training...
Elapsed time 9
Elapsed time 19
Elapsed time 28
Elapsed time 38
Elapsed time 47

  Average training loss: 0.38
  Training epoch took: 53
Running Validation...
  Average evaluation loss: 0.65
              precision    recall  f1-score   support

         0.0       0.80      0.24      0.36        17
         1.0       0.89      0.77      0.83       175
         2.0       0.76      0.81      0.78       177
         3.0       0.65      0.93      0.77        75
         4.0       0.00      0.00      0.00         8

    accuracy                           0.78       452
   macro avg       0.62      0.55      0.55       452
weighted avg       0.78      0.78      0.77       452

[[  4  11   2   0   0]
 [  1 135  39   0   0]
 [  0   5 143  29   0]
 [  0   0   5  70   0]
 [  0   0   0   8   0]]
0.7679740079440496
Filename	True Label	Prediction
1023_0001420	3.0	3.0
1023_0101683	3.0	3.0
1023_0101689	2.0	2.0
1023_0101690	2.0	2.0
1023_0101691	3.0	3.0
1023_0101693	3.0	3.0
1023_0101749	3.0	3.0
1023_0101847	3.0	3.0
1023_0101851	3.0	3.0
1023_0101893	3.0	3.0
1023_0101894	2.0	3.0
1023_0101907	3.0	3.0
1023_0103821	3.0	3.0
1023_0103823	3.0	3.0
1023_0103824	3.0	3.0
1023_0103830	3.0	3.0
1023_0103831	3.0	3.0
1023_0103839	3.0	3.0
1023_0107075	2.0	3.0
1023_0107682	2.0	2.0
1023_0107725	2.0	3.0
1023_0107729	3.0	3.0
1023_0107784	2.0	2.0
1023_0107787	2.0	3.0
1023_0108423	3.0	2.0
1023_0108426	2.0	3.0
1023_0108641	4.0	3.0
1023_0108815	3.0	3.0
1023_0108889	3.0	3.0
1023_0108931	3.0	3.0
1023_0108935	2.0	3.0
1023_0109248	2.0	3.0
1023_0109249	3.0	3.0
1023_0109267	2.0	3.0
1023_0109399	2.0	3.0
1023_0109495	3.0	3.0
1023_0109500	2.0	3.0
1023_0109516	3.0	3.0
1023_0109614	2.0	2.0
1023_0109717	3.0	3.0
1023_0109890	3.0	3.0
1023_0109891	3.0	3.0
1023_0109947	2.0	3.0
1023_0109951	2.0	3.0
1031_0001949	3.0	3.0
1031_0002003	3.0	3.0
1031_0002005	3.0	3.0
1031_0002032	3.0	3.0
1031_0002040	4.0	3.0
1031_0002043	4.0	3.0
1031_0002084	3.0	3.0
1031_0002089	3.0	3.0
1031_0002195	3.0	3.0
1031_0003029	3.0	3.0
1031_0003063	4.0	3.0
1031_0003065	3.0	3.0
1031_0003071	3.0	3.0
1031_0003072	3.0	3.0
1031_0003078	3.0	3.0
1031_0003092	2.0	3.0
1031_0003098	4.0	3.0
1031_0003099	3.0	3.0
1031_0003128	4.0	3.0
1031_0003131	3.0	3.0
1031_0003136	4.0	3.0
1031_0003155	3.0	3.0
1031_0003163	3.0	3.0
1031_0003182	4.0	3.0
1031_0003186	3.0	3.0
1031_0003211	2.0	3.0
1031_0003212	2.0	3.0
1031_0003221	2.0	3.0
1031_0003238	3.0	3.0
1031_0003245	3.0	3.0
1031_0003310	3.0	3.0
1031_0003338	3.0	3.0
1031_0003367	3.0	3.0
1031_0003384	2.0	3.0
1031_0003387	3.0	3.0
1031_0003393	3.0	3.0
1031_0003414	3.0	3.0
1061_0012029	3.0	2.0
1061_0120274	1.0	1.0
1061_0120275	2.0	2.0
1061_0120276	2.0	2.0
1061_0120277	1.0	2.0
1061_0120279	1.0	2.0
1061_0120280	1.0	1.0
1061_0120285	1.0	2.0
1061_0120290	1.0	2.0
1061_0120312	1.0	1.0
1061_0120327	2.0	2.0
1061_0120334	2.0	2.0
1061_0120335	2.0	3.0
1061_0120343	2.0	2.0
1061_0120347	1.0	2.0
1061_0120352	1.0	1.0
1061_0120354	1.0	1.0
1061_0120355	1.0	2.0
1061_0120358	1.0	2.0
1061_0120359	1.0	2.0
1061_0120366	3.0	3.0
1061_0120374	2.0	2.0
1061_0120388	1.0	2.0
1061_0120410	2.0	2.0
1061_0120421	2.0	3.0
1061_0120438	2.0	3.0
1061_0120443	0.0	1.0
1061_0120449	2.0	2.0
1061_0120457	2.0	2.0
1061_0120458	3.0	3.0
1061_0120486	2.0	2.0
1061_0120492	2.0	3.0
1061_0120494	2.0	2.0
1061_0120495	2.0	2.0
1061_0120497	3.0	3.0
1061_0120498	2.0	3.0
1061_0120500	2.0	2.0
1061_0120858	2.0	2.0
1061_0120874	2.0	2.0
1061_0120880	3.0	3.0
1061_0120887	1.0	2.0
1061_1029111	2.0	2.0
1061_1029114	1.0	1.0
1061_1029116	1.0	2.0
1061_1202912	2.0	2.0
1071_0020001	1.0	1.0
1071_0024683	0.0	1.0
1071_0024689	1.0	1.0
1071_0024702	1.0	2.0
1071_0024709	2.0	2.0
1071_0024759	0.0	1.0
1071_0024775	0.0	0.0
1071_0024777	1.0	1.0
1071_0024778	0.0	1.0
1071_0024783	0.0	0.0
1071_0024799	2.0	2.0
1071_0024810	1.0	1.0
1071_0024819	1.0	1.0
1071_0024820	0.0	1.0
1071_0024821	1.0	1.0
1071_0024822	0.0	1.0
1071_0024823	1.0	1.0
1071_0024827	1.0	1.0
1071_0024837	0.0	1.0
1071_0024852	0.0	0.0
1071_0024860	1.0	1.0
1071_0024866	2.0	2.0
1071_0024871	1.0	1.0
1071_0241831	1.0	1.0
1071_0242021	1.0	1.0
1071_0242091	1.0	0.0
1071_0243501	1.0	1.0
1071_0248304	1.0	1.0
1071_0248316	1.0	1.0
1071_0248318	0.0	0.0
1071_0248319	0.0	1.0
1071_0248322	1.0	1.0
1071_0248339	1.0	1.0
1071_0248343	1.0	1.0
1071_0248345	1.0	1.0
1091_0000004	1.0	1.0
1091_0000007	2.0	2.0
1091_0000012	1.0	1.0
1091_0000025	1.0	1.0
1091_0000031	1.0	1.0
1091_0000038	1.0	1.0
1091_0000044	1.0	2.0
1091_0000053	1.0	1.0
1091_0000055	2.0	2.0
1091_0000062	1.0	2.0
1091_0000068	2.0	2.0
1091_0000073	1.0	1.0
1091_0000075	2.0	2.0
1091_0000076	3.0	2.0
1091_0000078	1.0	1.0
1091_0000079	2.0	2.0
1091_0000102	1.0	2.0
1091_0000113	2.0	2.0
1091_0000123	2.0	2.0
1091_0000144	1.0	1.0
1091_0000145	1.0	1.0
1091_0000185	1.0	1.0
1091_0000191	2.0	2.0
1091_0000193	1.0	1.0
1091_0000208	2.0	1.0
1091_0000209	1.0	1.0
1091_0000210	1.0	1.0
1091_0000216	2.0	2.0
1091_0000225	1.0	1.0
1091_0000227	1.0	2.0
1091_0000229	2.0	2.0
1091_0000238	1.0	2.0
1091_0000240	1.0	1.0
1091_0000241	1.0	1.0
1091_0000254	1.0	1.0
1091_0000255	1.0	1.0
1091_0000260	2.0	2.0
1091_0000266	2.0	2.0
1091_0000274	2.0	2.0
0608	1.0	1.0
0610	1.0	2.0
0615	1.0	1.0
0618	1.0	2.0
0619	2.0	1.0
0622	1.0	1.0
0624	2.0	2.0
0627	2.0	2.0
0804	1.0	1.0
0806	1.0	2.0
0808	1.0	2.0
0809	2.0	2.0
0818	1.0	2.0
0819	3.0	2.0
0823	2.0	2.0
0824	1.0	1.0
0826	1.0	1.0
0828	2.0	2.0
0901	2.0	2.0
0906	2.0	2.0
0922	1.0	1.0
0923	2.0	2.0
0928	2.0	2.0
1001	1.0	1.0
1002	2.0	2.0
1007	2.0	2.0
1010	1.0	2.0
1117	1.0	1.0
BER0611007	2.0	2.0
KYJ0611005A	1.0	1.0
KYJ0611006A	1.0	1.0
KYJ0611006B	1.0	1.0
LIB0611001B	1.0	1.0
MOS0509001	2.0	2.0
PHA0111001B	1.0	1.0
PHA0111004B	1.0	1.0
PHA0111005A	1.0	1.0
PHA0111005B	1.0	1.0
PHA0111015	3.0	3.0
PHA0111016	3.0	3.0
PHA0112009B	2.0	1.0
PHA0112012B	1.0	1.0
PHA0209028	2.0	2.0
PHA0210007	1.0	2.0
PHA0411010B	1.0	1.0
PHA0411011A	1.0	1.0
PHA0411012B	1.0	1.0
PHA0411032	2.0	3.0
PHA0411037	2.0	2.0
PHA0411039	2.0	3.0
PHA0411043	2.0	2.0
PHA0411044	3.0	3.0
PHA0411055	3.0	3.0
PHA0411060	2.0	3.0
PHA0411061	3.0	3.0
PHA0509007	1.0	1.0
PHA0509025	3.0	3.0
PHA0509026	3.0	3.0
PHA0509027	2.0	2.0
PHA0509034	2.0	3.0
PHA0509036	3.0	3.0
PHA0509039	3.0	3.0
PHA0509042	3.0	3.0
PHA0510002B	1.0	1.0
PHA0510003B	1.0	1.0
PHA0510023	3.0	3.0
PHA0510030	2.0	3.0
PHA0510036	3.0	3.0
PHA0510046	2.0	2.0
PHA0510050	2.0	3.0
PHA0610005A	1.0	1.0
PHA0610019A	1.0	1.0
PHA0709008	3.0	3.0
PHA0710011	3.0	3.0
PHA0710016	3.0	2.0
PHA0809009	2.0	2.0
PHA0810003	2.0	3.0
PHA0810004	2.0	2.0
PHA0810015	3.0	3.0
PHA1110002B	2.0	1.0
PHA1110015	3.0	3.0
PHA1110021	2.0	2.0
PHA1111001B	1.0	1.0
VAR0909007	2.0	2.0
1325_1001013	2.0	2.0
1325_1001017	2.0	2.0
1325_1001019	2.0	2.0
1325_1001032	2.0	2.0
1325_1001033	2.0	2.0
1325_1001037	2.0	2.0
1325_1001043	2.0	2.0
1325_1001044	2.0	2.0
1325_1001048	2.0	2.0
1325_1001055	2.0	2.0
1325_1001080	2.0	2.0
1325_1001086	2.0	2.0
1325_1001088	2.0	2.0
1325_1001092	2.0	2.0
1325_1001100	2.0	2.0
1325_1001108	2.0	2.0
1325_1001121	2.0	2.0
1325_1001124	2.0	2.0
1325_1001126	2.0	2.0
1325_1001128	2.0	2.0
1325_1001131	2.0	2.0
1325_1001139	2.0	2.0
1325_1001142	2.0	2.0
1325_1001156	2.0	2.0
1325_1001163	2.0	2.0
1325_1001164	2.0	2.0
1325_1001165	2.0	2.0
1325_9000059	2.0	2.0
1325_9000090	2.0	2.0
1325_9000102	2.0	2.0
1325_9000144	2.0	2.0
1325_9000186	2.0	2.0
1325_9000187	2.0	2.0
1325_9000210	1.0	2.0
1325_9000302	2.0	2.0
1325_9000318	2.0	2.0
1325_9000319	2.0	2.0
1325_9000678	2.0	2.0
1325_9000750	2.0	2.0
1365_0100005	1.0	2.0
1365_0100015	1.0	1.0
1365_0100018	1.0	2.0
1365_0100023	1.0	2.0
1365_0100029	1.0	1.0
1365_0100031	2.0	2.0
1365_0100066	1.0	2.0
1365_0100067	1.0	2.0
1365_0100073	2.0	2.0
1365_0100098	1.0	2.0
1365_0100107	2.0	2.0
1365_0100136	2.0	2.0
1365_0100146	2.0	2.0
1365_0100147	2.0	2.0
1365_0100148	2.0	2.0
1365_0100162	2.0	2.0
1365_0100168	2.0	2.0
1365_0100177	2.0	2.0
1365_0100179	2.0	2.0
1365_0100183	2.0	2.0
1365_0100187	2.0	2.0
1365_0100203	2.0	2.0
1365_0100223	2.0	2.0
1365_0100224	2.0	2.0
1365_0100229	2.0	2.0
1365_0100230	2.0	2.0
1365_0100252	2.0	2.0
1365_0100259	2.0	2.0
1365_0100260	2.0	2.0
1365_0100263	2.0	2.0
1365_0100266	2.0	2.0
1365_0100267	2.0	2.0
1365_0100269	2.0	2.0
1365_0100278	2.0	2.0
1365_0100279	2.0	2.0
1365_0100280	1.0	1.0
1365_0100282	2.0	2.0
1365_0100285	2.0	2.0
1365_0100290	2.0	2.0
1365_0100451	2.0	2.0
1365_0100456	2.0	2.0
1365_0100470	2.0	2.0
1365_0100471	1.0	2.0
1365_0100472	2.0	2.0
1365_0100473	2.0	2.0
1365_0100480	2.0	2.0
1385_0000016	1.0	1.0
1385_0000023	1.0	1.0
1385_0000036	1.0	1.0
1385_0000040	1.0	1.0
1385_0000042	1.0	1.0
1385_0000043	1.0	1.0
1385_0000044	1.0	1.0
1385_0000054	1.0	1.0
1385_0000099	1.0	1.0
1385_0000125	1.0	1.0
1385_0000126	1.0	1.0
1385_0001105	1.0	1.0
1385_0001109	1.0	1.0
1385_0001110	1.0	1.0
1385_0001118	1.0	1.0
1385_0001124	1.0	1.0
1385_0001127	1.0	1.0
1385_0001131	1.0	1.0
1385_0001138	1.0	1.0
1385_0001154	1.0	1.0
1385_0001167	1.0	1.0
1385_0001171	1.0	1.0
1385_0001191	1.0	1.0
1385_0001195	1.0	2.0
1385_0001197	1.0	1.0
1385_0001524	1.0	1.0
1385_0001527	1.0	1.0
1385_0001716	1.0	1.0
1385_0001719	1.0	1.0
1385_0001725	1.0	1.0
1385_0001736	2.0	2.0
1385_0001738	0.0	2.0
1385_0001739	1.0	1.0
1385_0001746	1.0	1.0
1385_0001747	1.0	1.0
1385_0001749	1.0	1.0
1385_0001760	1.0	1.0
1385_0001774	0.0	1.0
1385_0001785	1.0	1.0
1385_0001790	1.0	1.0
1395_0000337	0.0	1.0
1395_0000354	1.0	1.0
1395_0000361	1.0	2.0
1395_0000364	1.0	2.0
1395_0000376	2.0	2.0
1395_0000391	2.0	2.0
1395_0000398	2.0	2.0
1395_0000402	1.0	1.0
1395_0000438	2.0	2.0
1395_0000450	1.0	1.0
1395_0000454	1.0	2.0
1395_0000460	1.0	1.0
1395_0000465	1.0	1.0
1395_0000471	1.0	1.0
1395_0000513	2.0	2.0
1395_0000514	2.0	2.0
1395_0000531	1.0	1.0
1395_0000534	1.0	2.0
1395_0000549	1.0	2.0
1395_0000551	2.0	1.0
1395_0000554	1.0	1.0
1395_0000556	1.0	1.0
1395_0000557	2.0	2.0
1395_0000565	1.0	1.0
1395_0000575	1.0	1.0
1395_0000583	1.0	1.0
1395_0000591	0.0	1.0
1395_0000604	1.0	1.0
1395_0000611	1.0	1.0
1395_0000627	1.0	1.0
1395_0000631	1.0	2.0
1395_0001019	1.0	1.0
1395_0001020	1.0	1.0
1395_0001034	1.0	1.0
1395_0001067	1.0	1.0
1395_0001069	1.0	1.0
1395_0001074	1.0	1.0
1395_0001075	1.0	1.0
1395_0001084	1.0	1.0
1395_0001121	0.0	2.0
1395_0001132	2.0	2.0
1395_0001149	1.0	1.0
1395_0001150	1.0	1.0
3 Fold, Dimension = OverallCEFRrating

======== Epoch 1 / 4 ========
Training...
Elapsed time 9
Elapsed time 19
Elapsed time 28
Elapsed time 37
Elapsed time 47

  Average training loss: 0.85
  Training epoch took: 53
Running Validation...
  Average evaluation loss: 0.76
              precision    recall  f1-score   support

         0.0       0.00      0.00      0.00        17
         1.0       0.85      0.63      0.72       175
         2.0       0.69      0.82      0.75       177
         3.0       0.66      0.97      0.79        75
         4.0       0.00      0.00      0.00         8

    accuracy                           0.73       452
   macro avg       0.44      0.49      0.45       452
weighted avg       0.71      0.73      0.70       452

[[  0  17   0   0   0]
 [  0 110  64   1   0]
 [  0   3 146  28   0]
 [  0   0   2  73   0]
 [  0   0   0   8   0]]
0.7041647137152169



======== Epoch 2 / 4 ========
Training...
Elapsed time 9
Elapsed time 19
Elapsed time 28
Elapsed time 38
Elapsed time 47

  Average training loss: 0.57
  Training epoch took: 53
Running Validation...
  Average evaluation loss: 0.50
              precision    recall  f1-score   support

         0.0       1.00      0.18      0.30        17
         1.0       0.79      0.90      0.84       175
         2.0       0.84      0.80      0.82       177
         3.0       0.80      0.88      0.84        75
         4.0       0.00      0.00      0.00         8

    accuracy                           0.81       452
   macro avg       0.69      0.55      0.56       452
weighted avg       0.81      0.81      0.80       452

[[  3  14   0   0   0]
 [  0 157  18   0   0]
 [  0  27 141   9   0]
 [  0   0   9  66   0]
 [  0   0   0   8   0]]
0.7959192999341004



======== Epoch 3 / 4 ========
Training...
Elapsed time 9
Elapsed time 19
Elapsed time 28
Elapsed time 38
Elapsed time 47

  Average training loss: 0.43
  Training epoch took: 53
Running Validation...
  Average evaluation loss: 0.57
              precision    recall  f1-score   support

         0.0       0.60      0.18      0.27        17
         1.0       0.84      0.76      0.80       175
         2.0       0.78      0.86      0.82       177
         3.0       0.76      0.95      0.85        75
         4.0       0.00      0.00      0.00         8

    accuracy                           0.79       452
   macro avg       0.60      0.55      0.55       452
weighted avg       0.78      0.79      0.78       452

[[  3  14   0   0   0]
 [  2 133  40   0   0]
 [  0  11 152  14   0]
 [  0   0   4  71   0]
 [  0   0   0   8   0]]
0.7789300513786859



======== Epoch 4 / 4 ========
Training...
Elapsed time 9
Elapsed time 19
Elapsed time 28
Elapsed time 38
Elapsed time 47

  Average training loss: 0.31
  Training epoch took: 53
Running Validation...
  Average evaluation loss: 0.56
              precision    recall  f1-score   support

         0.0       0.67      0.24      0.35        17
         1.0       0.83      0.78      0.80       175
         2.0       0.78      0.85      0.81       177
         3.0       0.78      0.93      0.85        75
         4.0       0.00      0.00      0.00         8

    accuracy                           0.80       452
   macro avg       0.61      0.56      0.56       452
weighted avg       0.78      0.80      0.78       452

[[  4  13   0   0   0]
 [  2 136  37   0   0]
 [  0  15 150  12   0]
 [  0   0   5  70   0]
 [  0   0   0   8   0]]
0.7828867820576266
Filename	True Label	Prediction
1023_0101695	2.0	3.0
1023_0101700	3.0	3.0
1023_0101701	2.0	2.0
1023_0101841	2.0	3.0
1023_0101846	4.0	3.0
1023_0101848	2.0	2.0
1023_0101852	3.0	3.0
1023_0101854	2.0	2.0
1023_0101855	2.0	2.0
1023_0101898	3.0	3.0
1023_0101906	2.0	2.0
1023_0101909	4.0	3.0
1023_0103827	3.0	3.0
1023_0103841	3.0	3.0
1023_0103843	2.0	3.0
1023_0103880	3.0	3.0
1023_0103955	3.0	3.0
1023_0104203	3.0	3.0
1023_0104209	3.0	3.0
1023_0107672	2.0	3.0
1023_0107740	3.0	3.0
1023_0107780	3.0	3.0
1023_0107781	3.0	3.0
1023_0107788	3.0	3.0
1023_0108304	3.0	3.0
1023_0108307	3.0	3.0
1023_0108422	3.0	3.0
1023_0108649	3.0	3.0
1023_0108751	3.0	3.0
1023_0108811	3.0	3.0
1023_0108813	3.0	3.0
1023_0108885	2.0	2.0
1023_0108887	2.0	2.0
1023_0109029	1.0	2.0
1023_0109033	4.0	3.0
1023_0109038	3.0	3.0
1023_0109039	3.0	3.0
1023_0109096	3.0	3.0
1023_0109151	3.0	3.0
1023_0109247	3.0	3.0
1023_0109400	3.0	3.0
1023_0109522	3.0	3.0
1023_0109591	3.0	3.0
1023_0109651	3.0	3.0
1023_0109721	2.0	3.0
1023_0109917	3.0	3.0
1023_0109946	2.0	3.0
1031_0001703	4.0	3.0
1031_0001950	3.0	3.0
1031_0002088	3.0	3.0
1031_0002091	3.0	3.0
1031_0002092	4.0	3.0
1031_0002185	3.0	3.0
1031_0002199	3.0	3.0
1031_0003035	3.0	3.0
1031_0003043	4.0	3.0
1031_0003052	3.0	3.0
1031_0003054	3.0	3.0
1031_0003074	3.0	3.0
1031_0003076	4.0	3.0
1031_0003164	3.0	3.0
1031_0003170	3.0	3.0
1031_0003174	3.0	3.0
1031_0003185	3.0	2.0
1031_0003187	3.0	3.0
1031_0003189	3.0	3.0
1031_0003218	3.0	3.0
1031_0003237	3.0	3.0
1031_0003246	3.0	3.0
1031_0003273	3.0	3.0
1031_0003274	3.0	3.0
1031_0003313	3.0	3.0
1031_0003315	3.0	3.0
1031_0003327	2.0	3.0
1031_0003352	2.0	3.0
1031_0003356	3.0	3.0
1031_0003369	3.0	3.0
1031_0003388	3.0	3.0
1031_0003390	3.0	3.0
1031_0003392	3.0	3.0
1031_0003408	2.0	3.0
1031_0003409	4.0	3.0
1061_0120271	2.0	2.0
1061_0120278	2.0	2.0
1061_0120283	1.0	1.0
1061_0120287	1.0	2.0
1061_0120288	2.0	2.0
1061_0120291	1.0	1.0
1061_0120296	2.0	2.0
1061_0120299	2.0	2.0
1061_0120308	2.0	2.0
1061_0120313	2.0	1.0
1061_0120316	2.0	1.0
1061_0120317	2.0	2.0
1061_0120323	1.0	2.0
1061_0120326	2.0	2.0
1061_0120331	1.0	1.0
1061_0120336	1.0	2.0
1061_0120337	2.0	2.0
1061_0120346	2.0	2.0
1061_0120348	1.0	1.0
1061_0120356	2.0	2.0
1061_0120360	3.0	3.0
1061_0120367	3.0	2.0
1061_0120369	2.0	1.0
1061_0120370	2.0	2.0
1061_0120372	2.0	2.0
1061_0120383	2.0	3.0
1061_0120390	2.0	2.0
1061_0120411	3.0	3.0
1061_0120423	2.0	2.0
1061_0120441	2.0	2.0
1061_0120450	2.0	2.0
1061_0120455	2.0	2.0
1061_0120456	2.0	2.0
1061_0120478	2.0	2.0
1061_0120490	2.0	2.0
1061_0120499	2.0	2.0
1061_0120876	2.0	2.0
1061_0120877	2.0	2.0
1061_0120882	3.0	3.0
1061_0120883	2.0	2.0
1061_0120886	2.0	1.0
1061_0120889	1.0	1.0
1061_0120894	2.0	2.0
1061_1029117	1.0	2.0
1061_1029118	1.0	1.0
1061_1202914	1.0	1.0
1061_1202915	1.0	2.0
1061_1202918	1.0	2.0
1061_1202919	2.0	1.0
1071_0024678	1.0	1.0
1071_0024681	2.0	2.0
1071_0024685	2.0	2.0
1071_0024687	1.0	1.0
1071_0024692	2.0	2.0
1071_0024710	1.0	1.0
1071_0024711	1.0	1.0
1071_0024713	1.0	1.0
1071_0024757	2.0	1.0
1071_0024772	0.0	0.0
1071_0024802	1.0	2.0
1071_0024807	1.0	1.0
1071_0024809	1.0	1.0
1071_0024814	1.0	1.0
1071_0024816	1.0	1.0
1071_0024824	1.0	1.0
1071_0024826	1.0	1.0
1071_0024833	1.0	1.0
1071_0024834	2.0	2.0
1071_0024841	0.0	1.0
1071_0024850	1.0	1.0
1071_0024862	1.0	1.0
1071_0024864	0.0	0.0
1071_0024867	2.0	1.0
1071_0024873	1.0	1.0
1071_0024875	1.0	1.0
1071_0024878	2.0	2.0
1071_0024879	1.0	0.0
1071_0024881	2.0	1.0
1071_0241832	1.0	1.0
1071_0242011	1.0	1.0
1071_0242013	1.0	1.0
1071_0242041	1.0	1.0
1071_0242071	0.0	0.0
1071_0243582	1.0	1.0
1071_0248301	1.0	1.0
1071_0248302	1.0	1.0
1071_0248303	1.0	1.0
1071_0248308	1.0	1.0
1071_0248313	1.0	1.0
1071_0248320	0.0	0.0
1071_0248325	0.0	1.0
1071_0248326	1.0	1.0
1071_0248332	2.0	2.0
1071_0248333	2.0	1.0
1071_0248335	1.0	1.0
1071_0248342	1.0	1.0
1071_0248344	1.0	1.0
1091_0000003	2.0	1.0
1091_0000013	1.0	1.0
1091_0000029	1.0	2.0
1091_0000032	2.0	2.0
1091_0000033	1.0	1.0
1091_0000048	1.0	1.0
1091_0000051	0.0	1.0
1091_0000052	0.0	1.0
1091_0000060	2.0	2.0
1091_0000126	2.0	2.0
1091_0000127	1.0	2.0
1091_0000140	1.0	1.0
1091_0000154	2.0	2.0
1091_0000156	2.0	2.0
1091_0000160	1.0	2.0
1091_0000163	1.0	1.0
1091_0000170	2.0	1.0
1091_0000192	1.0	1.0
1091_0000199	2.0	2.0
1091_0000212	2.0	2.0
1091_0000220	2.0	2.0
1091_0000222	1.0	1.0
1091_0000223	2.0	2.0
1091_0000230	2.0	2.0
1091_0000231	2.0	2.0
1091_0000232	2.0	2.0
1091_0000234	2.0	2.0
1091_0000235	1.0	1.0
1091_0000239	2.0	1.0
1091_0000243	1.0	1.0
1091_0000245	2.0	2.0
1091_0000247	2.0	2.0
1091_0000249	2.0	2.0
1091_0000259	2.0	2.0
1091_0000270	1.0	1.0
0614	2.0	2.0
0620	1.0	2.0
0621	2.0	2.0
0626	2.0	1.0
0630	1.0	1.0
0631	2.0	2.0
0634	2.0	2.0
0636	2.0	2.0
0641	1.0	1.0
0643	2.0	2.0
0645	2.0	2.0
0720	1.0	1.0
0801	1.0	2.0
0807	2.0	2.0
0811	2.0	2.0
0814	1.0	1.0
0817	1.0	2.0
0820	1.0	1.0
0821	2.0	2.0
0822	1.0	2.0
0829	1.0	2.0
0902	2.0	2.0
0903	1.0	1.0
0904	1.0	1.0
0910	1.0	1.0
0911	1.0	1.0
0913	2.0	2.0
0915	2.0	2.0
0920	2.0	2.0
0921	1.0	1.0
0927	2.0	2.0
1006	2.0	2.0
1008	1.0	1.0
1009	2.0	1.0
1015	1.0	2.0
1018	1.0	1.0
1115	1.0	2.0
1116	1.0	2.0
BER0611005	2.0	3.0
KYJ0611003A	1.0	1.0
KYJ0611004A	1.0	1.0
KYJ0611009B	1.0	1.0
LIB0611001A	1.0	1.0
LIB0611002B	1.0	1.0
LIB0611003A	1.0	1.0
LIB0611004B	1.0	1.0
LON0610002A	1.0	1.0
LON0611002A	1.0	1.0
LON0611003	3.0	3.0
LON0611004A	1.0	1.0
LON0611004B	1.0	1.0
MOS0611012	2.0	2.0
PAR1011018	3.0	2.0
PHA0111018	2.0	2.0
PHA0112002A	1.0	1.0
PHA0112002B	1.0	2.0
PHA0411008B	1.0	1.0
PHA0411031	3.0	3.0
PHA0411054	3.0	2.0
PHA0509030	3.0	3.0
PHA0509033	1.0	2.0
PHA0509035	2.0	2.0
PHA0509037	3.0	3.0
PHA0509040	2.0	2.0
PHA0510010B	1.0	1.0
PHA0510031	2.0	2.0
PHA0510039	2.0	3.0
PHA0510047	2.0	2.0
PHA0610006B	1.0	1.0
PHA0610007A	1.0	1.0
PHA0710009	2.0	2.0
PHA0710013	3.0	3.0
PHA0810002	2.0	2.0
PHA0810012	2.0	2.0
PHA0811016	2.0	2.0
PHA0811017	3.0	3.0
PHA0811019	3.0	3.0
PHA1109004	3.0	3.0
PHA1109005	2.0	2.0
PHA1109027	3.0	2.0
PHA1110001B	1.0	1.0
PHA1110016	2.0	2.0
PHA1110022	3.0	3.0
PHA1111003B	1.0	1.0
PHA1111004A	1.0	2.0
PHA1111006A	1.0	1.0
PHA1111006B	1.0	1.0
PHA1111008A	1.0	1.0
ST071122B	1.0	1.0
VAR0909006	3.0	3.0
VAR0910005	2.0	2.0
VAR0910009	3.0	3.0
VAR0910011	2.0	2.0
1325_1001015	2.0	2.0
1325_1001028	2.0	2.0
1325_1001029	2.0	2.0
1325_1001042	2.0	2.0
1325_1001054	2.0	2.0
1325_1001058	2.0	2.0
1325_1001076	2.0	2.0
1325_1001077	2.0	2.0
1325_1001079	2.0	2.0
1325_1001089	2.0	2.0
1325_1001090	2.0	2.0
1325_1001095	2.0	2.0
1325_1001098	2.0	2.0
1325_1001101	2.0	2.0
1325_1001110	2.0	2.0
1325_1001113	2.0	2.0
1325_1001120	2.0	2.0
1325_1001132	2.0	2.0
1325_1001135	2.0	2.0
1325_1001152	2.0	2.0
1325_1001153	2.0	2.0
1325_1001154	2.0	2.0
1325_1001155	2.0	2.0
1325_1001157	2.0	2.0
1325_1001158	2.0	2.0
1325_1001166	2.0	2.0
1325_9000107	2.0	2.0
1325_9000279	2.0	2.0
1325_9000322	2.0	2.0
1325_9000504	2.0	2.0
1325_9000536	2.0	2.0
1325_9000602	2.0	2.0
1325_9000611	2.0	2.0
1365_0100010	1.0	1.0
1365_0100022	2.0	2.0
1365_0100026	1.0	1.0
1365_0100051	1.0	1.0
1365_0100057	2.0	2.0
1365_0100063	2.0	2.0
1365_0100064	2.0	2.0
1365_0100074	1.0	2.0
1365_0100093	2.0	2.0
1365_0100099	1.0	2.0
1365_0100105	2.0	2.0
1365_0100116	2.0	2.0
1365_0100117	2.0	2.0
1365_0100134	2.0	2.0
1365_0100135	2.0	2.0
1365_0100171	1.0	2.0
1365_0100182	2.0	2.0
1365_0100185	1.0	2.0
1365_0100205	2.0	2.0
1365_0100219	2.0	2.0
1365_0100221	2.0	2.0
1365_0100225	2.0	2.0
1365_0100253	1.0	1.0
1365_0100256	2.0	2.0
1365_0100262	2.0	2.0
1365_0100268	1.0	1.0
1365_0100274	2.0	2.0
1365_0100289	2.0	2.0
1365_0100455	2.0	2.0
1365_0100459	2.0	2.0
1365_0100469	2.0	2.0
1365_0100476	2.0	2.0
1365_0100479	2.0	2.0
1385_0000013	0.0	1.0
1385_0000017	1.0	0.0
1385_0000035	1.0	2.0
1385_0000041	1.0	1.0
1385_0000045	1.0	1.0
1385_0000100	1.0	1.0
1385_0000123	1.0	1.0
1385_0000128	1.0	1.0
1385_0001112	1.0	1.0
1385_0001121	1.0	1.0
1385_0001123	1.0	1.0
1385_0001128	0.0	1.0
1385_0001129	1.0	1.0
1385_0001137	1.0	1.0
1385_0001150	1.0	1.0
1385_0001155	1.0	1.0
1385_0001162	1.0	1.0
1385_0001163	1.0	1.0
1385_0001165	1.0	1.0
1385_0001166	1.0	1.0
1385_0001528	1.0	2.0
1385_0001718	1.0	1.0
1385_0001720	0.0	1.0
1385_0001723	0.0	1.0
1385_0001727	0.0	1.0
1385_0001728	1.0	2.0
1385_0001734	1.0	1.0
1385_0001750	0.0	1.0
1385_0001751	1.0	1.0
1385_0001758	1.0	1.0
1385_0001771	1.0	1.0
1385_0001772	1.0	1.0
1385_0001773	1.0	1.0
1385_0001791	1.0	1.0
1385_0001793	1.0	1.0
1385_0001796	1.0	1.0
1395_0000338	1.0	1.0
1395_0000340	1.0	2.0
1395_0000355	1.0	2.0
1395_0000359	1.0	2.0
1395_0000369	2.0	2.0
1395_0000378	1.0	1.0
1395_0000379	1.0	1.0
1395_0000380	1.0	2.0
1395_0000389	0.0	1.0
1395_0000396	1.0	2.0
1395_0000432	1.0	1.0
1395_0000448	1.0	1.0
1395_0000458	1.0	1.0
1395_0000499	1.0	1.0
1395_0000500	1.0	1.0
1395_0000518	2.0	2.0
1395_0000526	1.0	1.0
1395_0000535	1.0	1.0
1395_0000559	1.0	1.0
1395_0000563	1.0	1.0
1395_0000579	1.0	1.0
1395_0000582	0.0	1.0
1395_0000585	1.0	1.0
1395_0000587	0.0	1.0
1395_0000608	1.0	1.0
1395_0000649	2.0	2.0
1395_0001016	2.0	1.0
1395_0001017	1.0	1.0
1395_0001024	1.0	2.0
1395_0001040	1.0	1.0
1395_0001045	1.0	1.0
1395_0001073	2.0	2.0
1395_0001109	1.0	1.0
1395_0001114	1.0	1.0
1395_0001115	2.0	2.0
1395_0001117	1.0	1.0
1395_0001122	1.0	1.0
1395_0001123	1.0	1.0
1395_0001124	1.0	1.0
1395_0001160	2.0	2.0
1395_0001164	2.0	2.0
1395_0001167	1.0	2.0
1395_0001170	1.0	2.0
4 Fold, Dimension = OverallCEFRrating

======== Epoch 1 / 4 ========
Training...
Elapsed time 9
Elapsed time 19
Elapsed time 28
Elapsed time 38
Elapsed time 47

  Average training loss: 0.91
  Training epoch took: 53
Running Validation...
  Average evaluation loss: 0.64
              precision    recall  f1-score   support

         0.0       0.00      0.00      0.00        17
         1.0       0.73      0.93      0.81       175
         2.0       0.87      0.58      0.70       177
         3.0       0.65      0.96      0.77        75
         4.0       0.00      0.00      0.00         8

    accuracy                           0.75       452
   macro avg       0.45      0.49      0.46       452
weighted avg       0.73      0.75      0.72       452

[[  0  17   0   0   0]
 [  0 162  13   0   0]
 [  0  43 103  31   0]
 [  0   1   2  72   0]
 [  0   0   0   8   0]]
0.7170947515195158



======== Epoch 2 / 4 ========
Training...
Elapsed time 9
Elapsed time 19
Elapsed time 28
Elapsed time 38
Elapsed time 47

  Average training loss: 0.60
  Training epoch took: 53
Running Validation...
  Average evaluation loss: 0.59
              precision    recall  f1-score   support

         0.0       0.00      0.00      0.00        17
         1.0       0.74      0.87      0.80       175
         2.0       0.77      0.72      0.74       177
         3.0       0.74      0.79      0.76        75
         4.0       0.00      0.00      0.00         8

    accuracy                           0.75       452
   macro avg       0.45      0.48      0.46       452
weighted avg       0.71      0.75      0.73       452

[[  0  17   0   0   0]
 [  0 153  22   0   0]
 [  0  37 127  13   0]
 [  0   1  15  59   0]
 [  0   0   0   8   0]]
0.7273355061908552



======== Epoch 3 / 4 ========
Training...
Elapsed time 9
Elapsed time 19
Elapsed time 28
Elapsed time 38
Elapsed time 47

  Average training loss: 0.48
  Training epoch took: 53
Running Validation...
  Average evaluation loss: 0.59
              precision    recall  f1-score   support

         0.0       0.83      0.29      0.43        17
         1.0       0.80      0.80      0.80       175
         2.0       0.77      0.76      0.77       177
         3.0       0.70      0.91      0.79        75
         4.0       0.00      0.00      0.00         8

    accuracy                           0.77       452
   macro avg       0.62      0.55      0.56       452
weighted avg       0.76      0.77      0.76       452

[[  5  12   0   0   0]
 [  1 140  34   0   0]
 [  0  21 135  21   0]
 [  0   1   6  68   0]
 [  0   0   0   8   0]]
0.7585438529105577



======== Epoch 4 / 4 ========
Training...
Elapsed time 9
Elapsed time 19
Elapsed time 28
Elapsed time 38
Elapsed time 47

  Average training loss: 0.38
  Training epoch took: 53
Running Validation...
  Average evaluation loss: 0.71
              precision    recall  f1-score   support

         0.0       1.00      0.29      0.45        17
         1.0       0.85      0.66      0.74       175
         2.0       0.70      0.82      0.76       177
         3.0       0.70      0.95      0.81        75
         4.0       0.00      0.00      0.00         8

    accuracy                           0.75       452
   macro avg       0.65      0.55      0.55       452
weighted avg       0.76      0.75      0.74       452

[[  5  12   0   0   0]
 [  0 116  59   0   0]
 [  0   9 146  22   0]
 [  0   0   4  71   0]
 [  0   0   0   8   0]]
0.7350956074089298
Filename	True Label	Prediction
1023_0001416	3.0	3.0
1023_0101751	3.0	3.0
1023_0101752	3.0	3.0
1023_0101849	3.0	3.0
1023_0101853	2.0	3.0
1023_0101896	2.0	2.0
1023_0103832	2.0	2.0
1023_0103837	3.0	3.0
1023_0103838	3.0	3.0
1023_0104206	3.0	3.0
1023_0107042	3.0	3.0
1023_0107074	3.0	3.0
1023_0107783	3.0	2.0
1023_0108305	3.0	3.0
1023_0108650	3.0	3.0
1023_0108752	3.0	3.0
1023_0108753	2.0	2.0
1023_0108812	2.0	3.0
1023_0108814	3.0	3.0
1023_0108932	2.0	3.0
1023_0108933	3.0	3.0
1023_0108934	3.0	3.0
1023_0108955	3.0	3.0
1023_0108958	2.0	3.0
1023_0109027	2.0	2.0
1023_0109030	3.0	3.0
1023_0109391	2.0	3.0
1023_0109392	3.0	3.0
1023_0109401	3.0	3.0
1023_0109515	3.0	3.0
1023_0109588	3.0	3.0
1023_0109716	3.0	3.0
1023_0109878	2.0	3.0
1023_0109914	2.0	3.0
1031_0002004	3.0	3.0
1031_0002011	4.0	3.0
1031_0002042	3.0	3.0
1031_0002085	3.0	3.0
1031_0002200	2.0	3.0
1031_0003012	3.0	3.0
1031_0003013	4.0	3.0
1031_0003023	3.0	3.0
1031_0003048	4.0	3.0
1031_0003088	4.0	3.0
1031_0003097	3.0	3.0
1031_0003106	3.0	3.0
1031_0003135	3.0	3.0
1031_0003144	3.0	3.0
1031_0003145	3.0	3.0
1031_0003149	3.0	3.0
1031_0003156	3.0	3.0
1031_0003157	4.0	3.0
1031_0003161	3.0	3.0
1031_0003167	3.0	3.0
1031_0003172	3.0	3.0
1031_0003173	3.0	3.0
1031_0003179	3.0	3.0
1031_0003183	4.0	3.0
1031_0003190	3.0	3.0
1031_0003205	3.0	3.0
1031_0003219	3.0	3.0
1031_0003230	3.0	3.0
1031_0003232	2.0	3.0
1031_0003244	4.0	3.0
1031_0003309	3.0	3.0
1031_0003314	3.0	3.0
1031_0003330	3.0	3.0
1031_0003353	2.0	3.0
1031_0003366	3.0	3.0
1031_0003415	4.0	3.0
1031_0003419	3.0	3.0
1061_0120273	1.0	2.0
1061_0120281	1.0	2.0
1061_0120289	1.0	1.0
1061_0120303	1.0	2.0
1061_0120304	2.0	2.0
1061_0120309	1.0	1.0
1061_0120315	2.0	1.0
1061_0120325	2.0	2.0
1061_0120332	1.0	2.0
1061_0120338	1.0	2.0
1061_0120345	2.0	2.0
1061_0120350	2.0	2.0
1061_0120357	3.0	3.0
1061_0120368	2.0	2.0
1061_0120376	2.0	2.0
1061_0120386	1.0	2.0
1061_0120387	1.0	2.0
1061_0120394	2.0	2.0
1061_0120406	2.0	2.0
1061_0120413	1.0	1.0
1061_0120424	2.0	2.0
1061_0120431	2.0	2.0
1061_0120432	2.0	2.0
1061_0120442	2.0	2.0
1061_0120448	3.0	2.0
1061_0120459	2.0	2.0
1061_0120479	2.0	2.0
1061_0120480	2.0	2.0
1061_0120483	1.0	2.0
1061_0120489	2.0	2.0
1061_0120496	2.0	2.0
1061_0120856	1.0	2.0
1061_0120859	2.0	2.0
1061_0120875	3.0	3.0
1061_0120884	2.0	2.0
1061_1029112	3.0	3.0
1061_1029115	2.0	2.0
1061_1029120	1.0	2.0
1061_1202916	2.0	2.0
1071_0024701	2.0	2.0
1071_0024706	1.0	1.0
1071_0024715	1.0	2.0
1071_0024716	1.0	1.0
1071_0024758	2.0	2.0
1071_0024763	1.0	1.0
1071_0024766	1.0	1.0
1071_0024769	0.0	1.0
1071_0024774	0.0	0.0
1071_0024781	1.0	1.0
1071_0024782	0.0	0.0
1071_0024784	1.0	1.0
1071_0024798	0.0	1.0
1071_0024800	1.0	1.0
1071_0024804	1.0	1.0
1071_0024808	1.0	1.0
1071_0024818	2.0	1.0
1071_0024835	1.0	1.0
1071_0024843	1.0	1.0
1071_0024844	1.0	1.0
1071_0024851	1.0	1.0
1071_0024853	1.0	1.0
1071_0024857	1.0	1.0
1071_0024863	1.0	1.0
1071_0241833	1.0	1.0
1071_0242042	1.0	1.0
1071_0242043	0.0	1.0
1071_0242072	0.0	0.0
1071_0242092	0.0	0.0
1071_0242093	0.0	1.0
1071_0243593	1.0	2.0
1071_0243621	2.0	1.0
1071_0243622	1.0	1.0
1071_0243623	1.0	1.0
1071_0248309	2.0	2.0
1071_0248311	1.0	1.0
1071_0248312	1.0	1.0
1071_0248314	1.0	1.0
1071_0248323	1.0	1.0
1071_0248324	0.0	1.0
1071_0248328	0.0	1.0
1071_0248330	2.0	1.0
1071_0248337	1.0	2.0
1071_0248340	0.0	0.0
1091_0000010	2.0	2.0
1091_0000011	2.0	1.0
1091_0000018	2.0	2.0
1091_0000022	3.0	2.0
1091_0000046	1.0	1.0
1091_0000047	1.0	1.0
1091_0000049	1.0	1.0
1091_0000059	2.0	2.0
1091_0000061	1.0	1.0
1091_0000064	1.0	1.0
1091_0000070	1.0	1.0
1091_0000077	1.0	1.0
1091_0000087	1.0	2.0
1091_0000092	2.0	2.0
1091_0000095	2.0	1.0
1091_0000125	2.0	2.0
1091_0000148	1.0	1.0
1091_0000152	1.0	1.0
1091_0000157	2.0	2.0
1091_0000162	1.0	2.0
1091_0000167	2.0	2.0
1091_0000169	1.0	2.0
1091_0000171	2.0	2.0
1091_0000194	2.0	2.0
1091_0000196	2.0	1.0
1091_0000200	1.0	2.0
1091_0000201	1.0	2.0
1091_0000203	1.0	1.0
1091_0000221	1.0	1.0
1091_0000236	1.0	2.0
1091_0000246	2.0	2.0
1091_0000250	1.0	2.0
1091_0000253	0.0	1.0
1091_0000256	2.0	2.0
1091_0000257	2.0	2.0
1091_0000265	1.0	2.0
1091_0000267	1.0	2.0
1091_0000271	1.0	1.0
1091_0000273	2.0	2.0
1091_0000276	3.0	2.0
0601	1.0	1.0
0602	1.0	2.0
0604	2.0	2.0
0616	1.0	2.0
0632	1.0	1.0
0635	1.0	2.0
0637	2.0	2.0
0640	2.0	2.0
0717	1.0	1.0
0718	1.0	2.0
0724	2.0	2.0
0805	2.0	2.0
0815	2.0	2.0
0905	2.0	2.0
0907	2.0	2.0
0912	2.0	2.0
0914	1.0	2.0
0919	1.0	2.0
0925	2.0	2.0
0929	1.0	1.0
1016	1.0	1.0
1017	1.0	1.0
1019	1.0	2.0
1020	2.0	2.0
1021	1.0	2.0
1112	1.0	2.0
1113	1.0	2.0
9999	1.0	1.0
KYJ0611005B	1.0	1.0
KYJ0611009A	1.0	1.0
LON0610002B	1.0	2.0
LON0611002B	1.0	1.0
MOS0611013	2.0	3.0
PAR1011009B	1.0	2.0
PHA0111002A	2.0	1.0
PHA0111003A	1.0	1.0
PHA0111010	3.0	3.0
PHA0111012	2.0	2.0
PHA0112007A	1.0	1.0
PHA0209001	1.0	2.0
PHA0209008	1.0	1.0
PHA0209031	3.0	3.0
PHA0411009B	1.0	1.0
PHA0411010A	1.0	1.0
PHA0411034	1.0	1.0
PHA0411035	3.0	3.0
PHA0411038	3.0	3.0
PHA0411047	2.0	3.0
PHA0411062	2.0	3.0
PHA0509002	1.0	1.0
PHA0509021	2.0	2.0
PHA0509024	2.0	2.0
PHA0509028	3.0	3.0
PHA0509043	3.0	3.0
PHA0509045	2.0	2.0
PHA0510004A	1.0	1.0
PHA0510027	2.0	2.0
PHA0510034	3.0	3.0
PHA0510038	3.0	3.0
PHA0510040	2.0	3.0
PHA0510049	2.0	3.0
PHA0610007B	1.0	1.0
PHA0610015	2.0	3.0
PHA0610016	3.0	3.0
PHA0710010	2.0	3.0
PHA0710012	3.0	3.0
PHA0710014	3.0	3.0
PHA0710015	3.0	3.0
PHA0710017	3.0	3.0
PHA0710018	3.0	3.0
PHA0710021	3.0	3.0
PHA0810010	2.0	3.0
PHA0810011	2.0	3.0
PHA0811012	3.0	3.0
PHA0811013	3.0	3.0
PHA0811020	2.0	2.0
PHA1109003	2.0	2.0
PHA1109024	3.0	3.0
PHA1109026	3.0	3.0
PHA1110003A	1.0	2.0
VAR0209036	2.0	3.0
VAR0909004	2.0	3.0
VAR0910004	3.0	3.0
VAR0910006	2.0	3.0
1325_1001008	2.0	2.0
1325_1001010	2.0	2.0
1325_1001011	2.0	2.0
1325_1001012	2.0	2.0
1325_1001016	2.0	2.0
1325_1001020	2.0	2.0
1325_1001021	2.0	2.0
1325_1001022	2.0	2.0
1325_1001027	2.0	2.0
1325_1001045	2.0	2.0
1325_1001046	2.0	2.0
1325_1001047	2.0	2.0
1325_1001050	2.0	2.0
1325_1001052	2.0	2.0
1325_1001059	2.0	2.0
1325_1001081	2.0	2.0
1325_1001097	1.0	2.0
1325_1001107	2.0	2.0
1325_1001109	2.0	2.0
1325_1001119	2.0	2.0
1325_1001130	2.0	2.0
1325_1001144	2.0	2.0
1325_1001169	2.0	2.0
1325_9000087	2.0	2.0
1325_9000138	2.0	2.0
1325_9000152	2.0	2.0
1325_9000188	2.0	2.0
1325_9000209	2.0	2.0
1325_9000215	2.0	2.0
1325_9000241	2.0	2.0
1325_9000278	2.0	2.0
1325_9000303	2.0	2.0
1325_9000304	2.0	2.0
1325_9000314	2.0	2.0
1325_9000533	2.0	2.0
1325_9000534	2.0	2.0
1325_9000601	2.0	2.0
1325_9000676	2.0	2.0
1325_9000684	2.0	2.0
1325_9000685	2.0	2.0
1325_9000686	2.0	2.0
1365_0100002	2.0	2.0
1365_0100007	1.0	1.0
1365_0100012	2.0	2.0
1365_0100027	2.0	2.0
1365_0100028	2.0	2.0
1365_0100058	2.0	2.0
1365_0100069	2.0	2.0
1365_0100070	2.0	2.0
1365_0100072	2.0	2.0
1365_0100080	2.0	2.0
1365_0100094	2.0	2.0
1365_0100102	2.0	2.0
1365_0100118	2.0	2.0
1365_0100123	2.0	2.0
1365_0100137	2.0	2.0
1365_0100138	2.0	2.0
1365_0100151	1.0	2.0
1365_0100163	2.0	2.0
1365_0100165	2.0	2.0
1365_0100166	1.0	2.0
1365_0100167	1.0	2.0
1365_0100172	2.0	2.0
1365_0100173	2.0	2.0
1365_0100174	1.0	2.0
1365_0100175	2.0	2.0
1365_0100178	2.0	2.0
1365_0100180	1.0	1.0
1365_0100181	1.0	2.0
1365_0100184	2.0	2.0
1365_0100188	2.0	2.0
1365_0100204	2.0	2.0
1365_0100213	2.0	2.0
1365_0100215	2.0	2.0
1365_0100220	2.0	2.0
1365_0100222	2.0	2.0
1365_0100227	2.0	2.0
1365_0100257	2.0	2.0
1365_0100276	2.0	2.0
1365_0100281	2.0	2.0
1365_0100287	2.0	2.0
1365_0100288	2.0	2.0
1365_0100299	2.0	2.0
1365_0100474	2.0	2.0
1365_0100482	2.0	2.0
1385_0000012	1.0	1.0
1385_0000020	1.0	1.0
1385_0000037	1.0	1.0
1385_0000038	1.0	1.0
1385_0000049	1.0	1.0
1385_0000052	1.0	1.0
1385_0000053	1.0	1.0
1385_0000059	1.0	1.0
1385_0000097	1.0	1.0
1385_0000102	1.0	1.0
1385_0000103	1.0	1.0
1385_0000104	1.0	1.0
1385_0000114	1.0	1.0
1385_0000122	1.0	1.0
1385_0001103	1.0	1.0
1385_0001104	1.0	1.0
1385_0001108	1.0	1.0
1385_0001113	1.0	1.0
1385_0001120	1.0	1.0
1385_0001122	1.0	1.0
1385_0001134	1.0	1.0
1385_0001136	1.0	1.0
1385_0001151	1.0	1.0
1385_0001152	1.0	1.0
1385_0001156	1.0	1.0
1385_0001157	1.0	2.0
1385_0001159	1.0	1.0
1385_0001169	1.0	1.0
1385_0001173	0.0	1.0
1385_0001174	1.0	1.0
1385_0001194	1.0	1.0
1385_0001196	1.0	1.0
1385_0001198	2.0	2.0
1385_0001523	1.0	2.0
1385_0001714	1.0	1.0
1385_0001717	2.0	2.0
1385_0001726	1.0	1.0
1385_0001733	1.0	1.0
1385_0001744	0.0	1.0
1385_0001753	1.0	1.0
1385_0001754	1.0	1.0
1385_0001761	1.0	1.0
1385_0001762	1.0	1.0
1385_0001764	1.0	1.0
1385_0001765	0.0	1.0
1385_0001768	1.0	1.0
1385_0001775	1.0	1.0
1385_0001786	1.0	1.0
1385_0001794	1.0	1.0
1385_0001795	1.0	1.0
1395_0000333	1.0	1.0
1395_0000357	2.0	2.0
1395_0000360	2.0	2.0
1395_0000383	1.0	2.0
1395_0000399	1.0	1.0
1395_0000404	1.0	2.0
1395_0000415	1.0	1.0
1395_0000443	2.0	2.0
1395_0000446	2.0	2.0
1395_0000447	1.0	2.0
1395_0000470	1.0	1.0
1395_0000504	1.0	1.0
1395_0000515	2.0	1.0
1395_0000547	1.0	2.0
1395_0000548	1.0	2.0
1395_0000550	1.0	2.0
1395_0000584	0.0	1.0
1395_0000609	1.0	1.0
1395_0000626	2.0	2.0
1395_0000630	1.0	2.0
1395_0000635	1.0	1.0
1395_0000639	1.0	2.0
1395_0000644	1.0	2.0
1395_0000646	1.0	1.0
1395_0001013	1.0	2.0
1395_0001021	1.0	1.0
1395_0001033	1.0	2.0
1395_0001060	2.0	2.0
1395_0001064	1.0	2.0
1395_0001065	1.0	2.0
1395_0001066	1.0	2.0
1395_0001090	2.0	2.0
1395_0001104	1.0	1.0
1395_0001118	1.0	1.0
1395_0001126	1.0	1.0
1395_0001133	1.0	1.0
1395_0001146	0.0	1.0
1395_0001158	2.0	2.0
1395_0001161	1.0	2.0
5 Fold, Dimension = OverallCEFRrating

======== Epoch 1 / 4 ========
Training...
Elapsed time 9
Elapsed time 19
Elapsed time 28
Elapsed time 38
Elapsed time 47

  Average training loss: 0.92
  Training epoch took: 53
Running Validation...
  Average evaluation loss: 0.65
              precision    recall  f1-score   support

         0.0       0.00      0.00      0.00        17
         1.0       0.72      0.95      0.82       175
         2.0       0.89      0.59      0.71       177
         3.0       0.65      0.93      0.77        74
         4.0       0.00      0.00      0.00         9

    accuracy                           0.75       452
   macro avg       0.45      0.49      0.46       452
weighted avg       0.74      0.75      0.72       452

[[  0  17   0   0   0]
 [  0 166   9   0   0]
 [  0  45 104  28   0]
 [  0   1   4  69   0]
 [  0   0   0   9   0]]
0.7207294343304659



======== Epoch 2 / 4 ========
Training...
Elapsed time 9
Elapsed time 19
Elapsed time 28
Elapsed time 38
Elapsed time 47

  Average training loss: 0.62
  Training epoch took: 53
Running Validation...
  Average evaluation loss: 0.57
              precision    recall  f1-score   support

         0.0       0.00      0.00      0.00        17
         1.0       0.84      0.77      0.80       175
         2.0       0.76      0.85      0.80       177
         3.0       0.71      0.91      0.80        74
         4.0       0.00      0.00      0.00         9

    accuracy                           0.78       452
   macro avg       0.46      0.50      0.48       452
weighted avg       0.74      0.78      0.76       452

[[  0  17   0   0   0]
 [  0 134  41   0   0]
 [  0   8 151  18   0]
 [  0   0   7  67   0]
 [  0   0   0   9   0]]
0.7557696124280474



======== Epoch 3 / 4 ========
Training...
Elapsed time 9
Elapsed time 19
Elapsed time 28
Elapsed time 38
Elapsed time 47

  Average training loss: 0.49
  Training epoch took: 53
Running Validation...
  Average evaluation loss: 0.60
              precision    recall  f1-score   support

         0.0       1.00      0.24      0.38        17
         1.0       0.85      0.76      0.80       175
         2.0       0.75      0.84      0.79       177
         3.0       0.71      0.91      0.80        74
         4.0       0.00      0.00      0.00         9

    accuracy                           0.78       452
   macro avg       0.66      0.55      0.56       452
weighted avg       0.78      0.78      0.77       452

[[  4  13   0   0   0]
 [  0 133  42   0   0]
 [  0  10 149  18   0]
 [  0   0   7  67   0]
 [  0   0   0   9   0]]
0.7672354891318879



======== Epoch 4 / 4 ========
Training...
Elapsed time 9
Elapsed time 19
Elapsed time 28
Elapsed time 38
Elapsed time 47

  Average training loss: 0.40
  Training epoch took: 53
Running Validation...
  Average evaluation loss: 0.63
              precision    recall  f1-score   support

         0.0       0.86      0.35      0.50        17
         1.0       0.87      0.77      0.82       175
         2.0       0.77      0.82      0.80       177
         3.0       0.69      0.93      0.79        74
         4.0       0.00      0.00      0.00         9

    accuracy                           0.79       452
   macro avg       0.64      0.58      0.58       452
weighted avg       0.78      0.79      0.78       452

[[  6  11   0   0   0]
 [  1 135  39   0   0]
 [  0   9 146  22   0]
 [  0   0   5  69   0]
 [  0   0   0   9   0]]
0.7769907328072819
Filename	True Label	Prediction
1023_0001422	2.0	2.0
1023_0101753	3.0	3.0
1023_0101895	3.0	3.0
1023_0101899	2.0	3.0
1023_0101900	3.0	3.0
1023_0101901	3.0	3.0
1023_0101904	2.0	2.0
1023_0102117	3.0	3.0
1023_0103825	3.0	3.0
1023_0103828	1.0	2.0
1023_0103840	3.0	3.0
1023_0104207	2.0	3.0
1023_0106816	3.0	3.0
1023_0107727	3.0	3.0
1023_0107773	2.0	3.0
1023_0108510	3.0	3.0
1023_0108518	3.0	3.0
1023_0108520	3.0	3.0
1023_0108810	3.0	3.0
1023_0108890	3.0	3.0
1023_0108908	3.0	3.0
1023_0108992	3.0	3.0
1023_0109026	2.0	2.0
1023_0109192	3.0	3.0
1023_0109250	2.0	3.0
1023_0109422	3.0	3.0
1023_0109496	3.0	3.0
1023_0109519	2.0	3.0
1023_0109520	2.0	3.0
1023_0109527	3.0	3.0
1023_0109609	2.0	2.0
1023_0109649	3.0	3.0
1023_0109671	3.0	3.0
1023_0109674	3.0	3.0
1023_0109915	2.0	2.0
1023_0109954	3.0	3.0
1023_0111896	2.0	2.0
1031_0001998	4.0	3.0
1031_0002002	2.0	3.0
1031_0002010	3.0	3.0
1031_0002079	4.0	3.0
1031_0002083	3.0	3.0
1031_0002087	3.0	3.0
1031_0002131	3.0	3.0
1031_0002184	3.0	3.0
1031_0002197	3.0	3.0
1031_0003042	3.0	3.0
1031_0003073	4.0	3.0
1031_0003077	3.0	3.0
1031_0003090	3.0	3.0
1031_0003091	2.0	2.0
1031_0003126	3.0	3.0
1031_0003127	4.0	3.0
1031_0003129	3.0	3.0
1031_0003130	4.0	3.0
1031_0003150	3.0	3.0
1031_0003154	3.0	3.0
1031_0003162	3.0	3.0
1031_0003165	2.0	3.0
1031_0003169	3.0	3.0
1031_0003181	4.0	3.0
1031_0003184	4.0	3.0
1031_0003203	2.0	2.0
1031_0003206	3.0	3.0
1031_0003207	4.0	3.0
1031_0003214	3.0	3.0
1031_0003225	3.0	3.0
1031_0003226	3.0	3.0
1031_0003231	3.0	3.0
1031_0003233	3.0	3.0
1031_0003235	3.0	3.0
1031_0003243	3.0	3.0
1031_0003260	3.0	3.0
1031_0003262	3.0	3.0
1031_0003272	3.0	2.0
1031_0003337	3.0	3.0
1031_0003339	3.0	3.0
1031_0003354	3.0	3.0
1031_0003357	3.0	3.0
1031_0003358	4.0	3.0
1031_0003359	2.0	3.0
1031_0003383	3.0	3.0
1031_0003391	2.0	3.0
1031_0003410	3.0	3.0
1061_0120272	1.0	1.0
1061_0120284	0.0	0.0
1061_0120300	2.0	2.0
1061_0120301	2.0	2.0
1061_0120306	3.0	2.0
1061_0120307	2.0	2.0
1061_0120310	2.0	2.0
1061_0120319	2.0	2.0
1061_0120320	3.0	3.0
1061_0120321	2.0	2.0
1061_0120330	2.0	2.0
1061_0120333	2.0	2.0
1061_0120341	1.0	1.0
1061_0120349	1.0	1.0
1061_0120351	2.0	2.0
1061_0120353	1.0	1.0
1061_0120361	2.0	3.0
1061_0120382	1.0	2.0
1061_0120384	1.0	1.0
1061_0120389	2.0	2.0
1061_0120405	2.0	2.0
1061_0120407	3.0	2.0
1061_0120408	2.0	2.0
1061_0120409	2.0	2.0
1061_0120414	2.0	2.0
1061_0120415	2.0	2.0
1061_0120425	2.0	2.0
1061_0120426	2.0	3.0
1061_0120427	2.0	2.0
1061_0120428	2.0	2.0
1061_0120429	2.0	2.0
1061_0120433	1.0	1.0
1061_0120440	1.0	1.0
1061_0120453	2.0	2.0
1061_0120485	2.0	2.0
1061_0120487	2.0	2.0
1061_0120488	2.0	2.0
1061_0120493	2.0	2.0
1061_0120878	1.0	2.0
1061_0120888	1.0	2.0
1061_0120890	1.0	1.0
1061_1029113	1.0	2.0
1061_1202917	1.0	1.0
1071_0024691	1.0	2.0
1071_0024699	1.0	1.0
1071_0024703	1.0	1.0
1071_0024708	1.0	1.0
1071_0024761	1.0	1.0
1071_0024762	1.0	1.0
1071_0024767	2.0	1.0
1071_0024768	1.0	1.0
1071_0024773	1.0	1.0
1071_0024776	0.0	0.0
1071_0024797	0.0	1.0
1071_0024803	1.0	1.0
1071_0024806	1.0	1.0
1071_0024811	1.0	1.0
1071_0024812	1.0	1.0
1071_0024817	1.0	1.0
1071_0024836	1.0	2.0
1071_0024838	0.0	0.0
1071_0024845	0.0	1.0
1071_0024846	1.0	1.0
1071_0024847	1.0	2.0
1071_0024848	1.0	1.0
1071_0024849	0.0	0.0
1071_0024854	0.0	1.0
1071_0024861	0.0	1.0
1071_0024865	2.0	2.0
1071_0024872	1.0	1.0
1071_0024877	1.0	1.0
1071_0242012	1.0	2.0
1071_0242023	1.0	1.0
1071_0243502	1.0	1.0
1071_0243591	1.0	1.0
1071_0243592	1.0	2.0
1071_0248305	0.0	1.0
1071_0248307	2.0	1.0
1071_0248315	0.0	0.0
1071_0248321	1.0	1.0
1071_0248331	1.0	1.0
1071_0248334	2.0	2.0
1071_0248336	1.0	1.0
1071_0248341	1.0	1.0
1071_0248346	1.0	1.0
1071_0248348	1.0	1.0
1071_0248349	1.0	1.0
1091_0000005	2.0	2.0
1091_0000006	0.0	1.0
1091_0000008	2.0	2.0
1091_0000014	0.0	1.0
1091_0000024	1.0	1.0
1091_0000026	1.0	1.0
1091_0000028	0.0	1.0
1091_0000034	1.0	1.0
1091_0000036	1.0	2.0
1091_0000037	1.0	1.0
1091_0000039	1.0	1.0
1091_0000041	1.0	1.0
1091_0000045	2.0	2.0
1091_0000056	2.0	2.0
1091_0000057	1.0	1.0
1091_0000058	2.0	2.0
1091_0000063	1.0	1.0
1091_0000065	2.0	2.0
1091_0000066	1.0	1.0
1091_0000067	2.0	1.0
1091_0000069	1.0	1.0
1091_0000072	2.0	2.0
1091_0000074	2.0	2.0
1091_0000086	1.0	1.0
1091_0000101	1.0	1.0
1091_0000114	2.0	2.0
1091_0000161	2.0	2.0
1091_0000166	2.0	1.0
1091_0000173	2.0	1.0
1091_0000174	1.0	0.0
1091_0000198	1.0	2.0
1091_0000202	2.0	2.0
1091_0000205	2.0	2.0
1091_0000219	2.0	2.0
1091_0000226	1.0	1.0
1091_0000228	2.0	2.0
1091_0000242	2.0	2.0
1091_0000244	2.0	2.0
1091_0000261	2.0	2.0
1091_0000268	2.0	2.0
0603	2.0	2.0
0605	2.0	2.0
0606	2.0	2.0
0607	2.0	2.0
0609	1.0	2.0
0612	1.0	1.0
0617	1.0	1.0
0628	2.0	2.0
0629	2.0	2.0
0638	1.0	2.0
0639	1.0	2.0
0721	2.0	2.0
0722	2.0	2.0
0725	1.0	2.0
0803	1.0	2.0
0810	1.0	2.0
0916	1.0	1.0
0917	1.0	1.0
0918	1.0	2.0
0926	2.0	2.0
1004	1.0	1.0
1111	1.0	1.0
1114	2.0	2.0
BER0611003	2.0	3.0
BER0611006	2.0	3.0
LIB0611002A	1.0	1.0
LIB0611011	1.0	2.0
MOS0611014	1.0	2.0
PAR1011017	3.0	3.0
PHA0111002B	2.0	2.0
PHA0111003B	1.0	1.0
PHA0111004A	1.0	1.0
PHA0111011	2.0	2.0
PHA0112007B	1.0	1.0
PHA0112012A	1.0	2.0
PHA0209024	2.0	2.0
PHA0209039	2.0	3.0
PHA0210001	1.0	1.0
PHA0210004	1.0	1.0
PHA0210008	1.0	1.0
PHA0411009A	1.0	1.0
PHA0411027	2.0	2.0
PHA0411028	2.0	2.0
PHA0411029	2.0	2.0
PHA0411041	3.0	3.0
PHA0411051	3.0	3.0
PHA0411053	3.0	3.0
PHA0411058	3.0	3.0
PHA0411059	3.0	3.0
PHA0509013	1.0	1.0
PHA0509015	3.0	2.0
PHA0509032	2.0	3.0
PHA0509038	2.0	2.0
PHA0509041	2.0	3.0
PHA0510004B	1.0	1.0
PHA0510010A	1.0	1.0
PHA0510013A	1.0	1.0
PHA0510029	3.0	3.0
PHA0510032	3.0	3.0
PHA0510037	2.0	2.0
PHA0510048	2.0	2.0
PHA0610018	3.0	3.0
PHA0610019B	1.0	2.0
PHA0610025	3.0	3.0
PHA0610026	3.0	3.0
PHA0810001	3.0	3.0
PHA0810009	3.0	3.0
PHA1109001	1.0	2.0
PHA1109006	2.0	2.0
PHA1109008	1.0	1.0
PHA1109023	1.0	1.0
PHA1109025	1.0	1.0
PHA1109028	2.0	3.0
PHA1110002A	2.0	2.0
PHA1110003B	1.0	2.0
PHA1110013	2.0	3.0
PHA1110014	2.0	3.0
PHA1110017	2.0	2.0
PHA1110019	2.0	2.0
PHA1111001A	1.0	1.0
PHA1111002B	1.0	1.0
PHA1111009A	1.0	1.0
TI071122B	1.0	1.0
VAR0909003	2.0	3.0
VAR0909010	2.0	2.0
VAR0910007	2.0	3.0
VAR0910010	3.0	2.0
1325_1001009	2.0	2.0
1325_1001023	2.0	2.0
1325_1001039	2.0	2.0
1325_1001041	2.0	2.0
1325_1001053	1.0	2.0
1325_1001056	2.0	2.0
1325_1001062	2.0	2.0
1325_1001078	2.0	2.0
1325_1001082	2.0	2.0
1325_1001083	2.0	2.0
1325_1001087	2.0	2.0
1325_1001094	2.0	2.0
1325_1001099	2.0	2.0
1325_1001111	2.0	2.0
1325_1001122	2.0	2.0
1325_1001133	2.0	2.0
1325_1001136	2.0	2.0
1325_1001138	2.0	2.0
1325_1001143	2.0	2.0
1325_1001161	2.0	2.0
1325_1001168	2.0	2.0
1325_9000099	2.0	2.0
1325_9000104	2.0	2.0
1325_9000136	2.0	2.0
1325_9000139	2.0	2.0
1325_9000143	2.0	2.0
1325_9000185	2.0	2.0
1325_9000237	2.0	2.0
1325_9000239	2.0	2.0
1325_9000317	2.0	2.0
1325_9000320	2.0	2.0
1325_9000321	2.0	2.0
1325_9000503	2.0	2.0
1325_9000612	1.0	2.0
1325_9000674	2.0	2.0
1325_9000677	2.0	2.0
1325_9000700	2.0	2.0
1365_0100006	2.0	2.0
1365_0100013	2.0	2.0
1365_0100019	1.0	1.0
1365_0100020	2.0	2.0
1365_0100030	1.0	2.0
1365_0100056	2.0	2.0
1365_0100092	2.0	2.0
1365_0100097	2.0	2.0
1365_0100100	2.0	2.0
1365_0100101	2.0	2.0
1365_0100103	2.0	2.0
1365_0100119	2.0	2.0
1365_0100120	2.0	2.0
1365_0100121	2.0	2.0
1365_0100125	2.0	2.0
1365_0100164	2.0	2.0
1365_0100176	2.0	2.0
1365_0100186	2.0	2.0
1365_0100190	2.0	2.0
1365_0100192	2.0	2.0
1365_0100194	2.0	2.0
1365_0100198	1.0	2.0
1365_0100199	2.0	2.0
1365_0100200	2.0	2.0
1365_0100211	2.0	2.0
1365_0100212	2.0	2.0
1365_0100218	2.0	2.0
1365_0100228	1.0	2.0
1365_0100231	2.0	2.0
1365_0100232	2.0	2.0
1365_0100233	2.0	2.0
1365_0100258	2.0	2.0
1365_0100261	2.0	2.0
1365_0100448	1.0	2.0
1365_0100475	2.0	2.0
1365_0100478	2.0	2.0
1385_0000011	0.0	1.0
1385_0000022	1.0	1.0
1385_0000034	1.0	1.0
1385_0000047	1.0	1.0
1385_0000048	1.0	1.0
1385_0000050	1.0	1.0
1385_0000058	1.0	1.0
1385_0000095	1.0	1.0
1385_0000119	1.0	1.0
1385_0000124	1.0	1.0
1385_0000129	1.0	1.0
1385_0001107	1.0	1.0
1385_0001119	1.0	1.0
1385_0001125	1.0	1.0
1385_0001133	1.0	1.0
1385_0001135	1.0	1.0
1385_0001147	1.0	1.0
1385_0001148	1.0	1.0
1385_0001170	1.0	1.0
1385_0001172	1.0	1.0
1385_0001175	1.0	1.0
1385_0001188	1.0	1.0
1385_0001189	1.0	1.0
1385_0001192	1.0	1.0
1385_0001193	2.0	1.0
1385_0001199	1.0	1.0
1385_0001501	1.0	1.0
1385_0001503	1.0	1.0
1385_0001525	1.0	2.0
1385_0001724	2.0	2.0
1385_0001729	1.0	1.0
1385_0001732	1.0	1.0
1385_0001740	1.0	1.0
1385_0001741	0.0	1.0
1385_0001748	1.0	1.0
1385_0001752	1.0	1.0
1385_0001756	1.0	1.0
1385_0001757	2.0	1.0
1385_0001767	1.0	1.0
1385_0001788	1.0	1.0
1385_0001798	1.0	1.0
1385_0001799	1.0	1.0
1385_0001800	1.0	1.0
1395_0000341	1.0	1.0
1395_0000356	1.0	1.0
1395_0000368	0.0	0.0
1395_0000392	1.0	1.0
1395_0000409	2.0	2.0
1395_0000414	1.0	1.0
1395_0000455	1.0	1.0
1395_0000469	1.0	1.0
1395_0000516	1.0	1.0
1395_0000525	2.0	1.0
1395_0000527	1.0	1.0
1395_0000529	1.0	1.0
1395_0000533	2.0	2.0
1395_0000537	1.0	2.0
1395_0000553	1.0	1.0
1395_0000560	1.0	2.0
1395_0000581	1.0	2.0
1395_0000593	1.0	1.0
1395_0000595	0.0	1.0
1395_0000596	2.0	1.0
1395_0000598	1.0	1.0
1395_0000599	1.0	1.0
1395_0000602	1.0	1.0
1395_0000612	1.0	1.0
1395_0000628	1.0	1.0
1395_0001022	1.0	1.0
1395_0001028	1.0	2.0
1395_0001061	2.0	2.0
1395_0001068	1.0	1.0
1395_0001071	1.0	1.0
1395_0001076	1.0	2.0
1395_0001093	1.0	1.0
1395_0001108	1.0	1.0
1395_0001116	1.0	1.0
1395_0001120	1.0	1.0
1395_0001131	1.0	1.0
1395_0001147	1.0	2.0
1395_0001169	1.0	2.0
Averaged weighted F1-scores 0.7549011890014798
LANGUAGE: DE
130.68810916179336 82.83744971317162
LANGUAGE: CZ
144.90552995391704 65.35717405024758
LANGUAGE: IT
148.5775 138.9822884174455
LABEL SET ['A1', 'A2', 'B1', 'B2', 'C1']
1 Fold, Dimension = Grammaticalaccuracy

======== Epoch 1 / 4 ========
Training...
Elapsed time 9
Elapsed time 19
Elapsed time 28
Elapsed time 37
Elapsed time 46

  Average training loss: 1.15
  Training epoch took: 52
Running Validation...
  Average evaluation loss: 0.97
              precision    recall  f1-score   support

         0.0       0.00      0.00      0.00        33
         1.0       0.54      0.42      0.47       142
         2.0       0.51      0.75      0.61       176
         3.0       0.61      0.56      0.58        90
         4.0       0.00      0.00      0.00        11

    accuracy                           0.54       452
   macro avg       0.33      0.35      0.33       452
weighted avg       0.49      0.54      0.50       452

[[  0  28   5   0   0]
 [  0  60  82   0   0]
 [  0  23 132  21   0]
 [  0   0  40  50   0]
 [  0   0   0  11   0]]
0.5010866220241673



======== Epoch 2 / 4 ========
Training...
Elapsed time 9
Elapsed time 19
Elapsed time 28
Elapsed time 37
Elapsed time 47

  Average training loss: 0.89
  Training epoch took: 53
Running Validation...
  Average evaluation loss: 1.16
              precision    recall  f1-score   support

         0.0       1.00      0.06      0.11        33
         1.0       0.54      0.25      0.34       142
         2.0       0.48      0.67      0.56       176
         3.0       0.56      0.84      0.67        90
         4.0       0.00      0.00      0.00        11

    accuracy                           0.51       452
   macro avg       0.51      0.37      0.34       452
weighted avg       0.54      0.51      0.47       452

[[  2  22   9   0   0]
 [  0  36 106   0   0]
 [  0   9 118  49   0]
 [  0   0  14  76   0]
 [  0   0   0  11   0]]
0.4677321144640118



======== Epoch 3 / 4 ========
Training...
Elapsed time 9
Elapsed time 19
Elapsed time 28
Elapsed time 37
Elapsed time 46

  Average training loss: 0.76
  Training epoch took: 52
Running Validation...
  Average evaluation loss: 1.08
              precision    recall  f1-score   support

         0.0       0.75      0.27      0.40        33
         1.0       0.58      0.51      0.55       142
         2.0       0.50      0.45      0.48       176
         3.0       0.53      0.91      0.67        90
         4.0       0.00      0.00      0.00        11

    accuracy                           0.54       452
   macro avg       0.47      0.43      0.42       452
weighted avg       0.54      0.54      0.52       452

[[ 9 20  4  0  0]
 [ 2 73 67  0  0]
 [ 1 32 80 63  0]
 [ 0  0  8 82  0]
 [ 0  0  0 11  0]]
0.5197071716093886



======== Epoch 4 / 4 ========
Training...
Elapsed time 9
Elapsed time 19
Elapsed time 28
Elapsed time 37
Elapsed time 46

  Average training loss: 0.62
  Training epoch took: 52
Running Validation...
  Average evaluation loss: 1.06
              precision    recall  f1-score   support

         0.0       0.88      0.21      0.34        33
         1.0       0.58      0.52      0.55       142
         2.0       0.53      0.52      0.52       176
         3.0       0.57      0.91      0.70        90
         4.0       0.00      0.00      0.00        11

    accuracy                           0.56       452
   macro avg       0.51      0.43      0.42       452
weighted avg       0.56      0.56      0.54       452

[[ 7 20  6  0  0]
 [ 1 74 67  0  0]
 [ 0 34 91 51  0]
 [ 0  0  8 82  0]
 [ 0  0  0 11  0]]
0.5403279420539406
Filename	True Label	Prediction
1023_0101694	3.0	3.0
1023_0101700	2.0	3.0
1023_0101701	2.0	2.0
1023_0101843	3.0	3.0
1023_0101847	3.0	3.0
1023_0101856	2.0	3.0
1023_0101893	3.0	3.0
1023_0101898	4.0	3.0
1023_0102118	3.0	3.0
1023_0103823	3.0	3.0
1023_0103826	3.0	3.0
1023_0103830	3.0	3.0
1023_0103831	3.0	3.0
1023_0103832	2.0	2.0
1023_0103837	3.0	3.0
1023_0103844	4.0	3.0
1023_0104206	3.0	3.0
1023_0104209	3.0	3.0
1023_0107672	2.0	3.0
1023_0107740	3.0	3.0
1023_0107773	2.0	3.0
1023_0107783	3.0	2.0
1023_0108426	2.0	2.0
1023_0108518	3.0	3.0
1023_0108751	2.0	2.0
1023_0108752	3.0	3.0
1023_0108815	2.0	3.0
1023_0108886	3.0	3.0
1023_0108934	2.0	3.0
1023_0109027	2.0	2.0
1023_0109038	3.0	3.0
1023_0109391	2.0	2.0
1023_0109401	2.0	2.0
1023_0109518	2.0	2.0
1023_0109522	3.0	3.0
1023_0109606	2.0	3.0
1023_0109674	2.0	3.0
1023_0109914	2.0	3.0
1023_0109915	2.0	1.0
1031_0001703	4.0	3.0
1031_0002002	2.0	3.0
1031_0002003	2.0	3.0
1031_0002011	3.0	3.0
1031_0002042	3.0	3.0
1031_0002043	3.0	3.0
1031_0002092	4.0	3.0
1031_0002196	4.0	3.0
1031_0002198	3.0	3.0
1031_0003023	3.0	3.0
1031_0003065	3.0	3.0
1031_0003073	4.0	3.0
1031_0003077	3.0	3.0
1031_0003092	2.0	3.0
1031_0003097	4.0	3.0
1031_0003133	4.0	3.0
1031_0003145	3.0	3.0
1031_0003155	3.0	3.0
1031_0003157	4.0	3.0
1031_0003162	3.0	3.0
1031_0003164	3.0	3.0
1031_0003173	3.0	3.0
1031_0003183	4.0	3.0
1031_0003207	4.0	3.0
1031_0003214	3.0	3.0
1031_0003220	2.0	3.0
1031_0003221	2.0	3.0
1031_0003230	2.0	3.0
1031_0003237	3.0	3.0
1031_0003272	3.0	2.0
1031_0003273	3.0	3.0
1031_0003274	3.0	3.0
1031_0003315	3.0	3.0
1031_0003327	2.0	3.0
1031_0003352	2.0	2.0
1031_0003359	3.0	3.0
1031_0003365	3.0	3.0
1031_0003389	3.0	3.0
1031_0003391	2.0	3.0
1031_0003410	3.0	3.0
1031_0003419	3.0	3.0
1061_0012029	3.0	3.0
1061_0120288	1.0	2.0
1061_0120296	1.0	1.0
1061_0120303	0.0	2.0
1061_0120307	2.0	2.0
1061_0120309	1.0	1.0
1061_0120310	2.0	2.0
1061_0120313	1.0	1.0
1061_0120314	1.0	2.0
1061_0120315	2.0	2.0
1061_0120330	2.0	3.0
1061_0120334	2.0	2.0
1061_0120352	1.0	1.0
1061_0120358	1.0	1.0
1061_0120371	3.0	3.0
1061_0120372	1.0	2.0
1061_0120374	2.0	2.0
1061_0120407	3.0	2.0
1061_0120408	2.0	2.0
1061_0120410	2.0	2.0
1061_0120413	1.0	1.0
1061_0120421	2.0	3.0
1061_0120424	2.0	2.0
1061_0120426	1.0	2.0
1061_0120431	2.0	2.0
1061_0120439	2.0	1.0
1061_0120453	2.0	2.0
1061_0120485	3.0	2.0
1061_0120489	2.0	2.0
1061_0120490	2.0	2.0
1061_0120492	2.0	2.0
1061_0120875	2.0	3.0
1061_0120880	2.0	2.0
1061_1202910	2.0	2.0
1061_1202911	0.0	1.0
1061_1202912	2.0	2.0
1061_1202918	1.0	2.0
1071_0024681	1.0	2.0
1071_0024687	0.0	1.0
1071_0024690	1.0	2.0
1071_0024692	2.0	3.0
1071_0024701	2.0	2.0
1071_0024714	2.0	1.0
1071_0024715	2.0	1.0
1071_0024757	2.0	1.0
1071_0024759	0.0	1.0
1071_0024772	0.0	0.0
1071_0024774	0.0	0.0
1071_0024775	0.0	0.0
1071_0024777	1.0	1.0
1071_0024779	1.0	2.0
1071_0024800	1.0	1.0
1071_0024802	2.0	1.0
1071_0024803	1.0	1.0
1071_0024809	0.0	1.0
1071_0024810	2.0	1.0
1071_0024815	0.0	1.0
1071_0024819	1.0	1.0
1071_0024822	0.0	1.0
1071_0024831	0.0	1.0
1071_0024837	0.0	0.0
1071_0024841	0.0	0.0
1071_0024843	0.0	1.0
1071_0024854	0.0	0.0
1071_0024859	1.0	1.0
1071_0024863	1.0	1.0
1071_0024871	1.0	1.0
1071_0024872	1.0	1.0
1071_0024874	1.0	1.0
1071_0024875	1.0	1.0
1071_0024878	1.0	2.0
1071_0241832	1.0	1.0
1071_0242012	1.0	2.0
1071_0242023	1.0	1.0
1071_0248304	1.0	1.0
1071_0248309	1.0	2.0
1071_0248324	0.0	1.0
1071_0248328	1.0	1.0
1071_0248333	2.0	2.0
1071_0248334	2.0	1.0
1071_0248344	1.0	1.0
1071_0248346	0.0	2.0
1071_0248348	2.0	1.0
1091_0000010	3.0	2.0
1091_0000028	1.0	1.0
1091_0000030	0.0	2.0
1091_0000036	1.0	2.0
1091_0000037	1.0	1.0
1091_0000039	1.0	1.0
1091_0000041	1.0	1.0
1091_0000042	1.0	0.0
1091_0000045	1.0	2.0
1091_0000046	2.0	1.0
1091_0000054	0.0	1.0
1091_0000055	1.0	2.0
1091_0000057	2.0	1.0
1091_0000067	2.0	2.0
1091_0000071	2.0	2.0
1091_0000077	2.0	1.0
1091_0000079	1.0	2.0
1091_0000087	2.0	1.0
1091_0000101	2.0	1.0
1091_0000114	1.0	2.0
1091_0000116	2.0	2.0
1091_0000125	2.0	2.0
1091_0000140	2.0	1.0
1091_0000154	1.0	2.0
1091_0000157	2.0	2.0
1091_0000159	2.0	2.0
1091_0000162	1.0	2.0
1091_0000163	1.0	1.0
1091_0000190	1.0	2.0
1091_0000193	2.0	1.0
1091_0000204	2.0	2.0
1091_0000209	2.0	2.0
1091_0000214	2.0	1.0
1091_0000217	2.0	1.0
1091_0000220	1.0	2.0
1091_0000221	2.0	1.0
1091_0000223	1.0	2.0
1091_0000227	0.0	2.0
1091_0000235	1.0	1.0
1091_0000236	2.0	2.0
1091_0000237	2.0	2.0
1091_0000243	1.0	1.0
1091_0000247	2.0	1.0
1091_0000250	1.0	2.0
1091_0000253	2.0	1.0
1091_0000261	1.0	2.0
1091_0000264	2.0	1.0
1091_0000267	1.0	1.0
1091_0000270	2.0	1.0
1091_0000275	2.0	1.0
0601	1.0	1.0
0608	1.0	1.0
0630	1.0	1.0
0635	1.0	2.0
0641	1.0	1.0
0723	2.0	2.0
0801	1.0	2.0
0810	2.0	2.0
0811	2.0	2.0
0816	2.0	2.0
0824	2.0	2.0
0901	2.0	2.0
0902	2.0	2.0
0911	1.0	1.0
0914	1.0	2.0
0915	2.0	2.0
0920	2.0	2.0
0924	1.0	1.0
0926	2.0	2.0
1001	1.0	2.0
1016	1.0	1.0
1017	1.0	1.0
1018	1.0	1.0
1115	1.0	2.0
1117	2.0	1.0
BER0611003	2.0	3.0
BER0611005	2.0	3.0
BER0611007	2.0	3.0
KYJ0611006A	1.0	2.0
KYJ0611009A	1.0	1.0
LIB0611002A	1.0	2.0
LIB0611004A	1.0	2.0
LIB0611004B	1.0	2.0
MOS0509004	1.0	1.0
PAR1011015	2.0	2.0
PHA0111001B	1.0	2.0
PHA0111003B	2.0	1.0
PHA0111004A	1.0	1.0
PHA0111004B	1.0	1.0
PHA0111012	1.0	2.0
PHA0112002A	2.0	1.0
PHA0112003A	1.0	1.0
PHA0112007A	1.0	1.0
PHA0112012B	1.0	2.0
PHA0209008	1.0	1.0
PHA0411011B	1.0	2.0
PHA0411028	2.0	2.0
PHA0411038	3.0	3.0
PHA0411041	3.0	3.0
PHA0411047	2.0	3.0
PHA0411051	3.0	3.0
PHA0411055	3.0	3.0
PHA0411056	3.0	3.0
PHA0411058	3.0	3.0
PHA0411062	3.0	3.0
PHA0509002	1.0	1.0
PHA0509013	1.0	1.0
PHA0509037	3.0	2.0
PHA0509042	3.0	3.0
PHA0510002A	2.0	1.0
PHA0510004B	0.0	1.0
PHA0510029	2.0	3.0
PHA0510034	3.0	3.0
PHA0610017	3.0	3.0
PHA0710012	3.0	3.0
PHA0710017	3.0	3.0
PHA0809009	2.0	2.0
PHA0810004	1.0	2.0
PHA0810015	3.0	3.0
PHA1109007	1.0	2.0
PHA1109008	1.0	1.0
PHA1109023	1.0	1.0
PHA1110003A	1.0	2.0
PHA1110003B	1.0	2.0
PHA1110017	1.0	2.0
PHA1111003B	1.0	2.0
PHA1111006B	1.0	1.0
PHA1111008B	1.0	2.0
ST071122B	1.0	2.0
VAR0909003	2.0	3.0
VAR0910004	3.0	3.0
VAR0910006	3.0	3.0
VAR0910009	3.0	3.0
VAR0910010	3.0	3.0
1325_1001012	2.0	3.0
1325_1001015	2.0	2.0
1325_1001028	2.0	3.0
1325_1001029	2.0	2.0
1325_1001054	2.0	3.0
1325_1001055	2.0	3.0
1325_1001058	2.0	2.0
1325_1001059	2.0	2.0
1325_1001077	2.0	3.0
1325_1001078	2.0	3.0
1325_1001084	2.0	2.0
1325_1001085	2.0	3.0
1325_1001099	3.0	3.0
1325_1001109	2.0	2.0
1325_1001122	2.0	2.0
1325_1001123	3.0	3.0
1325_1001131	3.0	3.0
1325_1001134	2.0	3.0
1325_1001138	2.0	3.0
1325_1001139	2.0	2.0
1325_1001144	3.0	3.0
1325_1001152	2.0	3.0
1325_1001154	3.0	3.0
1325_1001163	2.0	3.0
1325_1001166	2.0	2.0
1325_1001169	2.0	3.0
1325_9000087	2.0	3.0
1325_9000088	3.0	3.0
1325_9000089	2.0	3.0
1325_9000095	2.0	3.0
1325_9000107	2.0	3.0
1325_9000137	3.0	3.0
1325_9000139	2.0	2.0
1325_9000187	3.0	3.0
1325_9000209	2.0	3.0
1325_9000211	2.0	3.0
1325_9000278	3.0	3.0
1325_9000316	1.0	2.0
1325_9000321	3.0	3.0
1325_9000322	3.0	3.0
1325_9000504	3.0	3.0
1325_9000533	3.0	3.0
1325_9000611	2.0	3.0
1325_9000676	3.0	3.0
1325_9000678	3.0	3.0
1325_9000750	3.0	3.0
1365_0100003	1.0	1.0
1365_0100012	2.0	2.0
1365_0100014	2.0	2.0
1365_0100019	1.0	1.0
1365_0100024	1.0	2.0
1365_0100057	2.0	2.0
1365_0100063	3.0	3.0
1365_0100064	2.0	3.0
1365_0100069	1.0	2.0
1365_0100072	2.0	2.0
1365_0100093	2.0	2.0
1365_0100123	2.0	2.0
1365_0100125	3.0	3.0
1365_0100146	2.0	2.0
1365_0100163	3.0	3.0
1365_0100182	2.0	2.0
1365_0100184	2.0	2.0
1365_0100185	1.0	2.0
1365_0100192	3.0	3.0
1365_0100199	2.0	3.0
1365_0100200	3.0	3.0
1365_0100201	2.0	2.0
1365_0100204	2.0	2.0
1365_0100217	3.0	3.0
1365_0100228	1.0	2.0
1365_0100230	2.0	3.0
1365_0100251	2.0	3.0
1365_0100262	2.0	3.0
1365_0100263	3.0	3.0
1365_0100266	3.0	2.0
1365_0100287	2.0	2.0
1365_0100289	2.0	2.0
1365_0100448	1.0	2.0
1365_0100475	2.0	2.0
1365_0100477	1.0	2.0
1365_0100481	2.0	2.0
1385_0000011	0.0	1.0
1385_0000033	1.0	1.0
1385_0000038	1.0	1.0
1385_0000041	2.0	2.0
1385_0000059	2.0	2.0
1385_0000097	2.0	1.0
1385_0000098	1.0	1.0
1385_0000102	1.0	1.0
1385_0000124	2.0	2.0
1385_0001118	1.0	1.0
1385_0001127	2.0	2.0
1385_0001135	1.0	1.0
1385_0001138	1.0	1.0
1385_0001150	2.0	2.0
1385_0001159	1.0	1.0
1385_0001163	2.0	1.0
1385_0001164	1.0	2.0
1385_0001174	0.0	1.0
1385_0001178	0.0	0.0
1385_0001194	1.0	2.0
1385_0001197	1.0	1.0
1385_0001198	2.0	2.0
1385_0001523	1.0	2.0
1385_0001716	1.0	2.0
1385_0001717	2.0	2.0
1385_0001733	2.0	2.0
1385_0001734	1.0	1.0
1385_0001751	1.0	2.0
1385_0001754	1.0	1.0
1385_0001759	0.0	1.0
1385_0001761	0.0	2.0
1385_0001764	0.0	1.0
1385_0001771	0.0	1.0
1385_0001787	0.0	2.0
1385_0001794	0.0	1.0
1385_0001795	1.0	1.0
1385_0001796	2.0	2.0
1395_0000333	2.0	2.0
1395_0000357	3.0	2.0
1395_0000380	2.0	2.0
1395_0000399	1.0	2.0
1395_0000447	1.0	1.0
1395_0000469	1.0	1.0
1395_0000471	1.0	1.0
1395_0000504	1.0	1.0
1395_0000518	2.0	2.0
1395_0000525	2.0	1.0
1395_0000528	2.0	2.0
1395_0000531	2.0	1.0
1395_0000537	1.0	2.0
1395_0000554	2.0	1.0
1395_0000564	1.0	1.0
1395_0000582	0.0	1.0
1395_0000599	1.0	1.0
1395_0000608	1.0	2.0
1395_0000611	1.0	2.0
1395_0000639	1.0	2.0
1395_0000642	0.0	1.0
1395_0000644	1.0	2.0
1395_0001028	1.0	2.0
1395_0001045	2.0	1.0
1395_0001070	1.0	2.0
1395_0001073	2.0	2.0
1395_0001075	1.0	1.0
1395_0001101	1.0	1.0
1395_0001114	1.0	1.0
1395_0001122	1.0	1.0
1395_0001131	0.0	1.0
1395_0001132	1.0	2.0
1395_0001141	1.0	2.0
1395_0001160	2.0	2.0
1395_0001161	1.0	2.0
1395_0001169	2.0	2.0
2 Fold, Dimension = Grammaticalaccuracy

======== Epoch 1 / 4 ========
Training...
Elapsed time 9
Elapsed time 19
Elapsed time 28
Elapsed time 37
Elapsed time 46

  Average training loss: 1.14
  Training epoch took: 52
Running Validation...
  Average evaluation loss: 0.89
              precision    recall  f1-score   support

         0.0       0.00      0.00      0.00        33
         1.0       0.53      0.75      0.62       142
         2.0       0.61      0.53      0.57       176
         3.0       0.67      0.73      0.70        90
         4.0       0.00      0.00      0.00        11

    accuracy                           0.59       452
   macro avg       0.36      0.40      0.38       452
weighted avg       0.54      0.59      0.55       452

[[  0  33   0   0   0]
 [  0 106  36   0   0]
 [  0  61  93  22   0]
 [  0   0  24  66   0]
 [  0   0   0  11   0]]
0.5539425982894851



======== Epoch 2 / 4 ========
Training...
Elapsed time 9
Elapsed time 19
Elapsed time 28
Elapsed time 37
Elapsed time 46

  Average training loss: 0.93
  Training epoch took: 52
Running Validation...
  Average evaluation loss: 0.87
              precision    recall  f1-score   support

         0.0       0.45      0.27      0.34        33
         1.0       0.58      0.56      0.57       142
         2.0       0.60      0.75      0.67       176
         3.0       0.73      0.61      0.67        90
         4.0       0.00      0.00      0.00        11

    accuracy                           0.61       452
   macro avg       0.47      0.44      0.45       452
weighted avg       0.59      0.61      0.60       452

[[  9  24   0   0   0]
 [ 10  79  53   0   0]
 [  1  34 132   9   0]
 [  0   0  35  55   0]
 [  0   0   0  11   0]]
0.5950368387443886



======== Epoch 3 / 4 ========
Training...
Elapsed time 9
Elapsed time 19
Elapsed time 28
Elapsed time 37
Elapsed time 46

  Average training loss: 0.79
  Training epoch took: 52
Running Validation...
  Average evaluation loss: 0.91
              precision    recall  f1-score   support

         0.0       0.67      0.18      0.29        33
         1.0       0.58      0.56      0.57       142
         2.0       0.60      0.64      0.62       176
         3.0       0.64      0.83      0.72        90
         4.0       0.00      0.00      0.00        11

    accuracy                           0.60       452
   macro avg       0.50      0.44      0.44       452
weighted avg       0.59      0.60      0.58       452

[[  6  27   0   0   0]
 [  2  79  60   1   0]
 [  1  31 113  31   0]
 [  0   0  15  75   0]
 [  0   0   0  11   0]]
0.5841214899700484



======== Epoch 4 / 4 ========
Training...
Elapsed time 9
Elapsed time 19
Elapsed time 28
Elapsed time 37
Elapsed time 46

  Average training loss: 0.68
  Training epoch took: 52
Running Validation...
  Average evaluation loss: 0.92
              precision    recall  f1-score   support

         0.0       0.60      0.36      0.45        33
         1.0       0.57      0.51      0.54       142
         2.0       0.60      0.65      0.62       176
         3.0       0.67      0.87      0.76        90
         4.0       0.00      0.00      0.00        11

    accuracy                           0.61       452
   macro avg       0.49      0.48      0.48       452
weighted avg       0.59      0.61      0.60       452

[[ 12  20   1   0   0]
 [  7  73  62   0   0]
 [  1  34 114  27   0]
 [  0   0  12  78   0]
 [  0   0   0  11   0]]
0.597586491216588
Filename	True Label	Prediction
1023_0001420	3.0	3.0
1023_0101690	2.0	2.0
1023_0101751	3.0	3.0
1023_0101841	2.0	3.0
1023_0101848	2.0	2.0
1023_0101853	2.0	3.0
1023_0101901	3.0	3.0
1023_0101906	2.0	3.0
1023_0101907	3.0	3.0
1023_0103834	4.0	3.0
1023_0107075	2.0	2.0
1023_0107244	2.0	3.0
1023_0107729	3.0	3.0
1023_0107788	2.0	3.0
1023_0108305	3.0	3.0
1023_0108510	2.0	3.0
1023_0108520	2.0	2.0
1023_0108811	3.0	2.0
1023_0108813	3.0	2.0
1023_0108889	3.0	3.0
1023_0108932	2.0	3.0
1023_0108935	2.0	3.0
1023_0109029	1.0	1.0
1023_0109030	3.0	3.0
1023_0109151	3.0	3.0
1023_0109250	2.0	3.0
1023_0109402	2.0	2.0
1023_0109496	3.0	3.0
1023_0109505	2.0	3.0
1023_0109524	3.0	3.0
1023_0109591	3.0	3.0
1023_0109614	2.0	2.0
1023_0109717	3.0	3.0
1023_0109880	3.0	3.0
1023_0109947	2.0	3.0
1031_0001998	4.0	3.0
1031_0002040	4.0	3.0
1031_0002079	4.0	3.0
1031_0002091	3.0	3.0
1031_0002131	3.0	3.0
1031_0002185	3.0	3.0
1031_0002195	3.0	3.0
1031_0002197	4.0	3.0
1031_0003013	4.0	3.0
1031_0003035	3.0	3.0
1031_0003042	3.0	3.0
1031_0003052	3.0	3.0
1031_0003071	3.0	3.0
1031_0003072	3.0	3.0
1031_0003085	3.0	3.0
1031_0003090	3.0	3.0
1031_0003126	3.0	3.0
1031_0003131	3.0	3.0
1031_0003135	3.0	3.0
1031_0003136	3.0	3.0
1031_0003140	3.0	3.0
1031_0003146	4.0	3.0
1031_0003154	3.0	3.0
1031_0003156	3.0	3.0
1031_0003161	3.0	3.0
1031_0003166	2.0	2.0
1031_0003169	3.0	3.0
1031_0003181	3.0	3.0
1031_0003184	4.0	3.0
1031_0003189	3.0	3.0
1031_0003191	3.0	3.0
1031_0003234	3.0	2.0
1031_0003242	3.0	3.0
1031_0003245	3.0	3.0
1031_0003261	3.0	3.0
1031_0003262	3.0	3.0
1031_0003338	3.0	3.0
1031_0003354	3.0	3.0
1031_0003355	3.0	3.0
1031_0003356	3.0	3.0
1031_0003357	3.0	3.0
1031_0003390	3.0	3.0
1031_0003392	3.0	3.0
1031_0003407	3.0	3.0
1031_0003414	3.0	3.0
1031_0003415	4.0	3.0
1061_0120271	2.0	2.0
1061_0120273	2.0	1.0
1061_0120274	1.0	1.0
1061_0120278	1.0	2.0
1061_0120284	0.0	0.0
1061_0120311	3.0	2.0
1061_0120316	2.0	2.0
1061_0120317	2.0	2.0
1061_0120326	2.0	2.0
1061_0120327	2.0	2.0
1061_0120331	1.0	1.0
1061_0120336	1.0	2.0
1061_0120350	2.0	2.0
1061_0120351	2.0	2.0
1061_0120357	3.0	3.0
1061_0120359	1.0	2.0
1061_0120367	2.0	2.0
1061_0120368	2.0	2.0
1061_0120375	2.0	1.0
1061_0120387	1.0	2.0
1061_0120389	2.0	2.0
1061_0120390	2.0	2.0
1061_0120394	2.0	2.0
1061_0120406	2.0	2.0
1061_0120409	2.0	2.0
1061_0120411	3.0	3.0
1061_0120414	2.0	2.0
1061_0120425	2.0	2.0
1061_0120450	2.0	2.0
1061_0120455	2.0	2.0
1061_0120456	2.0	2.0
1061_0120480	2.0	2.0
1061_0120481	2.0	3.0
1061_0120486	2.0	2.0
1061_0120493	1.0	2.0
1061_0120499	2.0	2.0
1061_0120500	1.0	2.0
1061_0120856	1.0	1.0
1061_0120877	2.0	2.0
1061_0120887	1.0	2.0
1061_1029111	2.0	2.0
1061_1029115	2.0	2.0
1061_1202914	1.0	1.0
1061_1202919	2.0	1.0
1071_0024694	1.0	2.0
1071_0024704	1.0	1.0
1071_0024706	1.0	1.0
1071_0024708	1.0	1.0
1071_0024710	1.0	1.0
1071_0024716	1.0	1.0
1071_0024766	1.0	1.0
1071_0024770	1.0	1.0
1071_0024783	0.0	2.0
1071_0024784	1.0	0.0
1071_0024812	1.0	0.0
1071_0024821	1.0	0.0
1071_0024823	1.0	1.0
1071_0024825	0.0	1.0
1071_0024835	0.0	1.0
1071_0024840	1.0	1.0
1071_0024844	1.0	1.0
1071_0024846	0.0	0.0
1071_0024851	2.0	1.0
1071_0024855	1.0	1.0
1071_0024857	0.0	1.0
1071_0024860	1.0	1.0
1071_0024862	1.0	1.0
1071_0024873	0.0	0.0
1071_0241831	1.0	2.0
1071_0242013	1.0	2.0
1071_0242021	1.0	1.0
1071_0242022	0.0	1.0
1071_0242072	0.0	0.0
1071_0242073	1.0	1.0
1071_0242091	1.0	1.0
1071_0243501	2.0	1.0
1071_0243581	0.0	0.0
1071_0243593	1.0	2.0
1071_0243623	1.0	2.0
1071_0248301	2.0	1.0
1071_0248314	1.0	1.0
1071_0248321	2.0	1.0
1071_0248326	1.0	1.0
1071_0248330	2.0	1.0
1071_0248338	1.0	1.0
1071_0248341	0.0	0.0
1071_0248343	2.0	1.0
1071_0248347	1.0	0.0
1091_0000001	1.0	1.0
1091_0000003	2.0	1.0
1091_0000004	1.0	1.0
1091_0000013	1.0	0.0
1091_0000014	0.0	1.0
1091_0000017	2.0	2.0
1091_0000025	1.0	1.0
1091_0000029	2.0	1.0
1091_0000032	1.0	2.0
1091_0000033	1.0	1.0
1091_0000044	0.0	1.0
1091_0000053	0.0	1.0
1091_0000061	2.0	0.0
1091_0000062	2.0	2.0
1091_0000063	1.0	1.0
1091_0000064	1.0	1.0
1091_0000065	2.0	2.0
1091_0000066	2.0	1.0
1091_0000069	2.0	1.0
1091_0000086	1.0	2.0
1091_0000095	1.0	1.0
1091_0000127	2.0	2.0
1091_0000148	1.0	1.0
1091_0000152	1.0	1.0
1091_0000158	2.0	2.0
1091_0000165	1.0	1.0
1091_0000166	1.0	2.0
1091_0000191	1.0	2.0
1091_0000192	1.0	2.0
1091_0000194	1.0	2.0
1091_0000205	1.0	2.0
1091_0000207	1.0	2.0
1091_0000208	1.0	2.0
1091_0000210	2.0	1.0
1091_0000219	1.0	2.0
1091_0000230	2.0	2.0
1091_0000231	1.0	2.0
1091_0000251	2.0	1.0
1091_0000257	1.0	2.0
1091_0000258	2.0	2.0
1091_0000266	2.0	2.0
0602	2.0	2.0
0603	2.0	2.0
0606	1.0	2.0
0607	2.0	2.0
0610	2.0	2.0
0618	1.0	2.0
0619	2.0	2.0
0627	2.0	2.0
0629	2.0	2.0
0638	2.0	2.0
0719	2.0	1.0
0721	2.0	2.0
0804	1.0	1.0
0817	1.0	2.0
0822	1.0	2.0
0825	1.0	2.0
0910	1.0	1.0
0921	1.0	1.0
0922	1.0	2.0
1005	1.0	2.0
1008	2.0	2.0
1112	1.0	2.0
1114	2.0	2.0
1116	1.0	2.0
BER0609003	2.0	2.0
KYJ0611004A	1.0	1.0
KYJ0611006B	1.0	1.0
LON0610002A	2.0	1.0
MOS0611012	2.0	2.0
MOS0611013	2.0	3.0
PAR1011009B	1.0	2.0
PAR1011013	2.0	3.0
PAR1011016	3.0	3.0
PHA0111002A	2.0	1.0
PHA0111016	3.0	3.0
PHA0209024	1.0	2.0
PHA0209034	2.0	2.0
PHA0209038	4.0	3.0
PHA0210004	1.0	1.0
PHA0210007	1.0	1.0
PHA0411008A	1.0	2.0
PHA0411008B	1.0	1.0
PHA0411011A	1.0	1.0
PHA0411012A	1.0	1.0
PHA0411029	2.0	1.0
PHA0411031	3.0	3.0
PHA0411042	2.0	3.0
PHA0411054	3.0	2.0
PHA0509007	1.0	2.0
PHA0509015	3.0	2.0
PHA0509020	3.0	3.0
PHA0509021	1.0	2.0
PHA0509025	3.0	3.0
PHA0509028	2.0	3.0
PHA0509031	1.0	2.0
PHA0509033	1.0	1.0
PHA0509038	1.0	1.0
PHA0510013B	1.0	1.0
PHA0510039	3.0	3.0
PHA0510050	2.0	3.0
PHA0610006A	1.0	1.0
PHA0610019A	2.0	1.0
PHA0610019B	2.0	1.0
PHA0710013	4.0	3.0
PHA0710019	3.0	3.0
PHA0710021	3.0	3.0
PHA0810006	2.0	2.0
PHA0810011	2.0	2.0
PHA0811010	2.0	1.0
PHA0811019	3.0	3.0
PHA0811020	1.0	2.0
PHA1109025	1.0	1.0
PHA1109028	3.0	3.0
PHA1110002B	2.0	1.0
PHA1110021	2.0	3.0
PHA1111004B	1.0	1.0
PHA1111006A	1.0	2.0
PHA1111009A	1.0	1.0
VAR0909004	2.0	2.0
VAR0909008	2.0	1.0
VAR0909010	1.0	2.0
VAR0910007	2.0	3.0
1325_1001008	2.0	2.0
1325_1001011	2.0	2.0
1325_1001016	2.0	2.0
1325_1001018	2.0	3.0
1325_1001019	2.0	2.0
1325_1001021	2.0	3.0
1325_1001023	2.0	2.0
1325_1001025	2.0	2.0
1325_1001033	3.0	3.0
1325_1001040	3.0	3.0
1325_1001042	2.0	3.0
1325_1001043	2.0	3.0
1325_1001045	2.0	2.0
1325_1001052	2.0	2.0
1325_1001080	2.0	2.0
1325_1001083	2.0	2.0
1325_1001086	2.0	2.0
1325_1001087	2.0	3.0
1325_1001101	3.0	3.0
1325_1001110	3.0	3.0
1325_1001121	2.0	2.0
1325_1001129	1.0	2.0
1325_1001153	2.0	2.0
1325_1001158	2.0	3.0
1325_1001159	3.0	3.0
1325_1001161	2.0	2.0
1325_1001170	3.0	3.0
1325_9000102	2.0	2.0
1325_9000104	2.0	2.0
1325_9000138	3.0	3.0
1325_9000140	3.0	3.0
1325_9000144	3.0	3.0
1325_9000279	3.0	3.0
1325_9000503	3.0	3.0
1325_9000601	3.0	3.0
1325_9000612	2.0	2.0
1325_9000674	2.0	3.0
1365_0100006	2.0	3.0
1365_0100011	1.0	2.0
1365_0100015	1.0	1.0
1365_0100016	2.0	2.0
1365_0100028	2.0	2.0
1365_0100030	1.0	2.0
1365_0100079	2.0	2.0
1365_0100080	2.0	2.0
1365_0100098	1.0	2.0
1365_0100105	3.0	3.0
1365_0100133	2.0	2.0
1365_0100137	2.0	2.0
1365_0100138	2.0	2.0
1365_0100139	2.0	2.0
1365_0100147	2.0	2.0
1365_0100167	1.0	2.0
1365_0100168	3.0	2.0
1365_0100172	2.0	2.0
1365_0100175	2.0	2.0
1365_0100181	1.0	2.0
1365_0100203	2.0	2.0
1365_0100205	3.0	2.0
1365_0100213	2.0	2.0
1365_0100218	3.0	3.0
1365_0100225	2.0	2.0
1365_0100226	2.0	2.0
1365_0100231	2.0	2.0
1365_0100233	3.0	2.0
1365_0100255	2.0	2.0
1365_0100256	2.0	2.0
1365_0100257	2.0	2.0
1365_0100259	2.0	2.0
1365_0100276	3.0	3.0
1365_0100286	1.0	2.0
1365_0100451	2.0	2.0
1365_0100456	2.0	2.0
1365_0100479	3.0	3.0
1365_0100482	2.0	2.0
1385_0000021	2.0	2.0
1385_0000034	2.0	1.0
1385_0000042	2.0	2.0
1385_0000043	2.0	2.0
1385_0000048	2.0	2.0
1385_0000050	2.0	2.0
1385_0000051	2.0	2.0
1385_0000057	1.0	1.0
1385_0000095	1.0	0.0
1385_0000119	2.0	2.0
1385_0000123	1.0	2.0
1385_0000126	2.0	1.0
1385_0000127	2.0	1.0
1385_0000129	2.0	1.0
1385_0001111	2.0	1.0
1385_0001120	1.0	1.0
1385_0001126	0.0	1.0
1385_0001128	0.0	1.0
1385_0001130	1.0	1.0
1385_0001132	1.0	1.0
1385_0001133	2.0	1.0
1385_0001136	1.0	0.0
1385_0001137	1.0	1.0
1385_0001158	1.0	2.0
1385_0001160	3.0	2.0
1385_0001173	0.0	0.0
1385_0001190	0.0	1.0
1385_0001191	1.0	1.0
1385_0001192	1.0	1.0
1385_0001503	1.0	2.0
1385_0001525	1.0	1.0
1385_0001526	0.0	0.0
1385_0001720	0.0	1.0
1385_0001725	1.0	1.0
1385_0001727	0.0	1.0
1385_0001739	0.0	1.0
1385_0001742	0.0	1.0
1385_0001746	0.0	1.0
1385_0001756	1.0	1.0
1385_0001760	1.0	1.0
1385_0001762	1.0	1.0
1385_0001765	0.0	0.0
1385_0001773	0.0	0.0
1385_0001775	0.0	1.0
1385_0001798	1.0	2.0
1395_0000353	1.0	1.0
1395_0000369	2.0	2.0
1395_0000383	2.0	2.0
1395_0000402	1.0	1.0
1395_0000403	2.0	2.0
1395_0000414	2.0	1.0
1395_0000443	2.0	2.0
1395_0000446	2.0	2.0
1395_0000448	1.0	1.0
1395_0000462	2.0	2.0
1395_0000512	2.0	2.0
1395_0000513	2.0	2.0
1395_0000514	3.0	2.0
1395_0000515	2.0	1.0
1395_0000529	2.0	1.0
1395_0000533	3.0	2.0
1395_0000549	2.0	2.0
1395_0000550	1.0	2.0
1395_0000555	1.0	1.0
1395_0000581	1.0	2.0
1395_0000583	1.0	2.0
1395_0000587	0.0	1.0
1395_0000606	1.0	1.0
1395_0000607	1.0	1.0
1395_0000628	0.0	1.0
1395_0000631	1.0	2.0
1395_0000636	0.0	1.0
1395_0001022	1.0	1.0
1395_0001040	0.0	0.0
1395_0001060	1.0	2.0
1395_0001065	1.0	2.0
1395_0001067	1.0	1.0
1395_0001069	2.0	2.0
1395_0001080	1.0	1.0
1395_0001115	1.0	2.0
1395_0001116	2.0	1.0
1395_0001118	0.0	1.0
1395_0001146	0.0	0.0
1395_0001167	1.0	2.0
1395_0001170	1.0	2.0
3 Fold, Dimension = Grammaticalaccuracy

======== Epoch 1 / 4 ========
Training...
Elapsed time 9
Elapsed time 19
Elapsed time 28
Elapsed time 37
Elapsed time 46

  Average training loss: 1.15
  Training epoch took: 52
Running Validation...
  Average evaluation loss: 0.98
              precision    recall  f1-score   support

         0.0       0.00      0.00      0.00        33
         1.0       0.56      0.65      0.60       142
         2.0       0.57      0.62      0.60       177
         3.0       0.59      0.62      0.61        90
         4.0       0.00      0.00      0.00        10

    accuracy                           0.57       452
   macro avg       0.34      0.38      0.36       452
weighted avg       0.52      0.57      0.54       452

[[  0  33   0   0   0]
 [  0  92  50   0   0]
 [  0  38 110  29   0]
 [  0   2  32  56   0]
 [  0   0   0  10   0]]
0.5423062690878692



======== Epoch 2 / 4 ========
Training...
Elapsed time 9
Elapsed time 19
Elapsed time 28
Elapsed time 37
Elapsed time 47

  Average training loss: 0.90
  Training epoch took: 53
Running Validation...
  Average evaluation loss: 0.93
              precision    recall  f1-score   support

         0.0       1.00      0.12      0.22        33
         1.0       0.57      0.73      0.64       142
         2.0       0.60      0.69      0.64       177
         3.0       0.70      0.49      0.58        90
         4.0       0.00      0.00      0.00        10

    accuracy                           0.60       452
   macro avg       0.57      0.40      0.41       452
weighted avg       0.62      0.60      0.58       452

[[  4  29   0   0   0]
 [  0 103  39   0   0]
 [  0  45 122  10   0]
 [  0   3  43  44   0]
 [  0   0   1   9   0]]
0.5814206927819007



======== Epoch 3 / 4 ========
Training...
Elapsed time 9
Elapsed time 19
Elapsed time 28
Elapsed time 37
Elapsed time 46

  Average training loss: 0.78
  Training epoch took: 53
Running Validation...
  Average evaluation loss: 0.94
              precision    recall  f1-score   support

         0.0       0.77      0.30      0.43        33
         1.0       0.61      0.60      0.60       142
         2.0       0.59      0.59      0.59       177
         3.0       0.58      0.79      0.67        90
         4.0       0.00      0.00      0.00        10

    accuracy                           0.60       452
   macro avg       0.51      0.46      0.46       452
weighted avg       0.60      0.60      0.59       452

[[ 10  23   0   0   0]
 [  2  85  55   0   0]
 [  1  30 105  41   0]
 [  0   2  17  71   0]
 [  0   0   0  10   0]]
0.5868001810493665



======== Epoch 4 / 4 ========
Training...
Elapsed time 9
Elapsed time 19
Elapsed time 28
Elapsed time 38
Elapsed time 47

  Average training loss: 0.62
  Training epoch took: 54
Running Validation...
  Average evaluation loss: 1.03
              precision    recall  f1-score   support

         0.0       0.83      0.30      0.44        33
         1.0       0.61      0.48      0.54       142
         2.0       0.55      0.62      0.58       177
         3.0       0.56      0.80      0.66        90
         4.0       0.00      0.00      0.00        10

    accuracy                           0.58       452
   macro avg       0.51      0.44      0.44       452
weighted avg       0.58      0.58      0.56       452

[[ 10  21   2   0   0]
 [  2  68  71   1   0]
 [  0  22 110  45   0]
 [  0   1  17  72   0]
 [  0   0   0  10   0]]
0.5607009484126051
Filename	True Label	Prediction
1023_0101675	3.0	3.0
1023_0101684	2.0	3.0
1023_0101749	4.0	3.0
1023_0101852	3.0	3.0
1023_0101894	2.0	3.0
1023_0101896	2.0	2.0
1023_0101897	2.0	3.0
1023_0103824	3.0	3.0
1023_0103828	1.0	2.0
1023_0103829	2.0	3.0
1023_0103840	3.0	3.0
1023_0103883	2.0	3.0
1023_0104207	2.0	2.0
1023_0106816	3.0	3.0
1023_0107042	3.0	2.0
1023_0107074	3.0	3.0
1023_0107781	2.0	3.0
1023_0107784	1.0	2.0
1023_0107787	2.0	2.0
1023_0108304	3.0	3.0
1023_0108641	3.0	3.0
1023_0108753	2.0	2.0
1023_0108766	2.0	3.0
1023_0108810	3.0	3.0
1023_0108812	2.0	3.0
1023_0108885	2.0	2.0
1023_0108933	2.0	3.0
1023_0108955	3.0	3.0
1023_0109096	3.0	3.0
1023_0109248	2.0	2.0
1023_0109392	2.0	3.0
1023_0109399	2.0	3.0
1023_0109500	2.0	3.0
1023_0109515	3.0	3.0
1023_0109520	2.0	3.0
1023_0109588	3.0	2.0
1023_0109649	2.0	3.0
1023_0109651	3.0	3.0
1023_0109716	3.0	3.0
1023_0109721	2.0	2.0
1023_0109890	3.0	3.0
1023_0109917	3.0	3.0
1023_0109945	4.0	3.0
1023_0109954	3.0	3.0
1031_0001949	3.0	3.0
1031_0002061	3.0	3.0
1031_0002083	2.0	3.0
1031_0002086	3.0	3.0
1031_0002088	3.0	3.0
1031_0002187	3.0	3.0
1031_0003012	3.0	3.0
1031_0003043	4.0	3.0
1031_0003048	4.0	3.0
1031_0003053	3.0	3.0
1031_0003063	4.0	3.0
1031_0003099	3.0	3.0
1031_0003128	3.0	3.0
1031_0003129	3.0	3.0
1031_0003132	3.0	3.0
1031_0003144	3.0	3.0
1031_0003160	3.0	3.0
1031_0003180	3.0	3.0
1031_0003185	3.0	3.0
1031_0003186	3.0	3.0
1031_0003203	2.0	2.0
1031_0003212	2.0	3.0
1031_0003217	3.0	3.0
1031_0003219	3.0	3.0
1031_0003224	3.0	3.0
1031_0003225	3.0	3.0
1031_0003232	2.0	3.0
1031_0003233	2.0	3.0
1031_0003236	3.0	3.0
1031_0003239	4.0	3.0
1031_0003243	3.0	3.0
1031_0003310	3.0	3.0
1031_0003313	4.0	3.0
1031_0003314	3.0	3.0
1031_0003330	3.0	3.0
1031_0003353	3.0	3.0
1031_0003358	4.0	3.0
1031_0003368	3.0	3.0
1031_0003369	3.0	3.0
1031_0003386	2.0	3.0
1031_0003409	4.0	3.0
1061_0120277	1.0	1.0
1061_0120279	1.0	1.0
1061_0120280	1.0	1.0
1061_0120282	0.0	1.0
1061_0120283	0.0	1.0
1061_0120285	1.0	2.0
1061_0120298	1.0	1.0
1061_0120300	2.0	1.0
1061_0120319	2.0	2.0
1061_0120320	3.0	3.0
1061_0120321	2.0	2.0
1061_0120329	2.0	2.0
1061_0120341	1.0	1.0
1061_0120343	2.0	2.0
1061_0120345	2.0	2.0
1061_0120348	1.0	1.0
1061_0120353	1.0	1.0
1061_0120361	2.0	3.0
1061_0120373	2.0	2.0
1061_0120376	2.0	2.0
1061_0120388	1.0	2.0
1061_0120423	2.0	3.0
1061_0120432	1.0	1.0
1061_0120438	2.0	2.0
1061_0120440	1.0	1.0
1061_0120441	2.0	2.0
1061_0120449	3.0	2.0
1061_0120478	2.0	2.0
1061_0120479	2.0	2.0
1061_0120484	1.0	2.0
1061_0120488	2.0	2.0
1061_0120496	1.0	2.0
1061_0120497	2.0	3.0
1061_0120498	2.0	3.0
1061_0120855	1.0	2.0
1061_0120857	2.0	2.0
1061_0120859	2.0	2.0
1061_0120882	2.0	3.0
1061_0120883	1.0	2.0
1061_0120886	2.0	2.0
1061_1029113	2.0	2.0
1061_1029119	1.0	2.0
1061_1029120	1.0	1.0
1061_1202913	2.0	2.0
1061_1202916	2.0	2.0
1071_0024685	1.0	2.0
1071_0024688	1.0	1.0
1071_0024689	1.0	1.0
1071_0024691	1.0	2.0
1071_0024711	1.0	1.0
1071_0024713	1.0	1.0
1071_0024756	1.0	1.0
1071_0024758	2.0	2.0
1071_0024767	2.0	2.0
1071_0024781	0.0	1.0
1071_0024782	0.0	0.0
1071_0024797	0.0	1.0
1071_0024799	2.0	2.0
1071_0024807	0.0	1.0
1071_0024814	1.0	1.0
1071_0024818	2.0	1.0
1071_0024834	2.0	2.0
1071_0024836	1.0	2.0
1071_0024845	0.0	1.0
1071_0024852	0.0	0.0
1071_0024861	0.0	0.0
1071_0024864	0.0	0.0
1071_0024865	2.0	2.0
1071_0024867	1.0	2.0
1071_0024879	1.0	1.0
1071_0242041	1.0	1.0
1071_0242093	0.0	0.0
1071_0243502	1.0	1.0
1071_0243592	1.0	1.0
1071_0248305	0.0	0.0
1071_0248311	1.0	1.0
1071_0248320	0.0	0.0
1071_0248323	0.0	1.0
1071_0248332	2.0	2.0
1071_0248336	0.0	1.0
1071_0248339	2.0	1.0
1071_0248340	0.0	1.0
1071_0248345	1.0	2.0
1091_0000008	2.0	2.0
1091_0000009	0.0	1.0
1091_0000016	0.0	2.0
1091_0000019	1.0	2.0
1091_0000022	1.0	2.0
1091_0000023	2.0	1.0
1091_0000024	3.0	1.0
1091_0000026	1.0	1.0
1091_0000027	0.0	2.0
1091_0000047	2.0	1.0
1091_0000049	1.0	1.0
1091_0000051	1.0	1.0
1091_0000058	2.0	2.0
1091_0000072	1.0	2.0
1091_0000074	1.0	2.0
1091_0000076	2.0	2.0
1091_0000078	2.0	1.0
1091_0000113	1.0	2.0
1091_0000151	0.0	1.0
1091_0000155	1.0	3.0
1091_0000156	2.0	2.0
1091_0000160	2.0	2.0
1091_0000161	2.0	1.0
1091_0000164	1.0	1.0
1091_0000168	2.0	2.0
1091_0000169	3.0	2.0
1091_0000170	2.0	1.0
1091_0000172	2.0	1.0
1091_0000174	2.0	1.0
1091_0000197	1.0	2.0
1091_0000211	1.0	2.0
1091_0000212	1.0	2.0
1091_0000218	2.0	1.0
1091_0000225	2.0	1.0
1091_0000229	1.0	2.0
1091_0000234	3.0	2.0
1091_0000245	1.0	2.0
1091_0000246	2.0	2.0
1091_0000248	2.0	2.0
1091_0000263	3.0	2.0
1091_0000268	2.0	2.0
1091_0000269	1.0	2.0
1091_0000273	1.0	2.0
0604	2.0	2.0
0612	1.0	1.0
0614	1.0	2.0
0624	2.0	2.0
0625	2.0	1.0
0632	1.0	1.0
0639	1.0	2.0
0643	2.0	2.0
0644	1.0	2.0
0722	2.0	2.0
0803	2.0	2.0
0807	2.0	2.0
0808	1.0	2.0
0809	2.0	2.0
0813	1.0	2.0
0818	1.0	2.0
0820	1.0	1.0
0827	1.0	2.0
0904	1.0	2.0
0905	2.0	2.0
0907	2.0	2.0
0913	2.0	2.0
0919	1.0	2.0
0927	1.0	2.0
0930	2.0	2.0
1009	2.0	2.0
1019	1.0	2.0
1020	2.0	2.0
1113	1.0	2.0
9999	1.0	1.0
KYJ0611005B	1.0	1.0
KYJ0611009B	1.0	1.0
LIB0611003A	1.0	1.0
LIB0611011	1.0	1.0
LON0610002B	1.0	1.0
LON0611002A	1.0	2.0
LON0611002B	1.0	1.0
PHA0111005A	1.0	2.0
PHA0111010	3.0	3.0
PHA0111014	1.0	2.0
PHA0112009B	2.0	1.0
PHA0112012A	1.0	2.0
PHA0209031	4.0	3.0
PHA0210008	1.0	1.0
PHA0411009A	2.0	2.0
PHA0411034	1.0	1.0
PHA0411036	3.0	2.0
PHA0411045	3.0	2.0
PHA0411053	3.0	3.0
PHA0509017	2.0	3.0
PHA0509019	3.0	2.0
PHA0509026	3.0	3.0
PHA0509040	2.0	2.0
PHA0509044	2.0	2.0
PHA0510002B	2.0	1.0
PHA0510010B	0.0	1.0
PHA0510013A	2.0	2.0
PHA0510023	3.0	3.0
PHA0510027	1.0	2.0
PHA0510035	3.0	3.0
PHA0510036	3.0	3.0
PHA0510037	1.0	2.0
PHA0510049	3.0	3.0
PHA0610005B	0.0	1.0
PHA0610007A	1.0	1.0
PHA0610018	2.0	3.0
PHA0610025	2.0	3.0
PHA0709008	3.0	3.0
PHA0710011	3.0	3.0
PHA0710016	3.0	2.0
PHA0810008	3.0	3.0
PHA0810009	3.0	3.0
PHA1109002	3.0	3.0
PHA1109003	1.0	1.0
PHA1109004	3.0	3.0
PHA1110001B	1.0	1.0
PHA1110013	2.0	3.0
PHA1110016	1.0	2.0
PHA1110022	3.0	3.0
PHA1111001A	1.0	2.0
PHA1111002A	2.0	1.0
PHA1111002B	1.0	1.0
PHA1111004A	1.0	2.0
VAR0910005	3.0	2.0
1325_1001010	2.0	2.0
1325_1001020	2.0	2.0
1325_1001024	2.0	2.0
1325_1001027	3.0	2.0
1325_1001037	2.0	2.0
1325_1001041	3.0	3.0
1325_1001047	1.0	1.0
1325_1001048	1.0	2.0
1325_1001053	1.0	2.0
1325_1001062	2.0	3.0
1325_1001079	3.0	3.0
1325_1001088	2.0	2.0
1325_1001098	2.0	3.0
1325_1001111	3.0	3.0
1325_1001119	3.0	3.0
1325_1001156	2.0	3.0
1325_1001157	2.0	2.0
1325_1001164	2.0	2.0
1325_1001165	2.0	2.0
1325_9000090	2.0	3.0
1325_9000106	2.0	3.0
1325_9000188	2.0	3.0
1325_9000296	2.0	3.0
1325_9000303	3.0	3.0
1325_9000314	2.0	2.0
1325_9000319	2.0	2.0
1325_9000320	3.0	2.0
1325_9000677	3.0	3.0
1325_9000684	3.0	3.0
1325_9000700	2.0	3.0
1365_0100002	2.0	2.0
1365_0100007	1.0	1.0
1365_0100018	1.0	2.0
1365_0100020	2.0	2.0
1365_0100021	2.0	2.0
1365_0100022	2.0	2.0
1365_0100031	2.0	2.0
1365_0100051	1.0	2.0
1365_0100067	2.0	2.0
1365_0100070	2.0	3.0
1365_0100071	2.0	2.0
1365_0100073	2.0	2.0
1365_0100092	2.0	2.0
1365_0100096	2.0	3.0
1365_0100097	2.0	2.0
1365_0100100	2.0	3.0
1365_0100104	2.0	2.0
1365_0100106	2.0	2.0
1365_0100116	2.0	2.0
1365_0100117	3.0	3.0
1365_0100119	3.0	3.0
1365_0100135	2.0	2.0
1365_0100162	2.0	2.0
1365_0100170	1.0	2.0
1365_0100173	2.0	2.0
1365_0100176	2.0	2.0
1365_0100179	2.0	2.0
1365_0100183	1.0	2.0
1365_0100211	2.0	3.0
1365_0100220	2.0	3.0
1365_0100221	2.0	3.0
1365_0100232	3.0	3.0
1365_0100252	2.0	2.0
1365_0100268	2.0	2.0
1365_0100290	2.0	2.0
1365_0100299	3.0	3.0
1365_0100455	3.0	3.0
1365_0100458	2.0	3.0
1365_0100469	2.0	2.0
1365_0100474	2.0	2.0
1365_0100476	2.0	3.0
1365_0100478	2.0	3.0
1385_0000016	2.0	1.0
1385_0000036	1.0	1.0
1385_0000052	1.0	2.0
1385_0000104	2.0	1.0
1385_0000114	2.0	2.0
1385_0001103	2.0	1.0
1385_0001104	1.0	0.0
1385_0001105	2.0	1.0
1385_0001112	2.0	2.0
1385_0001113	1.0	1.0
1385_0001124	1.0	1.0
1385_0001134	1.0	1.0
1385_0001152	2.0	2.0
1385_0001153	3.0	2.0
1385_0001154	2.0	2.0
1385_0001169	1.0	0.0
1385_0001172	0.0	1.0
1385_0001196	1.0	1.0
1385_0001501	1.0	2.0
1385_0001524	0.0	1.0
1385_0001724	1.0	2.0
1385_0001726	1.0	1.0
1385_0001728	1.0	2.0
1385_0001729	1.0	2.0
1385_0001740	1.0	1.0
1385_0001748	1.0	2.0
1385_0001750	0.0	0.0
1385_0001757	2.0	1.0
1385_0001800	1.0	1.0
1395_0000337	0.0	0.0
1395_0000338	1.0	1.0
1395_0000340	2.0	2.0
1395_0000354	1.0	1.0
1395_0000359	2.0	2.0
1395_0000360	3.0	2.0
1395_0000361	2.0	2.0
1395_0000365	2.0	2.0
1395_0000366	2.0	2.0
1395_0000376	2.0	2.0
1395_0000379	1.0	1.0
1395_0000387	3.0	2.0
1395_0000389	0.0	1.0
1395_0000391	3.0	2.0
1395_0000392	2.0	2.0
1395_0000396	2.0	2.0
1395_0000398	2.0	2.0
1395_0000409	2.0	2.0
1395_0000452	1.0	1.0
1395_0000454	2.0	2.0
1395_0000455	1.0	2.0
1395_0000460	1.0	1.0
1395_0000465	1.0	1.0
1395_0000499	1.0	1.0
1395_0000500	1.0	1.0
1395_0000516	1.0	1.0
1395_0000548	2.0	2.0
1395_0000560	2.0	2.0
1395_0000565	1.0	1.0
1395_0000575	1.0	1.0
1395_0000584	0.0	0.0
1395_0000585	1.0	2.0
1395_0000591	0.0	1.0
1395_0000593	1.0	2.0
1395_0000597	1.0	2.0
1395_0000602	1.0	1.0
1395_0000610	2.0	1.0
1395_0000630	1.0	2.0
1395_0000646	1.0	2.0
1395_0001013	1.0	2.0
1395_0001015	1.0	1.0
1395_0001017	1.0	1.0
1395_0001019	0.0	1.0
1395_0001020	1.0	1.0
1395_0001058	1.0	2.0
1395_0001074	1.0	2.0
1395_0001103	1.0	2.0
1395_0001109	0.0	1.0
1395_0001117	1.0	1.0
1395_0001119	1.0	2.0
1395_0001121	0.0	1.0
1395_0001126	1.0	1.0
1395_0001133	0.0	1.0
1395_0001145	2.0	2.0
1395_0001147	1.0	2.0
1395_0001164	2.0	2.0
4 Fold, Dimension = Grammaticalaccuracy

======== Epoch 1 / 4 ========
Training...
Elapsed time 10
Elapsed time 19
Elapsed time 29
Elapsed time 39
Elapsed time 48

  Average training loss: 1.17
  Training epoch took: 55
Running Validation...
  Average evaluation loss: 0.91
              precision    recall  f1-score   support

         0.0       0.00      0.00      0.00        33
         1.0       0.58      0.71      0.64       142
         2.0       0.59      0.65      0.62       176
         3.0       0.63      0.57      0.60        91
         4.0       0.00      0.00      0.00        10

    accuracy                           0.59       452
   macro avg       0.36      0.39      0.37       452
weighted avg       0.54      0.59      0.56       452

[[  0  33   0   0   0]
 [  0 101  41   0   0]
 [  0  40 115  21   0]
 [  0   0  39  52   0]
 [  0   0   0  10   0]]
0.5625519217385296



======== Epoch 2 / 4 ========
Training...
Elapsed time 9
Elapsed time 19
Elapsed time 28
Elapsed time 38
Elapsed time 47

  Average training loss: 0.92
  Training epoch took: 53
Running Validation...
  Average evaluation loss: 0.84
              precision    recall  f1-score   support

         0.0       0.80      0.24      0.37        33
         1.0       0.63      0.73      0.68       142
         2.0       0.67      0.56      0.61       176
         3.0       0.58      0.85      0.69        91
         4.0       0.00      0.00      0.00        10

    accuracy                           0.63       452
   macro avg       0.54      0.47      0.47       452
weighted avg       0.63      0.63      0.61       452

[[  8  24   1   0   0]
 [  2 103  33   4   0]
 [  0  36  98  42   0]
 [  0   0  14  77   0]
 [  0   0   0  10   0]]
0.614779206352571



======== Epoch 3 / 4 ========
Training...
Elapsed time 9
Elapsed time 19
Elapsed time 28
Elapsed time 38
Elapsed time 47

  Average training loss: 0.76
  Training epoch took: 53
Running Validation...
  Average evaluation loss: 0.84
              precision    recall  f1-score   support

         0.0       0.77      0.30      0.43        33
         1.0       0.67      0.59      0.63       142
         2.0       0.61      0.74      0.67       176
         3.0       0.65      0.71      0.68        91
         4.0       0.00      0.00      0.00        10

    accuracy                           0.64       452
   macro avg       0.54      0.47      0.48       452
weighted avg       0.64      0.64      0.63       452

[[ 10  21   2   0   0]
 [  3  84  55   0   0]
 [  0  20 131  25   0]
 [  0   0  26  65   0]
 [  0   0   0  10   0]]
0.6280292276647448



======== Epoch 4 / 4 ========
Training...
Elapsed time 10
Elapsed time 19
Elapsed time 28
Elapsed time 38
Elapsed time 47

  Average training loss: 0.61
  Training epoch took: 53
Running Validation...
  Average evaluation loss: 0.99
              precision    recall  f1-score   support

         0.0       0.73      0.24      0.36        33
         1.0       0.65      0.48      0.55       142
         2.0       0.58      0.62      0.60       176
         3.0       0.56      0.91      0.70        91
         4.0       0.00      0.00      0.00        10

    accuracy                           0.59       452
   macro avg       0.50      0.45      0.44       452
weighted avg       0.59      0.59      0.57       452

[[  8  21   4   0   0]
 [  3  68  68   3   0]
 [  0  16 109  51   0]
 [  0   0   8  83   0]
 [  0   0   0  10   0]]
0.5725102461776238
Filename	True Label	Prediction
1023_0001416	4.0	3.0
1023_0001419	3.0	3.0
1023_0001575	3.0	3.0
1023_0101689	1.0	1.0
1023_0101693	3.0	3.0
1023_0101695	2.0	3.0
1023_0101753	3.0	3.0
1023_0101846	4.0	3.0
1023_0101849	3.0	3.0
1023_0101851	3.0	3.0
1023_0101854	2.0	2.0
1023_0101855	2.0	2.0
1023_0101899	3.0	3.0
1023_0101900	3.0	3.0
1023_0101909	3.0	3.0
1023_0103821	3.0	3.0
1023_0103836	3.0	3.0
1023_0103839	3.0	3.0
1023_0107725	2.0	3.0
1023_0107726	2.0	3.0
1023_0107780	3.0	3.0
1023_0108307	3.0	3.0
1023_0108423	2.0	2.0
1023_0108649	3.0	3.0
1023_0108650	3.0	3.0
1023_0108814	3.0	3.0
1023_0108887	2.0	2.0
1023_0108888	3.0	3.0
1023_0108908	2.0	3.0
1023_0108931	3.0	3.0
1023_0108958	2.0	3.0
1023_0108992	3.0	3.0
1023_0108993	3.0	3.0
1023_0109026	2.0	2.0
1023_0109033	3.0	3.0
1023_0109192	2.0	2.0
1023_0109249	2.0	3.0
1023_0109395	2.0	2.0
1023_0109400	3.0	3.0
1023_0109422	3.0	3.0
1023_0109528	3.0	2.0
1023_0109590	3.0	2.0
1023_0109671	3.0	3.0
1023_0109946	2.0	2.0
1031_0001950	3.0	3.0
1031_0002010	2.0	3.0
1031_0002032	3.0	3.0
1031_0002084	3.0	3.0
1031_0002085	3.0	3.0
1031_0002087	3.0	3.0
1031_0002184	3.0	3.0
1031_0002199	3.0	3.0
1031_0002200	2.0	3.0
1031_0003029	3.0	3.0
1031_0003054	3.0	3.0
1031_0003074	3.0	3.0
1031_0003076	4.0	3.0
1031_0003098	4.0	3.0
1031_0003121	4.0	3.0
1031_0003127	4.0	3.0
1031_0003130	4.0	3.0
1031_0003149	3.0	3.0
1031_0003165	2.0	3.0
1031_0003167	3.0	3.0
1031_0003170	2.0	3.0
1031_0003174	4.0	3.0
1031_0003179	3.0	3.0
1031_0003190	3.0	3.0
1031_0003216	3.0	3.0
1031_0003218	3.0	3.0
1031_0003231	3.0	3.0
1031_0003235	3.0	3.0
1031_0003238	3.0	3.0
1031_0003240	2.0	3.0
1031_0003246	3.0	3.0
1031_0003249	3.0	3.0
1031_0003309	3.0	3.0
1031_0003331	2.0	3.0
1031_0003336	2.0	3.0
1031_0003337	3.0	3.0
1031_0003339	3.0	3.0
1031_0003367	4.0	3.0
1031_0003384	2.0	2.0
1031_0003393	3.0	3.0
1061_0120275	2.0	1.0
1061_0120287	1.0	2.0
1061_0120308	3.0	3.0
1061_0120312	1.0	1.0
1061_0120325	2.0	1.0
1061_0120328	1.0	1.0
1061_0120332	1.0	2.0
1061_0120333	3.0	3.0
1061_0120335	3.0	3.0
1061_0120337	2.0	2.0
1061_0120338	2.0	2.0
1061_0120346	2.0	2.0
1061_0120355	1.0	1.0
1061_0120366	3.0	3.0
1061_0120369	1.0	1.0
1061_0120370	2.0	2.0
1061_0120383	2.0	3.0
1061_0120384	1.0	1.0
1061_0120386	0.0	1.0
1061_0120415	2.0	2.0
1061_0120427	1.0	2.0
1061_0120428	2.0	2.0
1061_0120429	2.0	2.0
1061_0120430	1.0	2.0
1061_0120457	3.0	2.0
1061_0120460	2.0	2.0
1061_0120482	1.0	2.0
1061_0120487	2.0	2.0
1061_0120491	2.0	2.0
1061_0120853	1.0	2.0
1061_0120884	1.0	2.0
1061_0120885	2.0	2.0
1061_0120888	1.0	2.0
1061_0120890	1.0	1.0
1061_0120894	2.0	2.0
1061_1029114	1.0	1.0
1061_1029116	1.0	1.0
1061_1029117	1.0	2.0
1061_1029118	1.0	2.0
1061_1202915	1.0	2.0
1071_0020001	1.0	1.0
1071_0024680	2.0	2.0
1071_0024683	0.0	1.0
1071_0024693	1.0	1.0
1071_0024699	1.0	1.0
1071_0024709	2.0	2.0
1071_0024769	0.0	2.0
1071_0024773	1.0	1.0
1071_0024776	0.0	0.0
1071_0024778	0.0	0.0
1071_0024804	1.0	1.0
1071_0024806	1.0	1.0
1071_0024808	0.0	1.0
1071_0024811	1.0	1.0
1071_0024813	0.0	1.0
1071_0024816	1.0	1.0
1071_0024820	0.0	1.0
1071_0024824	1.0	1.0
1071_0024833	1.0	1.0
1071_0024838	0.0	0.0
1071_0024847	1.0	2.0
1071_0024866	2.0	2.0
1071_0242043	0.0	1.0
1071_0242092	0.0	0.0
1071_0243622	1.0	0.0
1071_0248302	0.0	0.0
1071_0248303	0.0	0.0
1071_0248307	2.0	1.0
1071_0248310	0.0	1.0
1071_0248312	1.0	1.0
1071_0248319	0.0	1.0
1071_0248325	0.0	1.0
1071_0248327	0.0	0.0
1071_0248335	1.0	1.0
1071_0248349	1.0	1.0
1091_0000002	2.0	2.0
1091_0000005	2.0	2.0
1091_0000011	1.0	2.0
1091_0000012	1.0	1.0
1091_0000015	2.0	2.0
1091_0000018	2.0	2.0
1091_0000020	1.0	2.0
1091_0000021	1.0	2.0
1091_0000034	2.0	1.0
1091_0000038	1.0	1.0
1091_0000043	1.0	1.0
1091_0000059	1.0	2.0
1091_0000060	2.0	3.0
1091_0000075	2.0	2.0
1091_0000123	2.0	2.0
1091_0000145	1.0	1.0
1091_0000146	1.0	1.0
1091_0000167	2.0	2.0
1091_0000171	1.0	2.0
1091_0000185	2.0	1.0
1091_0000195	1.0	1.0
1091_0000199	2.0	2.0
1091_0000201	2.0	1.0
1091_0000202	1.0	2.0
1091_0000216	1.0	2.0
1091_0000222	2.0	1.0
1091_0000224	1.0	1.0
1091_0000226	1.0	1.0
1091_0000238	1.0	2.0
1091_0000244	2.0	2.0
1091_0000255	0.0	2.0
1091_0000260	1.0	2.0
1091_0000271	2.0	2.0
1091_0000272	1.0	1.0
1091_0000274	1.0	2.0
1091_0000276	2.0	1.0
0611	2.0	2.0
0613	1.0	1.0
0615	1.0	2.0
0616	1.0	2.0
0617	1.0	2.0
0620	1.0	2.0
0631	2.0	2.0
0633	2.0	2.0
0642	1.0	2.0
0645	2.0	2.0
0715	2.0	2.0
0716	2.0	2.0
0724	2.0	2.0
0802	2.0	2.0
0805	2.0	2.0
0806	1.0	2.0
0819	3.0	2.0
0823	2.0	2.0
0829	1.0	2.0
0903	1.0	2.0
0916	1.0	1.0
0923	2.0	2.0
0925	2.0	2.0
0928	1.0	2.0
0929	0.0	1.0
1003	1.0	2.0
1006	2.0	2.0
1007	2.0	2.0
1010	1.0	2.0
1014	2.0	2.0
KYJ0611003A	1.0	1.0
LIB0611001B	1.0	1.0
LON0611004B	1.0	1.0
MOS0611014	1.0	1.0
MOS0611015	2.0	3.0
PAR1011008A	1.0	1.0
PAR1011009A	2.0	2.0
PAR1011014	2.0	3.0
PAR1011018	3.0	2.0
PHA0111001A	1.0	1.0
PHA0111005B	2.0	1.0
PHA0111011	2.0	3.0
PHA0112002B	1.0	1.0
PHA0112003B	1.0	1.0
PHA0112006A	3.0	2.0
PHA0112007B	1.0	1.0
PHA0209026	2.0	3.0
PHA0209028	2.0	2.0
PHA0210001	1.0	1.0
PHA0411010A	0.0	1.0
PHA0411012B	1.0	1.0
PHA0411032	1.0	3.0
PHA0411033	2.0	2.0
PHA0411035	3.0	3.0
PHA0411037	2.0	3.0
PHA0411039	2.0	3.0
PHA0411060	2.0	3.0
PHA0411061	3.0	3.0
PHA0509022	4.0	3.0
PHA0509024	2.0	3.0
PHA0509027	1.0	2.0
PHA0509030	2.0	3.0
PHA0509032	2.0	3.0
PHA0509034	1.0	3.0
PHA0509039	3.0	3.0
PHA0509041	2.0	3.0
PHA0510003A	1.0	2.0
PHA0510003B	1.0	1.0
PHA0510004A	1.0	1.0
PHA0510010A	1.0	1.0
PHA0510030	2.0	3.0
PHA0510031	2.0	2.0
PHA0510032	3.0	3.0
PHA0510038	3.0	3.0
PHA0510040	2.0	3.0
PHA0510048	1.0	2.0
PHA0610005A	1.0	1.0
PHA0610006B	1.0	1.0
PHA0610007B	1.0	1.0
PHA0710010	2.0	3.0
PHA0710014	3.0	3.0
PHA0710015	2.0	2.0
PHA0810002	1.0	2.0
PHA0810012	3.0	3.0
PHA0811014	1.0	3.0
PHA1109006	2.0	2.0
PHA1110015	3.0	3.0
PHA1110019	2.0	2.0
VAR0910011	3.0	3.0
1325_1001009	2.0	2.0
1325_1001013	2.0	3.0
1325_1001014	3.0	3.0
1325_1001022	2.0	2.0
1325_1001035	3.0	3.0
1325_1001036	2.0	2.0
1325_1001039	3.0	3.0
1325_1001051	2.0	2.0
1325_1001057	2.0	2.0
1325_1001081	3.0	2.0
1325_1001082	2.0	2.0
1325_1001093	2.0	2.0
1325_1001094	2.0	3.0
1325_1001095	2.0	2.0
1325_1001096	2.0	2.0
1325_1001097	1.0	2.0
1325_1001100	2.0	2.0
1325_1001107	3.0	3.0
1325_1001108	3.0	3.0
1325_1001120	3.0	3.0
1325_1001126	2.0	2.0
1325_1001128	2.0	3.0
1325_1001130	2.0	2.0
1325_1001133	2.0	3.0
1325_1001135	2.0	2.0
1325_1001141	2.0	2.0
1325_1001167	3.0	3.0
1325_1001168	2.0	3.0
1325_9000059	2.0	3.0
1325_9000099	2.0	3.0
1325_9000105	1.0	2.0
1325_9000136	2.0	3.0
1325_9000210	2.0	2.0
1325_9000213	3.0	3.0
1325_9000239	3.0	3.0
1325_9000240	2.0	2.0
1325_9000302	2.0	2.0
1325_9000315	2.0	2.0
1325_9000317	3.0	3.0
1325_9000318	3.0	3.0
1325_9000505	2.0	3.0
1325_9000536	2.0	3.0
1325_9000602	3.0	3.0
1325_9000675	3.0	2.0
1365_0100017	2.0	3.0
1365_0100027	2.0	2.0
1365_0100029	1.0	1.0
1365_0100056	2.0	3.0
1365_0100058	2.0	3.0
1365_0100065	1.0	2.0
1365_0100066	1.0	2.0
1365_0100094	2.0	2.0
1365_0100099	2.0	2.0
1365_0100118	3.0	3.0
1365_0100120	3.0	3.0
1365_0100121	3.0	3.0
1365_0100134	2.0	2.0
1365_0100136	2.0	2.0
1365_0100145	2.0	3.0
1365_0100164	2.0	3.0
1365_0100178	2.0	2.0
1365_0100180	1.0	1.0
1365_0100186	2.0	2.0
1365_0100190	2.0	3.0
1365_0100191	2.0	2.0
1365_0100194	3.0	3.0
1365_0100195	1.0	2.0
1365_0100212	3.0	3.0
1365_0100215	2.0	2.0
1365_0100219	2.0	3.0
1365_0100223	2.0	3.0
1365_0100258	2.0	2.0
1365_0100260	2.0	3.0
1365_0100261	2.0	2.0
1365_0100265	3.0	3.0
1365_0100269	2.0	3.0
1365_0100270	2.0	2.0
1365_0100275	2.0	3.0
1365_0100281	1.0	2.0
1365_0100282	2.0	2.0
1365_0100285	2.0	2.0
1365_0100447	3.0	3.0
1365_0100457	2.0	3.0
1365_0100461	2.0	2.0
1365_0100480	2.0	2.0
1385_0000012	2.0	2.0
1385_0000020	2.0	1.0
1385_0000023	2.0	1.0
1385_0000035	2.0	2.0
1385_0000037	1.0	2.0
1385_0000040	1.0	1.0
1385_0000044	2.0	2.0
1385_0000049	2.0	2.0
1385_0000053	2.0	2.0
1385_0000054	2.0	2.0
1385_0000099	0.0	1.0
1385_0000100	1.0	1.0
1385_0000122	2.0	2.0
1385_0000128	1.0	2.0
1385_0001107	2.0	1.0
1385_0001109	2.0	1.0
1385_0001110	2.0	2.0
1385_0001119	1.0	1.0
1385_0001121	1.0	2.0
1385_0001122	1.0	2.0
1385_0001125	1.0	1.0
1385_0001129	1.0	1.0
1385_0001148	2.0	2.0
1385_0001151	2.0	2.0
1385_0001157	1.0	2.0
1385_0001161	2.0	2.0
1385_0001165	1.0	2.0
1385_0001166	0.0	1.0
1385_0001170	1.0	0.0
1385_0001171	1.0	0.0
1385_0001195	1.0	2.0
1385_0001199	1.0	1.0
1385_0001723	0.0	1.0
1385_0001741	0.0	1.0
1385_0001744	0.0	1.0
1385_0001749	1.0	1.0
1385_0001752	0.0	1.0
1385_0001758	1.0	1.0
1385_0001772	0.0	1.0
1385_0001785	0.0	0.0
1385_0001786	1.0	2.0
1385_0001788	1.0	2.0
1385_0001792	0.0	2.0
1385_0001793	1.0	1.0
1395_0000355	2.0	2.0
1395_0000364	1.0	2.0
1395_0000368	0.0	1.0
1395_0000378	1.0	2.0
1395_0000390	1.0	1.0
1395_0000413	2.0	2.0
1395_0000415	1.0	2.0
1395_0000432	2.0	2.0
1395_0000449	2.0	2.0
1395_0000458	2.0	1.0
1395_0000527	1.0	2.0
1395_0000534	2.0	2.0
1395_0000535	1.0	1.0
1395_0000547	2.0	2.0
1395_0000551	2.0	1.0
1395_0000556	1.0	1.0
1395_0000557	3.0	3.0
1395_0000563	1.0	2.0
1395_0000572	1.0	2.0
1395_0000579	1.0	1.0
1395_0000598	1.0	2.0
1395_0000612	1.0	2.0
1395_0000626	1.0	2.0
1395_0000627	1.0	2.0
1395_0000635	0.0	1.0
1395_0000649	2.0	2.0
1395_0001016	2.0	1.0
1395_0001023	1.0	1.0
1395_0001024	1.0	2.0
1395_0001033	1.0	2.0
1395_0001061	1.0	2.0
1395_0001064	2.0	2.0
1395_0001078	0.0	2.0
1395_0001084	1.0	2.0
1395_0001093	1.0	2.0
1395_0001120	1.0	1.0
1395_0001123	1.0	1.0
1395_0001149	0.0	1.0
1395_0001171	1.0	2.0
5 Fold, Dimension = Grammaticalaccuracy

======== Epoch 1 / 4 ========
Training...
Elapsed time 9
Elapsed time 19
Elapsed time 28
Elapsed time 37
Elapsed time 47

  Average training loss: 1.16
  Training epoch took: 53
Running Validation...
  Average evaluation loss: 0.99